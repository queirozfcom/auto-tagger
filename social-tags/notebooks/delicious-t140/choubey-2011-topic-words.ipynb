{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see http://krex.k-state.edu/dspace/bitstream/handle/2097/9785/RahulChoubey2011.pdf\n",
    "\n",
    "This is an implementation of the first method of the two described above.\n",
    "\n",
    "Extract topics from the dataset using LDA then, for each test document, find out what are the most significant topics for it. Then they take the top 5 most likely words for the most likely topic and use those as recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import sklearn\n",
    "import sys\n",
    "import string\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV,ParameterGrid, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier,NearestNeighbors\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(os.getcwd(), os.pardir, '../src')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport data.delicious_t140\n",
    "%aimport features.delicious_t140\n",
    "%aimport helpers.labels,helpers.neighbours, helpers.delicious_t140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.delicious_t140 import load_or_get_from_cache,make_sample_with_contents_or_get_from_cache\n",
    "from features.delicious_t140 import clean_text_delicious\n",
    "from helpers.labels import truncate_labels\n",
    "from helpers.neighbours import get_predicted_labels_from_neighbours\n",
    "from helpers.topics import get_top_words_for_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../data/interim/movielens-ml20m-imdb/\")\n",
    "ML_ROOT = \"/media/felipe/SAMSUNG/movielens/ml-20m/\"\n",
    "IMDB_ROOT = \"/media/felipe/SAMSUNG/imdb/\"\n",
    "\n",
    "PATH_TO_MOVIES = ML_ROOT + \"/movies.csv\"\n",
    "PATH_TO_TAG_ASSIGNMENTS = ML_ROOT + \"/tags.csv\"\n",
    "PATH_TO_MOVIE_PLOTS = IMDB_ROOT+\"/plot.list\"\n",
    "\n",
    "# CONFIGS\n",
    "\n",
    "\n",
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../data/interim/delicious-t140/\")\n",
    "DATA_ROOT = \"/media/felipe/SAMSUNG/delicious/delicioust140/\"\n",
    "TAGINFO=DATA_ROOT+\"taginfo.xml\"\n",
    "\n",
    "# CONFIGS\n",
    "MAX_NB_WORDS = 4000 # using this because I've used this for other methods too\n",
    "STOP_WORDS='english' # using stopwords since most people using LDA did this\n",
    "NB_COMPONENTS = 200\n",
    "NB_RECOMMENDED_TAGS = 5\n",
    "PREPROC=clean_text_delicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = load_or_get_from_cache(TAGINFO,INTERIM_DATA_ROOT)\n",
    "sample_df = make_sample_with_contents_or_get_from_cache(docs_df,INTERIM_DATA_ROOT,DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sample_df['contents'].values\n",
    "labelsets = sample_df[\"unique_tags\"].map(lambda tagstring: tagstring.split(\",\")).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labelsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't put this into a pipeline because NearestNeighbors is not a normal classifier, I think\n",
    "# I need to customize the pipeline object to be able to call the methods for that class.\n",
    "vect = CountVectorizer(max_features=MAX_NB_WORDS, preprocessor=PREPROC, stop_words=STOP_WORDS)\n",
    "lda = LatentDirichletAllocation(n_components=NB_COMPONENTS, learning_method='online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,labelsets,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_train = lda.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "X_test = vect.transform(X_test)\n",
    "X_test = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2155, 200), (719, 200), (2155, 6881), (719, 6881))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "y_trues = []\n",
    "\n",
    "for (i,test_document_topics_distr) in enumerate(X_test):\n",
    "           \n",
    "    top_topic_index = test_document_topics_distr.argmax()\n",
    "    \n",
    "    top_words = get_top_words_for_topic(lda,top_topic_index,vect.get_feature_names(),NB_RECOMMENDED_TAGS)\n",
    "    \n",
    "    # some topic words are not valid tags\n",
    "    top_words_tags = [word for word in top_words if word in mlb.classes_]\n",
    "   \n",
    "    binary_label_vector = mlb.transform(np.array([top_words_tags]))\n",
    "       \n",
    "    y_pred = binary_label_vector.ravel()\n",
    "    y_true = y_test[i]\n",
    "     \n",
    "    y_preds.append(y_pred)\n",
    "    y_trues.append(y_true)\n",
    "    \n",
    "y_preds = np.array(y_preds)\n",
    "y_trues = np.array(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((719, 6881), (719, 6881))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds.shape,y_trues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0075122292103424167"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_trues,y_preds,average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
