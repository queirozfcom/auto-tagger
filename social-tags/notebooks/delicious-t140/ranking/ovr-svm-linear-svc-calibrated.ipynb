{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ovr-svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import sklearn\n",
    "import sys\n",
    "import string\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,average_precision_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV,ParameterGrid, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler,MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(os.getcwd(), os.pardir, '../../')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.data.delicious_t140\n",
    "%aimport src.helpers.labels\n",
    "%aimport src.utils.dataframes, src.utils.clusters, src.utils.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.delicious_t140 import clean_text_delicious\n",
    "from src.data.delicious_t140 import load_or_get_from_cache_with_contents\n",
    "from src.helpers.labels import truncate_labels\n",
    "from src.utils.metrics import ranking\n",
    "from src.utils.dataframes import sample_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_ROOT = os.path.abspath(\"../../../../models/ranking/delicious-t140-ovr-linear-svc-calibrated\")\n",
    "DATA_ROOT = \"/media/felipe/SAMSUNG/delicious/delicioust140\"\n",
    "INTERIM_DATA_ROOT = os.path.abspath(\"/data/interim/delicious-t140/\")\n",
    "OUTPUT_FILE = 'output-linear-svc-'+ datetime.now().strftime('%Y-%m-%d-%H-%M-%S')+'.txt'\n",
    "\n",
    "MAX_NB_WORDS = 5000\n",
    "SEED= 123\n",
    "SAMPLING_FACTOR = 0.5\n",
    "\n",
    "# because we are sampling the rows, we need to reassure the minimum tag_df is still\n",
    "# 10, as in the full dataset\n",
    "MIN_TAG_DF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = load_or_get_from_cache_with_contents(\n",
    "    source_dataframe=None,\n",
    "    interim_data_root=INTERIM_DATA_ROOT,\n",
    "    data_root=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must sample or we'll run out of memory\n",
    "num_rows = len(docs_df)\n",
    "num_rows_sample = int(num_rows*SAMPLING_FACTOR)\n",
    "\n",
    "docs_df = sample_rows(docs_df,num_rows_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = docs_df[\"tags\"].map(lambda tagstring: tagstring.split(\",\"))\n",
    "labels = truncate_labels(labels,MIN_TAG_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique tags: 5966 \n",
      "total number of train documents: 61080\n",
      "total number of validation documents: 10778\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "binary_labels = mlb.fit_transform(labels)\n",
    "\n",
    "print(\"total number of unique tags: {} \".format(len(mlb.classes_)))\n",
    "\n",
    "data = docs_df['contents'].values\n",
    "indices = np.arange(len(data))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "data = [data[i] for i in indices]\n",
    "targets = binary_labels[indices]\n",
    "num_validation_samples = int(0.15 * len(data))\n",
    "\n",
    "X_train = data[:-num_validation_samples]\n",
    "Y_train = targets[:-num_validation_samples]\n",
    "X_val = data[-num_validation_samples:]\n",
    "Y_val = targets[-num_validation_samples:]\n",
    "\n",
    "print('total number of train documents: {}'.format(len(X_train)))\n",
    "print('total number of validation documents: {}'.format(len(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/scikit-learn/scikit-learn/issues/6614\n",
    "class MyTfidfVectorizer(TfidfVectorizer):\n",
    "    def fit_transform(self, X, y):\n",
    "        result = super(MyTfidfVectorizer, self).fit_transform(X, y)\n",
    "        result.sort_indices()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', MyTfidfVectorizer()),\n",
    "    # https://stackoverflow.com/a/39712590/436721\n",
    "    ('clf', OneVsRestClassifier(CalibratedClassifierCV(LinearSVC(),cv=2),n_jobs=-1)),\n",
    "])\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "        \"vect__max_features\": [MAX_NB_WORDS]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for g in ParameterGrid(parameters):\n",
    "    pipeline.set_params(**g)\n",
    "    \n",
    "    pipeline.fit(X_train,Y_train)\n",
    "    \n",
    "    Y_pred_train = pipeline.predict_proba(X_train)    \n",
    "    Y_pred_val = pipeline.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train.shape,Y_pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(pipeline,open(MODELS_ROOT+\"/delicious-ovr-svc.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with open(OUTPUT_FILE,'a+') as f:\n",
    "\n",
    "    ks = [1,2,3,4,5,6,7,8,9,10]       \n",
    "\n",
    "    f.write('NORMALIZED MICRO-F1:')    \n",
    "    for k in ks:\n",
    "        f.write(\"train micro-F1 @{}: {}\\n\".format(k,ranking.micro_f1_at_k(Y_train,Y_pred_train,k=k,normalize=True)))\n",
    "        f.write(\"validation micro-F1 @{}: {}\\n\".format(k,ranking.micro_f1_at_k(Y_val,Y_pred_val,k=k,normalize=True)))\n",
    "\n",
    "    f.write(\"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
