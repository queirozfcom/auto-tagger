{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adapted from: https://github.com/nzw0301/keras-examples/blob/master/CBoW.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,re,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Embedding, Lambda, Input, Concatenate, Average\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "import gensim\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, '../../')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "%aimport src.data.movielens_20m_imdb\n",
    "%aimport src.helpers.labels,src.helpers.neighbours, src.helpers.segments\n",
    "%aimport src.utils.dataframes, src.utils.clusters, src.utils.metrics\n",
    "\n",
    "from src.data.movielens_20m_imdb import load_df_or_get_from_cache\n",
    "from src.helpers.labels import truncate_labels\n",
    "from src.helpers.neighbours import get_predicted_labels_from_neighbours\n",
    "from src.helpers.segments import make_distance_matrix_for_segments,vectorize_segments\n",
    "\n",
    "from src.utils.dataframes import sample_rows\n",
    "from src.utils.metrics import ranking\n",
    "\n",
    "MODELS_ROOT = os.path.abspath(\"../../../models/ranking/\")\n",
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../../data/interim/movielens-ml20m-imdb/\")\n",
    "PATH_TO_PROCESSED_FILE = os.path.abspath('../../../data/processed/movielens-20m-imdb-tags-and-synopses-2017-12-13.csv')\n",
    "\n",
    "# CONFIGS\n",
    "\n",
    "SEED= 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DEFAULT_KERAS_FILTER = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "\n",
    "MAX_TEXT_LENGTH = 1000\n",
    "NB_DOCS = 50\n",
    "DIM = 100\n",
    "CONTEXT_WINDOW_SIZE = 4\n",
    "STOPWORDS = None\n",
    "TOKENIZER_FILTERS = DEFAULT_KERAS_FILTER\n",
    "NB_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_df = load_df_or_get_from_cache(PATH_TO_PROCESSED_FILE,INTERIM_DATA_ROOT)\n",
    "docs_df = sample_rows(docs_df,NB_DOCS)\n",
    "corpus = docs_df['synopsis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=TOKENIZER_FILTERS)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE=len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(CONTEXT_WINDOW_SIZE*2,))\n",
    "x1 = Embedding(VOCAB_SIZE,output_dim=DIM,name=\"word_embeddings\")(input1)\n",
    "x1 = Lambda(lambda x: K.mean(x, axis=1), output_shape=(DIM,))(x1)\n",
    "\n",
    "outputs = Dense(VOCAB_SIZE,activation='softmax')(x1)\n",
    "\n",
    "cbow = Model(inputs=input1,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbow.compile(loss='categorical_crossentropy', optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 348.00 304.00\" width=\"348pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 344,-300 344,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140059180024328 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140059180024328</title>\n",
       "<polygon fill=\"none\" points=\"45.5,-249.5 45.5,-295.5 294.5,-295.5 294.5,-249.5 45.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"108\" y=\"-268.8\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"170.5,-249.5 170.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"170.5,-272.5 225.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"225.5,-249.5 225.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260\" y=\"-280.3\">(None, 8)</text>\n",
       "<polyline fill=\"none\" points=\"225.5,-272.5 294.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260\" y=\"-257.3\">(None, 8)</text>\n",
       "</g>\n",
       "<!-- 140059180024384 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140059180024384</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 340,-212.5 340,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-185.8\">word_embeddings: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"188,-166.5 188,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"188,-189.5 243,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"243,-166.5 243,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.5\" y=\"-197.3\">(None, 8)</text>\n",
       "<polyline fill=\"none\" points=\"243,-189.5 340,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291.5\" y=\"-174.3\">(None, 8, 100)</text>\n",
       "</g>\n",
       "<!-- 140059180024328&#45;&gt;140059180024384 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140059180024328-&gt;140059180024384</title>\n",
       "<path d=\"M170,-249.366C170,-241.152 170,-231.658 170,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"173.5,-222.607 170,-212.607 166.5,-222.607 173.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140059180024160 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140059180024160</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-83.5 32.5,-129.5 307.5,-129.5 307.5,-83.5 32.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-102.8\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"155.5,-83.5 155.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"155.5,-106.5 210.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"183\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-83.5 210.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-114.3\">(None, 8, 100)</text>\n",
       "<polyline fill=\"none\" points=\"210.5,-106.5 307.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"259\" y=\"-91.3\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 140059180024384&#45;&gt;140059180024160 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140059180024384-&gt;140059180024160</title>\n",
       "<path d=\"M170,-166.366C170,-158.152 170,-148.658 170,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"173.5,-139.607 170,-129.607 166.5,-139.607 173.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140060820932424 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140060820932424</title>\n",
       "<polygon fill=\"none\" points=\"47,-0.5 47,-46.5 293,-46.5 293,-0.5 47,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98\" y=\"-19.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"149,-0.5 149,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"149,-23.5 204,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"176.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204,-0.5 204,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-31.3\">(None, 100)</text>\n",
       "<polyline fill=\"none\" points=\"204,-23.5 293,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-8.3\">(None, 8140)</text>\n",
       "</g>\n",
       "<!-- 140059180024160&#45;&gt;140060820932424 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140059180024160-&gt;140060820932424</title>\n",
       "<path d=\"M170,-83.3664C170,-75.1516 170,-65.6579 170,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"173.5,-56.6068 170,-46.6068 166.5,-56.6069 173.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(cbow,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(document_sequences, window_size, vocabulary_size):\n",
    "    \n",
    "    maxlen = window_size*2\n",
    "    \n",
    "    for word_sequence in document_sequences:\n",
    "               \n",
    "        text_length = len(word_sequence)\n",
    "        \n",
    "        for index_in_document,word in enumerate(word_sequence):\n",
    "            \n",
    "            # these are the words in the context\n",
    "            contexts = []\n",
    "            # these are the target words (which we'll predict using the context)\n",
    "            labels = []\n",
    "                        \n",
    "            context_start = index_in_document - window_size           \n",
    "            context_end   = index_in_document + window_size\n",
    "            \n",
    "            context = []\n",
    "            \n",
    "            for index_in_context in range(context_start, context_end+1):\n",
    "                if index_in_document != index_in_context: # index_in_context is the target word\n",
    "                    if index_in_context >= 0 and index_in_context < text_length: # inner_index must be a valid index\n",
    "                        context_word = word_sequence[index_in_context]\n",
    "                        context.append(context_word)\n",
    "                        \n",
    "            contexts.append(context)\n",
    "                       \n",
    "            labels.append(word)\n",
    "            \n",
    "            x = sequence.pad_sequences(contexts, maxlen=maxlen)\n",
    "            y = np_utils.to_categorical(labels,vocabulary_size)\n",
    "            \n",
    "            \n",
    "            yield (x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:21, 220.66it/s]\n",
      "23it [00:00, 223.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 446069.647014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:05, 234.60it/s]\n",
      "23it [00:00, 222.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 419264.262371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:09, 230.82it/s]\n",
      "23it [00:00, 225.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 412276.138731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:29, 214.10it/s]\n",
      "25it [00:00, 247.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 408076.373506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:32, 211.35it/s]\n",
      "23it [00:00, 229.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 405076.060303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:16, 224.59it/s]\n",
      "26it [00:00, 253.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 402690.049448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [03:56, 244.09it/s]\n",
      "23it [00:00, 228.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 400639.264996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:09, 231.02it/s]\n",
      "22it [00:00, 212.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 398772.944107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:22, 220.00it/s]\n",
      "22it [00:00, 212.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 397007.804901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:12, 228.31it/s]\n",
      "23it [00:00, 221.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 395302.378117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:22, 219.89it/s]\n",
      "22it [00:00, 217.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 393642.745139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:11, 229.17it/s]\n",
      "23it [00:00, 222.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 392031.443743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:17, 224.13it/s]\n",
      "23it [00:00, 222.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 390478.77586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:15, 225.44it/s]\n",
      "18it [00:00, 176.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 388996.738824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:32, 211.50it/s]\n",
      "22it [00:00, 214.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 387595.35157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:11, 228.98it/s]\n",
      "24it [00:00, 230.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 386281.714822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:17, 223.58it/s]\n",
      "26it [00:00, 251.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 385059.334571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:07, 232.96it/s]\n",
      "16it [00:00, 154.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 383928.123292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:18, 223.25it/s]\n",
      "21it [00:00, 207.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 382884.787867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57641it [04:08, 232.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 381923.524573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NB_EPOCHS):\n",
    "    loss = 0.\n",
    "    for x, y in tqdm(generate_data(sequences, CONTEXT_WINDOW_SIZE, VOCAB_SIZE)):\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('vectors.txt' ,'w')\n",
    "f.write(' '.join([str(VOCAB_SIZE-1), str(DIM)]))\n",
    "f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = [ (word,i) for word,i in tokenizer.word_index.items()]\n",
    "\n",
    "pairs = sorted(pairs,key=lambda tpl: tpl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actually_used_word_index = dict(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8140, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = cbow.get_weights()[0]\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word, i in actually_used_word_index.items():\n",
    "    f.write(word)\n",
    "    f.write(' ')\n",
    "    f.write(' '.join(map(str, list(vectors[i, :]))))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('that', 0.6086381673812866),\n",
       " ('he', 0.588042140007019),\n",
       " ('not', 0.572224497795105),\n",
       " ('will', 0.5647653341293335),\n",
       " ('can', 0.5543062686920166),\n",
       " ('because', 0.5513842105865479),\n",
       " ('may', 0.5508166551589966),\n",
       " ('him', 0.5297994613647461),\n",
       " ('says', 0.5255216360092163),\n",
       " ('it', 0.5166193842887878)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('that', 0.8691412210464478),\n",
       " ('she', 0.8348675966262817),\n",
       " ('not', 0.8228061199188232),\n",
       " ('it', 0.8227299451828003),\n",
       " ('tells', 0.8151426315307617),\n",
       " ('her', 0.8141981959342957),\n",
       " ('will', 0.8055366277694702),\n",
       " ('him', 0.8026009202003479),\n",
       " ('but', 0.7896877527236938),\n",
       " ('was', 0.7857427597045898)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rest', 0.7995232343673706),\n",
       " ('celebrate', 0.7980454564094543),\n",
       " ('howls', 0.7945990562438965),\n",
       " ('group', 0.7936820983886719),\n",
       " ('missile', 0.7922608256340027),\n",
       " ('structure', 0.7911497354507446),\n",
       " ('launched', 0.7891209125518799),\n",
       " ('ground', 0.7878245115280151),\n",
       " ('murderer', 0.7875157594680786),\n",
       " ('dwindling', 0.7819898724555969)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('that', 0.8039196729660034),\n",
       " ('will', 0.7990150451660156),\n",
       " ('says', 0.7880035638809204),\n",
       " ('tells', 0.7846977710723877),\n",
       " ('he', 0.7732518911361694),\n",
       " ('not', 0.7722700834274292),\n",
       " ('if', 0.7616811990737915),\n",
       " ('but', 0.7610113024711609),\n",
       " ('him', 0.754069447517395),\n",
       " ('she', 0.753523588180542)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['can'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = PATH_TO_SAVED_MODELS+\"/word2vec-cbow.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbow.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
