{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mimlsvm\n",
    "\n",
    "mi = mulit-instance\n",
    "ml = multi-label\n",
    "svm = svm\n",
    "\n",
    "As described in Shen et al 2009: http://ieeexplore.ieee.org/document/5346261/\n",
    "\n",
    "> Should we use SVM-struct instead? https://github.com/pystruct/pystruct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good params: {'svm_degree': 3, 'svm_kernel': 'poly', 'medoid_normalization': None, 'nb_medoids_ratio': 0.2, 'svm_gamma': 'auto', 'vectorizer_norm': None, 'svm_c': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import sklearn\n",
    "import sys\n",
    "import string\n",
    "\n",
    "from hausdorff import hausdorff\n",
    "\n",
    "from nltk import TextTilingTokenizer\n",
    "from scipy.spatial.distance  import directed_hausdorff, pdist\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV,ParameterGrid, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler,MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(os.getcwd(), os.pardir, '../../')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.data.movielens_20m_imdb\n",
    "%aimport src.helpers.labels,src.helpers.neighbours, src.helpers.segments\n",
    "%aimport src.utils.dataframes, src.utils.clusters, src.utils.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.movielens_20m_imdb import load_df_or_get_from_cache\n",
    "from src.helpers.labels import truncate_labels\n",
    "from src.helpers.neighbours import get_predicted_labels_from_neighbours\n",
    "from src.helpers.segments import make_distance_matrix_for_segments,vectorize_segments\n",
    "\n",
    "from src.utils.dataframes import sample_rows\n",
    "from src.utils.metrics import ranking\n",
    "from src.utils.clusters import k_medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_ROOT = os.path.abspath(\"../../../models/ranking/movielens-ovr-linear-svc-calibrated/\")\n",
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../../data/interim/movielens-ml20m-imdb/\")\n",
    "PATH_TO_PROCESSED_FILE = os.path.abspath('../../../data/processed/movielens-20m-imdb-tags-and-synopses-2017-12-20.csv')\n",
    "\n",
    "# CONFIGS\n",
    "\n",
    "SEED= 42\n",
    "MAX_NB_WORDS = 300\n",
    "NB_DOCS=0.2\n",
    "MIN_TAG_DF=10\n",
    "\n",
    "# preprocessing\n",
    "\n",
    "# grid search:\n",
    "\n",
    "VECTORIZER_NORM = ['l1','l2',None]\n",
    "W=20 # Pseudosentence size (in words) - not specified in the paper, taken from TextTiling default values\n",
    "K=10 # Size (in sentences) of the block used in the block comparison method - not specified in the paper, taken from TextTiling default values\n",
    "\n",
    "# calculating medoids\n",
    "NORMALIZATION = ['standard','minmax',None] # not specified in the paper\n",
    "SAMPLE_TO_NB_MEDOIDS_RATIO = [0.2,0.3,0.4] # not specified in the paper, but taken from MIMLSVM canonical implementation\n",
    "# classification\n",
    "SVM_KERNEL=['rbf','linear','poly'] # not specified in the paper, but taken from MIMLSVM canonical implementation\n",
    "SVM_GAMMA=['auto'] # not specified in the paper, but taken from MIMLSVM canonical implementation\n",
    "SVM_C= [0.001,0.01,0.1,1]# not specified in the paper, but taken from MIMLSVM canonical implementation\n",
    "SVM_DEGREE=[3,4,5]\n",
    "\n",
    "####################################\n",
    "### FINAL PARAMS AFTER GRID SEARCH\n",
    "###################################\n",
    "MAX_NB_WORDS = 5000\n",
    "\n",
    "# preprocessing\n",
    "VECTORIZER_NORM = [None]\n",
    "W=20 # Pseudosentence size (in words) - not specified in the paper, taken from TextTiling default values\n",
    "K=10 # Size (in sentences) of the block used in the block comparison method - not specified in the paper, taken from TextTiling default values\n",
    "\n",
    "# calculating medoids\n",
    "NORMALIZATION = [None] # not specified in the paper\n",
    "SAMPLE_TO_NB_MEDOIDS_RATIO = [0.2] # not specified in the paper, but taken from MIMLSVM canonical implementation\n",
    "# classification\n",
    "SVM_KERNEL=['poly'] # not specified in the paper, but taken from MIMLSVM canonical implementation\n",
    "SVM_GAMMA=['auto'] # not specified in the paper, but taken from MIMLSVM canonical implementation\n",
    "SVM_C= [1]# not specified in the paper, but taken from MIMLSVM canonical implementation\n",
    "SVM_DEGREE=[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = load_df_or_get_from_cache(PATH_TO_PROCESSED_FILE,INTERIM_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this for production\n",
    "# docs_df = sample_rows(docs_df,NB_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df['sentences'] = docs_df['synopsis'].map(lambda row: sentence_tokenizer.tokenize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 4.43 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs_df['num_sentences'] = docs_df['sentences'].map( lambda sents: len(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>num_tags</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>A boy called Andy Davis (voice: John Morris) u...</td>\n",
       "      <td>buy,want-to-see-again,unlikely-friendships,inn...</td>\n",
       "      <td>59</td>\n",
       "      <td>[A boy called Andy Davis (voice: John Morris) ...</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>The film begins in 1869 in the town of Brantfo...</td>\n",
       "      <td>childish,robin-williams,time,not-for-kids,adap...</td>\n",
       "      <td>19</td>\n",
       "      <td>[The film begins in 1869 in the town of Brantf...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>An inbound Blue Line train pulls in to Firesto...</td>\n",
       "      <td>rviolence,soundtrack,suspense,dialogue,bibliot...</td>\n",
       "      <td>57</td>\n",
       "      <td>[An inbound Blue Line train pulls in to Firest...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Sabrina Fairchild (Julia Ormond), is the Larra...</td>\n",
       "      <td>based-on-a-play,clv,remake,relationships,chick...</td>\n",
       "      <td>13</td>\n",
       "      <td>[Sabrina Fairchild (Julia Ormond), is the Larr...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>The film opens with Injun Joe (Eric Schweig) a...</td>\n",
       "      <td>based-on-a-book,adapted-frombook,seen</td>\n",
       "      <td>3</td>\n",
       "      <td>[The film opens with Injun Joe (Eric Schweig) ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                title  \\\n",
       "0         1     Toy Story (1995)   \n",
       "1         2       Jumanji (1995)   \n",
       "2         6          Heat (1995)   \n",
       "3         7       Sabrina (1995)   \n",
       "4         8  Tom and Huck (1995)   \n",
       "\n",
       "                                            synopsis  \\\n",
       "0  A boy called Andy Davis (voice: John Morris) u...   \n",
       "1  The film begins in 1869 in the town of Brantfo...   \n",
       "2  An inbound Blue Line train pulls in to Firesto...   \n",
       "3  Sabrina Fairchild (Julia Ormond), is the Larra...   \n",
       "4  The film opens with Injun Joe (Eric Schweig) a...   \n",
       "\n",
       "                                                tags  num_tags  \\\n",
       "0  buy,want-to-see-again,unlikely-friendships,inn...        59   \n",
       "1  childish,robin-williams,time,not-for-kids,adap...        19   \n",
       "2  rviolence,soundtrack,suspense,dialogue,bibliot...        57   \n",
       "3  based-on-a-play,clv,remake,relationships,chick...        13   \n",
       "4              based-on-a-book,adapted-frombook,seen         3   \n",
       "\n",
       "                                           sentences  num_sentences  \n",
       "0  [A boy called Andy Davis (voice: John Morris) ...            267  \n",
       "1  [The film begins in 1869 in the town of Brantf...            115  \n",
       "2  [An inbound Blue Line train pulls in to Firest...            226  \n",
       "3  [Sabrina Fairchild (Julia Ormond), is the Larr...             27  \n",
       "4  [The film opens with Injun Joe (Eric Schweig) ...             23  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A boy called Andy Davis (voice: John Morris) uses his toys to act out a bank robbery.',\n",
       " 'The bank is a cardboard box, the robber is Mr.',\n",
       " 'Potato Head (voice: Don Rickles) assisted by Slinky Dog (voice: Jim Varney), and the bystanders include Bo Peep (voice: Annie Potts) and her sheep.',\n",
       " 'The day is saved by cowboy doll Woody (voice: Tom Hanks) playing the sheriff, with help from Rex the dinosaur (voice: Wallace Shawn).',\n",
       " 'Woody is the only toy who gets to say his own lines because he has a pull-string that makes him say things like \"Reach for the sky!\"']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.iloc[0]['sentences'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>num_tags</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6710.000000</td>\n",
       "      <td>6710.000000</td>\n",
       "      <td>6710.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41263.124888</td>\n",
       "      <td>12.214605</td>\n",
       "      <td>58.771088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39409.134389</td>\n",
       "      <td>14.369509</td>\n",
       "      <td>74.754297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4106.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31251.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74531.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>131082.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>1472.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            movie_id     num_tags  num_sentences\n",
       "count    6710.000000  6710.000000    6710.000000\n",
       "mean    41263.124888    12.214605      58.771088\n",
       "std     39409.134389    14.369509      74.754297\n",
       "min         1.000000     1.000000       1.000000\n",
       "25%      4106.250000     3.000000      13.000000\n",
       "50%     31251.000000     7.000000      37.000000\n",
       "75%     74531.500000    16.000000      72.000000\n",
       "max    131082.000000   189.000000    1472.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = TextTilingTokenizer(w=W, k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments(candidates):\n",
    "    \n",
    "    try:\n",
    "        # we must manually insert \"\\n\\n\" because this is how \n",
    "        # texttilingtokenizer requires candidate boundaries to be \n",
    "        # represented.\n",
    "        segments = tok.tokenize(\"\\n\\n\".join(candidates))\n",
    "    except ValueError:\n",
    "        # this happens when the candidate list is too small for the \n",
    "        # text tiling tokenizer to be able to find segments. so just return\n",
    "        # the original sentences.\n",
    "        segments= candidates\n",
    "        \n",
    "    # now remove the artificially added chars\n",
    "    segments = [segment.replace(\"\\n\\n\",\" \").strip() for segment in segments]\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51min 54s, sys: 40 ms, total: 51min 54s\n",
      "Wall time: 51min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docs_df['segments'] = docs_df['sentences'].map(lambda candidates: extract_segments(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A boy called Andy Davis (voice: John Morris) uses his toys to act out a bank robbery. The bank is a cardboard box, the robber is Mr. Potato Head (voice: Don Rickles) assisted by Slinky Dog (voice: Jim Varney), and the bystanders include Bo Peep (voice: Annie Potts) and her sheep. The day is saved by cowboy doll Woody (voice: Tom Hanks) playing the sheriff, with help from Rex the dinosaur (voice: Wallace Shawn). Woody is the only toy who gets to say his own lines because he has a pull-string that makes him say things like \"Reach for the sky!\"',\n",
       " 'and \"You\\'re my favorite deputy!\" During the opening credits (soundtrack: Randy Newman\\'s \"You\\'ve Got a Friend in Me\"), Andy takes Woody downstairs to find his mother (voice: Laurie Metcalf) decorating the dining room for his birthday party. He asks if they can leave the decorations up until they move, and his mom agrees. She says the guests will arrive soon and sends him back upstairs to get his baby sister Molly (voice: Hannah Unkrich), whose crib is in his room.',\n",
       " 'Andy tosses Woody onto his bed before he pulls Molly out of her crib and carries her away. Woody and the other toys have seemed limp and inanimate up to this point, but as soon as Andy leaves the room, Woody sits up and expresses surprise that the birthday party is today. He calls \"Ok, everybody, the coast is clear,\" and the other toys come to life too. Woody calls a staff meeting and tells Slinky Dog to spread the word. Within a few minutes (during which Bo Peep makes a date with Woody for that evening), all the toys are assembled.',\n",
       " \"Woody starts by reminding them all to find a moving buddy so they don't get lost when the Davis family moves to their new house, which will happen in a week. Then he tries to downplay the news that Andy's birthday party is happening today, but it causes a commotion as the toys know that Andy's actual birthday isn't till next week. Rex worries that someone will give Andy another dinosaur, and many of the toys have similar concerns. Woody points out that it makes sense to have the party before the move, then tries to calm them down.\",\n",
       " 'He\\'s interrupted when Hamm (voice: John Ratzenberger) the piggybank, stationed near the window, announces that the guests are arriving. The toys rush to the window to see the presents the kids are bringing; the bigger boxes make them especially nervous. Hamm predicts \"we\\'re next month\\'s garage sale fodder for sure.\" Woody finally says, \"If I send out the troops, will you all calm down?\" Sending out the troops means that the little green plastic soldiers, led by Sarge (voice: R. Lee Ermey), lower the baby monitor to the first floor and hide with it in a potted plant, where they can observe the opening of the gifts and report back to the toys in Andy\\'s room. At first, the presents seem nonthreatening &amp;mdash; a lunchbox, bed sheets (\"who invited that kid?\" wonders Mr. Potato Head), a Battleship game. But Andy\\'s mom pulls a surprise present from the closet. Andy\\'s very excited about it, but before they hear what it is, Rex knocks the speaker off the table and the batteries fall out.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['segments'][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = docs_df['segments'].values\n",
    "documents = docs_df['synopsis'].values\n",
    "labels = docs_df[\"tags\"].map(lambda tagstring: tagstring.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove for production\n",
    "# labels = truncate_labels(labels,MIN_TAG_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_dataset(distance_matrix, medoid_indices):\n",
    "    \"\"\"\n",
    "    Returns a matrix where element Aij contains the distance from sample i to medoid j.\n",
    "\n",
    "    :param distance_matrix: MxM matrix with pairwise distances\n",
    "    :param medoid_indices: array of length N containing the indices of the medoids for each cluster\n",
    "    :return: distances to medoids (MxN matrix)\n",
    "    \"\"\"\n",
    "\n",
    "    return distance_matrix[:,medoid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_dataset(source_vectorized_segments, medoid_vectorized_segments):\n",
    "    \"\"\"\n",
    "    Calculates the distances from every source_document (reprsented by its segments) to every medoid\n",
    "    document (also represented by its segments) using the hausdorff distance.\n",
    "    \n",
    "    Returns a matrix where element Aij contains the distance from sample i to medoid j.\n",
    "\n",
    "    :param source_vectorized_segments: array of length M, where each element is a matrix with one row\n",
    "        for every segment in a source document\n",
    "    :param medoid_vectorized_segments: array of length N where each element is a matrix with one row\n",
    "        for every segment in a medoid document\n",
    "    :return: distances to medoids (MxN matrix)\n",
    "    \"\"\"\n",
    "    \n",
    "    num_test_samples = len(source_vectorized_segments)\n",
    "    num_medoids = len(medoid_vectorized_segments)\n",
    "    \n",
    "    test_dataset = np.zeros((num_test_samples,num_medoids))    \n",
    "    \n",
    "    for i,source_segments in enumerate(source_vectorized_segments):\n",
    "        for j,medoid_segments in enumerate(medoid_vectorized_segments):\n",
    "            test_dataset[i][j] = hausdorff(source_segments.toarray(),medoid_segments.toarray())\n",
    "            \n",
    "    return np.array(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of train documents: 5703\n",
      "total number of validation documents: 1007\n"
     ]
    }
   ],
   "source": [
    "# segments, documents and labelsets are defined outside of the parameterGrid loop\n",
    "# because they're the same for every configuration    \n",
    "segments_train, segments_test, documents_train, documents_test, Y_train, Y_test = train_test_split(segments,\n",
    "                                                                                               documents,\n",
    "                                                                                               labels,\n",
    "                                                                                               test_size=0.15)\n",
    "\n",
    "print('total number of train documents: {}'.format(len(documents_train)))\n",
    "print('total number of validation documents: {}'.format(len(documents_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of unique tags: 2138 \n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "\n",
    "# the binarizer needs to be fit on all labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labels)\n",
    "\n",
    "Y_train = mlb.transform(Y_train)\n",
    "Y_test = mlb.transform(Y_test)\n",
    "\n",
    "print(\"total number of unique tags: {} \".format(len(mlb.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_params = [\n",
    "    {\n",
    "        'medoid_normalization':  NORMALIZATION,\n",
    "        'svm_kernel': ['poly'],\n",
    "        'svm_c':SVM_C,\n",
    "        'svm_degree' :SVM_DEGREE,\n",
    "        'svm_gamma':SVM_GAMMA,\n",
    "        'vectorizer_norm': VECTORIZER_NORM,\n",
    "        'nb_medoids_ratio': SAMPLE_TO_NB_MEDOIDS_RATIO\n",
    "    },\n",
    "    {\n",
    "        'medoid_normalization':  NORMALIZATION,\n",
    "        'svm_kernel': ['rbf'],\n",
    "        'svm_c':SVM_C,\n",
    "        'svm_degree' :[None],\n",
    "        'svm_gamma':SVM_GAMMA,\n",
    "        'vectorizer_norm': VECTORIZER_NORM,\n",
    "        'nb_medoids_ratio': SAMPLE_TO_NB_MEDOIDS_RATIO\n",
    "    },\n",
    "    {\n",
    "        'medoid_normalization':  NORMALIZATION,\n",
    "        'svm_kernel': ['linear'],\n",
    "        'svm_c':SVM_C,\n",
    "        'svm_gamma':SVM_GAMMA,\n",
    "        'svm_degree' :[None],\n",
    "        'vectorizer_norm': VECTORIZER_NORM,\n",
    "        'nb_medoids_ratio': SAMPLE_TO_NB_MEDOIDS_RATIO\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'medoid_normalization':  NORMALIZATION,\n",
    "        'svm_kernel': SVM_KERNEL,\n",
    "        'svm_c':SVM_C,\n",
    "        'svm_degree' :SVM_DEGREE,\n",
    "        'svm_gamma':SVM_GAMMA,\n",
    "        'vectorizer_norm': VECTORIZER_NORM,\n",
    "        'nb_medoids_ratio': SAMPLE_TO_NB_MEDOIDS_RATIO\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of configurations to test: 1\n"
     ]
    }
   ],
   "source": [
    "print('total number of configurations to test: {}'.format(len(ParameterGrid(parameters))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting distance matrix for norm=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.4/dist-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/connection.py\", line 416, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/connection.py\", line 383, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.4/dist-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-15ec94e2de76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# y_train was defined outside the loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# train score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;34m\"not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[0;32m--> 215\u001b[0;31m             for i, column in enumerate(columns))\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = float(\"-inf\")\n",
    "best_configuration = None\n",
    "\n",
    "for (i,configuration) in enumerate(tqdm(ParameterGrid(parameters))):\n",
    "    \n",
    "    # TFIDF_VECTORIZER = COUNT_VECTORIZER + TFIDF_TRANSFORMER\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=MAX_NB_WORDS, norm=configuration['vectorizer_norm'])\n",
    "    # TRAINING SET\n",
    "    tfidf_vectorizer.fit(documents_train)\n",
    "    tfidf_segments_train = vectorize_segments(segments_train, tfidf_vectorizer)\n",
    "        \n",
    "    \n",
    "    # THE FOLLOWING BLOCK TAKES SOME TIME, BUT IT WILL ONLY RUN ONCE\n",
    "    \n",
    "    path_to_cache = INTERIM_DATA_ROOT.rstrip('/') + \"/mimlsvm/distance-matrix-train-sample-{}-{}-{}.p\".format(\n",
    "        NB_DOCS,\n",
    "        MAX_NB_WORDS,\n",
    "        configuration['vectorizer_norm'])\n",
    "    \n",
    "    if os.path.isfile(path_to_cache):\n",
    "        dist_matrix_train = pickle.load(open(path_to_cache,\"rb\"))\n",
    "    else:\n",
    "        print('Fitting distance matrix for norm={}'.format(configuration['vectorizer_norm']))\n",
    "        \n",
    "        dist_matrix_train = make_distance_matrix_for_segments(tfidf_segments_train)\n",
    "        pickle.dump(dist_matrix_train, open(path_to_cache, \"wb\"))\n",
    "    \n",
    "    # nb_medoids depends upon the dataset length\n",
    "    ratio = configuration['nb_medoids_ratio']\n",
    "    nb_medoids = int(len(tfidf_segments_train) * ratio)\n",
    "    \n",
    "    medoids_indices_train = k_medoids(dist_matrix_train,nb_medoids)[0]\n",
    "\n",
    "    X_train = make_train_dataset(dist_matrix_train,medoids_indices_train)\n",
    "    \n",
    "    # TEST SET\n",
    "    \n",
    "    tfidf_segments_test = vectorize_segments(segments_test, tfidf_vectorizer)\n",
    "          \n",
    "    # medoids trained on the training set\n",
    "    fitted_medoids = tfidf_segments_train[medoids_indices_train]\n",
    "    X_test = make_test_dataset(tfidf_segments_test,fitted_medoids)\n",
    "      \n",
    "    clf = OneVsRestClassifier(\n",
    "        SVC(kernel=configuration['svm_kernel'],\n",
    "            gamma=configuration['svm_gamma'],\n",
    "            C=configuration['svm_c'],\n",
    "            degree=configuration['svm_degree'],\n",
    "            probability=True,\n",
    "           ),n_jobs=-1)    \n",
    "\n",
    "   \n",
    "    \n",
    "    if configuration['medoid_normalization'] == 'standard':      \n",
    "        scaler = StandardScaler()\n",
    "        X_train_final = scaler.fit_transform(X_train)\n",
    "        X_test_final = scaler.transform(X_test)\n",
    "    elif configuration['medoid_normalization'] == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_final = scaler.fit_transform(X_train)\n",
    "        X_test_final = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_final = X_train\n",
    "        X_test_final = X_test\n",
    "    \n",
    "    # y_train was defined outside the loop    \n",
    "    clf.fit(X_train,Y_train)\n",
    "    \n",
    "    # train score\n",
    "    Y_pred_train = clf.predict_proba(X_train)\n",
    "    \n",
    "    # validation score\n",
    "    Y_pred_test = clf.predict_proba(X_test)  \n",
    "    \n",
    "    print(\"iter: {}, configuration: {}\\n\".format(i,configuration))\n",
    "    \n",
    "    ks = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "    for k in ks:\n",
    "#         print(\"train micro-F1 @{}: {}\".format(k,ranking.micro_f1_at_k(Y_train,Y_pred_train,k=k,normalize=True)))\n",
    "        print(\"validation micro-F1 @{}: {}\".format(k,ranking.micro_f1_at_k(Y_test,Y_pred_test,k=k,normalize=True)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
