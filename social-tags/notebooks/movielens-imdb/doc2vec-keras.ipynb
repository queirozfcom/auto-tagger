{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adapted from: https://github.com/nzw0301/keras-examples/blob/master/CBoW.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,re,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import pickle\n",
    "import string\n",
    "import gensim\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input,Lambda, Dense, Concatenate, Average,Flatten\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/felipe/auto-tagger/social-tags/notebooks/movielens-imdb/../../\n"
     ]
    }
   ],
   "source": [
    "src_dir = os.path.join(os.getcwd(), os.pardir, '../')\n",
    "print(src_dir)\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport src.data.movielens_20m_imdb\n",
    "%aimport src.utils.dataframes\n",
    "\n",
    "from src.data.movielens_20m_imdb import load_df_or_get_from_cache\n",
    "from src.utils.dataframes import sample_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VECTORS_DATA_ROOT = os.path.abspath(\"../../data/vectors/movielens-ml20m-imdb/\")\n",
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../data/interim/movielens-ml20m-imdb/\")\n",
    "\n",
    "\n",
    "PATH_TO_SAVED_MODELS = os.path.abspath('../../models/')\n",
    "\n",
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../data/interim/movielens-ml20m-imdb/\")\n",
    "PATH_TO_PROCESSED_FILE = os.path.abspath('../../data/processed/movielens-20m-imdb-tags-and-synopses-2017-12-13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_KERAS_FILTER = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "MAX_TEXT_LENGTH = 1000\n",
    "NB_DOCS = 500\n",
    "DIM = 50\n",
    "CONTEXT_WINDOW_SIZE = 2\n",
    "# STOPWORDS BREAK W2V!!!!\n",
    "STOPWORDS = None\n",
    "\n",
    "TOKENIZER_FILTERS = DEFAULT_KERAS_FILTER\n",
    "NB_EPOCHS = 10\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = load_df_or_get_from_cache(PATH_TO_PROCESSED_FILE,INTERIM_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove this for production\n",
    "docs_df = sample_rows(docs_df,NB_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = docs_df['synopsis'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=TOKENIZER_FILTERS)\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = sum(len(seq) for seq in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565575"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total size of the corpus, in words\n",
    "# this will be the number of iterations be epoch\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the document marker is just added as another word to every context\n",
    "# note that it will be averaged with the other words in the context\n",
    "def generate_data(document_sequences, window_size, vocabulary_size):\n",
    "    \n",
    "    maxlen = window_size*2\n",
    "    \n",
    "    for doc_index, word_sequence in enumerate(document_sequences):\n",
    "                  \n",
    "        text_length = len(word_sequence)\n",
    "        \n",
    "        for index_in_document,word in enumerate(word_sequence):\n",
    "                  \n",
    "            # these are the words in the context\n",
    "            contexts = []\n",
    "               \n",
    "            # these are the target words (which we'll predict using the context)\n",
    "            labels = []\n",
    "        \n",
    "            context_start = index_in_document - window_size           \n",
    "            context_end   = index_in_document + window_size\n",
    "            \n",
    "            context_words = []\n",
    "            \n",
    "            for index_in_context in range(context_start, context_end+1):\n",
    "                if index_in_document != index_in_context: # index_in_context is the target word\n",
    "                    if index_in_context >= 0 and index_in_context < text_length: # inner_index must be a valid index\n",
    "                        context_word = word_sequence[index_in_context]\n",
    "                        context_words.append(context_word)\n",
    "                                                                     \n",
    "            labels.append(word)\n",
    "                        \n",
    "            x1 = sequence.pad_sequences([context_words], maxlen=maxlen)\n",
    "                       \n",
    "            # needs to be at least one or the index will be interpreted as a mask    \n",
    "            x2 = np.array([doc_index+1])\n",
    "                                   \n",
    "            x = [x1,x2]\n",
    "            \n",
    "            y = np_utils.to_categorical(labels,vocabulary_size)           \n",
    "            \n",
    "#             print(\"contexts is: {}\".format(contexts))\n",
    "#             print(\"x1 is: {}\".format(x1.shape))\n",
    "#             print(\"x2 is: {}\".format(x2.shape))\n",
    "#             print(\"y is: {}\".format(y.shape))\n",
    "#             return\n",
    "            \n",
    "            yield (x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28510"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE=len(tokenizer.word_index) + 1\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(CONTEXT_WINDOW_SIZE*2,))\n",
    "x1 = Embedding(VOCAB_SIZE,output_dim=DIM,name=\"word_embeddings\")(input1)\n",
    "x1 = Lambda(lambda x: K.mean(x, axis=1))(x1)\n",
    "\n",
    "input2 = Input(shape=(1,))\n",
    "x2 = Embedding(NB_DOCS+1,output_dim=DIM,name=\"document_embeddings\")(input2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "x = Average()([x1,x2])\n",
    "\n",
    "outputs = Dense(VOCAB_SIZE,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvdm = Model(inputs=[input1,input2],outputs=outputs)\n",
    "pvdm.compile(loss='categorical_crossentropy', optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 718.00 387.00\" width=\"718pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-383 714,-383 714,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139958347294536 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139958347294536</title>\n",
       "<polygon fill=\"none\" points=\"38.5,-332.5 38.5,-378.5 294.5,-378.5 294.5,-332.5 38.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-351.8\">input_14: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"170.5,-332.5 170.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"170.5,-355.5 225.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"225.5,-332.5 225.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260\" y=\"-363.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"225.5,-355.5 294.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260\" y=\"-340.3\">(None, 4)</text>\n",
       "</g>\n",
       "<!-- 139958347294480 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139958347294480</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 333,-295.5 333,-249.5 0,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-268.8\">word_embeddings: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"188,-249.5 188,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"188,-272.5 243,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"243,-249.5 243,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-280.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"243,-272.5 333,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-257.3\">(None, 4, 50)</text>\n",
       "</g>\n",
       "<!-- 139958347294536&#45;&gt;139958347294480 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139958347294536-&gt;139958347294480</title>\n",
       "<path d=\"M166.5,-332.366C166.5,-324.152 166.5,-314.658 166.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"170,-305.607 166.5,-295.607 163,-305.607 170,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139958347294424 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139958347294424</title>\n",
       "<polygon fill=\"none\" points=\"402.5,-332.5 402.5,-378.5 658.5,-378.5 658.5,-332.5 402.5,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468.5\" y=\"-351.8\">input_15: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-332.5 534.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"534.5,-355.5 589.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"562\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"589.5,-332.5 589.5,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"624\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"589.5,-355.5 658.5,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"624\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 139958347294872 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139958347294872</title>\n",
       "<polygon fill=\"none\" points=\"351,-249.5 351,-295.5 710,-295.5 710,-249.5 351,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"458\" y=\"-268.8\">document_embeddings: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"565,-249.5 565,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"565,-272.5 620,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"620,-249.5 620,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"665\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"620,-272.5 710,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"665\" y=\"-257.3\">(None, 1, 50)</text>\n",
       "</g>\n",
       "<!-- 139958347294424&#45;&gt;139958347294872 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139958347294424-&gt;139958347294872</title>\n",
       "<path d=\"M530.5,-332.366C530.5,-324.152 530.5,-314.658 530.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"534,-305.607 530.5,-295.607 527,-305.607 534,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139958347294760 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139958347294760</title>\n",
       "<polygon fill=\"none\" points=\"74.5,-166.5 74.5,-212.5 342.5,-212.5 342.5,-166.5 74.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"136\" y=\"-185.8\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"197.5,-166.5 197.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"197.5,-189.5 252.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"252.5,-166.5 252.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-197.3\">(None, 4, 50)</text>\n",
       "<polyline fill=\"none\" points=\"252.5,-189.5 342.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-174.3\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 139958347294480&#45;&gt;139958347294760 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139958347294480-&gt;139958347294760</title>\n",
       "<path d=\"M177.977,-249.366C182.421,-240.794 187.588,-230.83 192.393,-221.563\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"195.541,-223.096 197.037,-212.607 189.327,-219.873 195.541,-223.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139958347442832 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139958347442832</title>\n",
       "<polygon fill=\"none\" points=\"382,-166.5 382,-212.5 637,-212.5 637,-166.5 382,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"437\" y=\"-185.8\">flatten_6: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"492,-166.5 492,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"519.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"492,-189.5 547,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"519.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"547,-166.5 547,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592\" y=\"-197.3\">(None, 1, 50)</text>\n",
       "<polyline fill=\"none\" points=\"547,-189.5 637,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592\" y=\"-174.3\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 139958347294872&#45;&gt;139958347442832 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139958347294872-&gt;139958347442832</title>\n",
       "<path d=\"M524.762,-249.366C522.609,-241.062 520.117,-231.451 517.779,-222.434\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"521.129,-221.408 515.231,-212.607 514.353,-223.165 521.129,-221.408\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139958347440480 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139958347440480</title>\n",
       "<polygon fill=\"none\" points=\"192.5,-83.5 192.5,-129.5 524.5,-129.5 524.5,-83.5 192.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-102.8\">average_4: Average</text>\n",
       "<polyline fill=\"none\" points=\"317.5,-83.5 317.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"317.5,-106.5 372.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"372.5,-83.5 372.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-114.3\">[(None, 50), (None, 50)]</text>\n",
       "<polyline fill=\"none\" points=\"372.5,-106.5 524.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-91.3\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 139958347294760&#45;&gt;139958347440480 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139958347294760-&gt;139958347440480</title>\n",
       "<path d=\"M249.488,-166.366C267.76,-156.5 289.448,-144.788 308.649,-134.419\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"310.425,-137.438 317.561,-129.607 307.099,-131.279 310.425,-137.438\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139958347442832&#45;&gt;139958347440480 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139958347442832-&gt;139958347440480</title>\n",
       "<path d=\"M468.239,-166.366C449.845,-156.5 428.012,-144.788 408.683,-134.419\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"410.178,-131.25 399.712,-129.607 406.869,-137.418 410.178,-131.25\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139958343975208 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139958343975208</title>\n",
       "<polygon fill=\"none\" points=\"232,-0.5 232,-46.5 485,-46.5 485,-0.5 232,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283\" y=\"-19.8\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"334,-0.5 334,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"334,-23.5 389,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"389,-0.5 389,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"437\" y=\"-31.3\">(None, 50)</text>\n",
       "<polyline fill=\"none\" points=\"389,-23.5 485,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"437\" y=\"-8.3\">(None, 28510)</text>\n",
       "</g>\n",
       "<!-- 139958347440480&#45;&gt;139958343975208 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139958347440480-&gt;139958343975208</title>\n",
       "<path d=\"M358.5,-83.3664C358.5,-75.1516 358.5,-65.6579 358.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"362,-56.6068 358.5,-46.6068 355,-56.6069 362,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(pvdm,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.420833333333334"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_iter_second = 50\n",
    "num_iterations = (nb_samples * NB_EPOCHS)\n",
    "\n",
    "rough_time_in_hours = (num_iterations / avg_iter_second) / (60 * 60)\n",
    "rough_time_in_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xs = []\n",
    "# ys = []\n",
    "\n",
    "# for x, y in generate_data(document_sequences=sequences, window_size=CONTEXT_WINDOW_SIZE, vocabulary_size=len(tokenizer.word_index)+1):\n",
    "#     xs.append(x)\n",
    "#     ys.append(y)\n",
    "# xs[0],ys[0],xs[1],ys[1],xs[2],xs[3],xs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26887it [03:30, 131.99it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(NB_EPOCHS):\n",
    "    loss = 0.\n",
    "    for x, y in tqdm(generate_data(document_sequences=sequences, window_size=CONTEXT_WINDOW_SIZE, vocabulary_size=VOCAB_SIZE)):\n",
    "        \n",
    "        loss += pvdm.train_on_batch(x, y)\n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = PATH_TO_SAVED_MODELS+\"/doc2vec-pvdm-model-{}.p\".format(DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvdm.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_word_vectors_file = VECTORS_DATA_ROOT+'/doc2vec-pvdm-word-vectors-{}.txt'.format(DIM)\n",
    "f = open(path_to_word_vectors_file ,'w')\n",
    "f.write(' '.join([str(V-1), str(DIM)]))\n",
    "f.write('\\n')\n",
    "word_embeddings =  pvdm.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    str_vec = ' '.join(map(str, list(word_embeddings[i, :])))\n",
    "    f.write('{} {}\\n'.format(word, str_vec))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(path_to_word_vectors_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write the document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_document_vectors_file = VECTORS_DATA_ROOT+'/doc2vec-pvdm-document-vectors-{}.txt'.format(DIM)\n",
    "f = open(path_to_document_vectors_file ,'w')\n",
    "f.write(' '.join([str(NB_DOCS), str(DIM)]))\n",
    "f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_embeddings =  pvdm.get_weights()[0]\n",
    "doc_embeddings = pvdm.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one weight for the bias and another one for each document\n",
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,document_id in enumerate(doc_embeddings):\n",
    "    if i == 0:\n",
    "        continue # bias\n",
    "        \n",
    "    # document_embedding i refers to document i-1\n",
    "    \n",
    "    document_title = docs_df.iloc[i-1]['title']\n",
    "    document_vector = doc_embeddings[i]\n",
    "    \n",
    "    f.write(str(i))\n",
    "    f.write(' ')\n",
    "    f.write(' '.join(map(str, list(document_vector))))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's see if the pseudo_documents are good representations for the documents.\n",
    "\n",
    "One way to find this is to fetch the most similar documents to a given documentï¿¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gensim_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_document_vectors_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_title(document_index, source_dataframe):\n",
    "    return source_dataframe.iloc[document_index]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tags(document_index, source_dataframe):\n",
    "    return ','.join(source_dataframe.iloc[document_index]['unique_tags'].split(',')[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(document_index,source_dataframe,gensim_w2v_model):\n",
    "    tuples = gensim_w2v_model.most_similar(positive=[str(document_index+1)])\n",
    "    \n",
    "    print(\"title for source document is: {}\".format(get_title(document_index, source_dataframe)))\n",
    "    \n",
    "    return [ (index, get_title(int(index),source_dataframe), similarity) for index,similarity in tuples ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(227,docs_df,gensim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(62,docs_df,gensim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(248,docs_df,gensim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['can'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
