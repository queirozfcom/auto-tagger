{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adapted from: https://github.com/nzw0301/keras-examples/blob/master/CBoW.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os,re,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "import pickle\n",
    "import string\n",
    "import gensim\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input,Lambda, Dense, Concatenate, Average,Flatten\n",
    "from keras.layers.merge import Dot\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_dir = os.path.join(os.getcwd(), os.pardir, '../src')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%aimport data.movielens_20m_imdb\n",
    "%aimport utils.dataframes\n",
    "\n",
    "from data.movielens_20m_imdb import load_or_get_from_cache\n",
    "from utils.dataframes import sample_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VECTORS_DATA_ROOT = os.path.abspath(\"../../data/vectors/movielens-ml20m-imdb/\")\n",
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../data/interim/movielens-ml20m-imdb/\")\n",
    "ML_ROOT = \"/media/felipe/SAMSUNG/movielens/ml-20m/\"\n",
    "IMDB_ROOT = \"/media/felipe/SAMSUNG/imdb/\"\n",
    "\n",
    "PATH_TO_SAVED_MODELS = os.path.abspath('../../models/')\n",
    "\n",
    "PATH_TO_MOVIES = ML_ROOT + \"/movies.csv\"\n",
    "PATH_TO_TAG_ASSIGNMENTS = ML_ROOT + \"/tags.csv\"\n",
    "PATH_TO_MOVIE_PLOTS = IMDB_ROOT+\"/plot.list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_TEXT_LENGTH = 500\n",
    "NB_DOCS = 250\n",
    "DIM = 50\n",
    "CONTEXT_WINDOW_SIZE = 4\n",
    "# STOPWORDS BREAK W2V!!!!\n",
    "STOPWORDS = None\n",
    "\n",
    "TOKENIZER_FILTERS = string.punctuation+\"'\"\n",
    "NB_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_df = load_or_get_from_cache(PATH_TO_MOVIES,PATH_TO_TAG_ASSIGNMENTS,PATH_TO_MOVIE_PLOTS,INTERIM_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove this for production\n",
    "docs_df = sample_rows(docs_df,NB_DOCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>unique_tags</th>\n",
       "      <th>num_users</th>\n",
       "      <th>num_unique_tags</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>4878</td>\n",
       "      <td>68358</td>\n",
       "      <td>Star Trek (2009)</td>\n",
       "      <td>star-trek,time-travel,scifi,space,action,alter...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>25</td>\n",
       "      <td>On the day of James Kirk's birth, his father d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>4237</td>\n",
       "      <td>48774</td>\n",
       "      <td>Children of Men (2006)</td>\n",
       "      <td>dystopia,apocalypse,atmospheric,scifi,survival...</td>\n",
       "      <td>144.0</td>\n",
       "      <td>25</td>\n",
       "      <td>The world's youngest citizen has just died at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>535</td>\n",
       "      <td>1222</td>\n",
       "      <td>Full Metal Jacket (1987)</td>\n",
       "      <td>stanley-kubrick,vietnam-war,vietnam,antiwar,mi...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>25</td>\n",
       "      <td>A two-segment look at the effect of the milita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>534</td>\n",
       "      <td>1219</td>\n",
       "      <td>Psycho (1960)</td>\n",
       "      <td>alfred-hitchcock,psychology,classic,suspensefu...</td>\n",
       "      <td>124.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Phoenix officeworker Marion Crane is fed up wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>4305</td>\n",
       "      <td>50872</td>\n",
       "      <td>Ratatouille (2007)</td>\n",
       "      <td>pixar,animation,cooking,disney,paris,rats,food...</td>\n",
       "      <td>114.0</td>\n",
       "      <td>25</td>\n",
       "      <td>A rat named Remy dreams of becoming a great Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>465</td>\n",
       "      <td>1036</td>\n",
       "      <td>Die Hard (1988)</td>\n",
       "      <td>bruce-willis,action,humorous,alan-rickman,chri...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>25</td>\n",
       "      <td>NYPD cop John McClane goes on a Christmas vaca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4219</td>\n",
       "      <td>48385</td>\n",
       "      <td>Borat: Cultural Learnings of America for Make ...</td>\n",
       "      <td>satire,mockumentary,social-commentary,controve...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Borat Sagdiyev is a TV reporter of a popular s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1330</td>\n",
       "      <td>3052</td>\n",
       "      <td>Dogma (1999)</td>\n",
       "      <td>satire,kevin-smith,religion,jay-and-silent-bob...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>25</td>\n",
       "      <td>An abortion clinic worker with a special herit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>4376</td>\n",
       "      <td>53125</td>\n",
       "      <td>Pirates of the Caribbean: At World's End (2007)</td>\n",
       "      <td>johnny-depp,pirates,adventure,keira-knightley,...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>25</td>\n",
       "      <td>After Elizabeth, Will, and Captain Barbossa re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>425</td>\n",
       "      <td>953</td>\n",
       "      <td>It's a Wonderful Life (1946)</td>\n",
       "      <td>christmas,classic,heartwarming,james-stewart,b...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>25</td>\n",
       "      <td>George Bailey has spent his entire life giving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>4340</td>\n",
       "      <td>52281</td>\n",
       "      <td>Grindhouse (2007)</td>\n",
       "      <td>quentin-tarantino,robert-rodriguez,zombies,ser...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>25</td>\n",
       "      <td>A double-bill of thrillers that recall both fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4477</td>\n",
       "      <td>55290</td>\n",
       "      <td>Gone Baby Gone (2007)</td>\n",
       "      <td>morgan-freeman,casey-affleck,police,twist,mora...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>25</td>\n",
       "      <td>When 4 year old Amanda McCready disappears fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>3047</td>\n",
       "      <td>7360</td>\n",
       "      <td>Dawn of the Dead (2004)</td>\n",
       "      <td>zombies,postapocalyptic,zombie,remake,nudity-t...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Ana goes home to her peaceful suburban residen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1699</td>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>ben-stiller,robert-de-niro,comedy,owen-wilson,...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>25</td>\n",
       "      <td>A Jewish male nurse plans to ask his live-in g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2407</td>\n",
       "      <td>5673</td>\n",
       "      <td>Punch-Drunk Love (2002)</td>\n",
       "      <td>adam-sandler,paul-thomas-anderson,quirky,phili...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Barry Egan hates himself and hates his life. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2337</td>\n",
       "      <td>5464</td>\n",
       "      <td>Road to Perdition (2002)</td>\n",
       "      <td>tom-hanks,organized-crime,revenge,jude-law,193...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1931. Mike Sullivan and Connor Rooney are two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>828</td>\n",
       "      <td>1945</td>\n",
       "      <td>On the Waterfront (1954)</td>\n",
       "      <td>black-and-white,marlon-brando,oscar-best-pictu...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Terry Malloy dreams about being a prize fighte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>730</td>\n",
       "      <td>1673</td>\n",
       "      <td>Boogie Nights (1997)</td>\n",
       "      <td>dark-comedy,drugs,1970s,ensemble-cast,philip-s...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Adult film director Jack Horner is always on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4746</td>\n",
       "      <td>63062</td>\n",
       "      <td>Changeling (2008)</td>\n",
       "      <td>angelina-jolie,based-on-a-true-story,clint-eas...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Los Angeles, 1928. A single mother returns fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2781</td>\n",
       "      <td>6754</td>\n",
       "      <td>Underworld (2003)</td>\n",
       "      <td>vampires,vampire,werewolves,heroine-in-tight-s...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>25</td>\n",
       "      <td>A war has been raging between the Vampires and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  movie_id                                              title  \\\n",
       "227   4878     68358                                   Star Trek (2009)   \n",
       "148   4237     48774                             Children of Men (2006)   \n",
       "82     535      1222                           Full Metal Jacket (1987)   \n",
       "62     534      1219                                      Psycho (1960)   \n",
       "189   4305     50872                                 Ratatouille (2007)   \n",
       "18     465      1036                                    Die Hard (1988)   \n",
       "19    4219     48385  Borat: Cultural Learnings of America for Make ...   \n",
       "81    1330      3052                                       Dogma (1999)   \n",
       "177   4376     53125    Pirates of the Caribbean: At World's End (2007)   \n",
       "17     425       953                       It's a Wonderful Life (1946)   \n",
       "160   4340     52281                                  Grindhouse (2007)   \n",
       "70    4477     55290                              Gone Baby Gone (2007)   \n",
       "234   3047      7360                            Dawn of the Dead (2004)   \n",
       "140   1699      3948                            Meet the Parents (2000)   \n",
       "198   2407      5673                            Punch-Drunk Love (2002)   \n",
       "106   2337      5464                           Road to Perdition (2002)   \n",
       "58     828      1945                           On the Waterfront (1954)   \n",
       "96     730      1673                               Boogie Nights (1997)   \n",
       "24    4746     63062                                  Changeling (2008)   \n",
       "175   2781      6754                                  Underworld (2003)   \n",
       "\n",
       "                                           unique_tags  num_users  \\\n",
       "227  star-trek,time-travel,scifi,space,action,alter...      168.0   \n",
       "148  dystopia,apocalypse,atmospheric,scifi,survival...      144.0   \n",
       "82   stanley-kubrick,vietnam-war,vietnam,antiwar,mi...      126.0   \n",
       "62   alfred-hitchcock,psychology,classic,suspensefu...      124.0   \n",
       "189  pixar,animation,cooking,disney,paris,rats,food...      114.0   \n",
       "18   bruce-willis,action,humorous,alan-rickman,chri...      108.0   \n",
       "19   satire,mockumentary,social-commentary,controve...       97.0   \n",
       "81   satire,kevin-smith,religion,jay-and-silent-bob...       87.0   \n",
       "177  johnny-depp,pirates,adventure,keira-knightley,...       79.0   \n",
       "17   christmas,classic,heartwarming,james-stewart,b...       74.0   \n",
       "160  quentin-tarantino,robert-rodriguez,zombies,ser...       70.0   \n",
       "70   morgan-freeman,casey-affleck,police,twist,mora...       65.0   \n",
       "234  zombies,postapocalyptic,zombie,remake,nudity-t...       63.0   \n",
       "140  ben-stiller,robert-de-niro,comedy,owen-wilson,...       61.0   \n",
       "198  adam-sandler,paul-thomas-anderson,quirky,phili...       61.0   \n",
       "106  tom-hanks,organized-crime,revenge,jude-law,193...       59.0   \n",
       "58   black-and-white,marlon-brando,oscar-best-pictu...       55.0   \n",
       "96   dark-comedy,drugs,1970s,ensemble-cast,philip-s...       55.0   \n",
       "24   angelina-jolie,based-on-a-true-story,clint-eas...       55.0   \n",
       "175  vampires,vampire,werewolves,heroine-in-tight-s...       55.0   \n",
       "\n",
       "     num_unique_tags                                               plot  \n",
       "227               25  On the day of James Kirk's birth, his father d...  \n",
       "148               25  The world's youngest citizen has just died at ...  \n",
       "82                25  A two-segment look at the effect of the milita...  \n",
       "62                25  Phoenix officeworker Marion Crane is fed up wi...  \n",
       "189               25  A rat named Remy dreams of becoming a great Fr...  \n",
       "18                25  NYPD cop John McClane goes on a Christmas vaca...  \n",
       "19                25  Borat Sagdiyev is a TV reporter of a popular s...  \n",
       "81                25  An abortion clinic worker with a special herit...  \n",
       "177               25  After Elizabeth, Will, and Captain Barbossa re...  \n",
       "17                25  George Bailey has spent his entire life giving...  \n",
       "160               25  A double-bill of thrillers that recall both fi...  \n",
       "70                25  When 4 year old Amanda McCready disappears fro...  \n",
       "234               25  Ana goes home to her peaceful suburban residen...  \n",
       "140               25  A Jewish male nurse plans to ask his live-in g...  \n",
       "198               25  Barry Egan hates himself and hates his life. T...  \n",
       "106               25  1931. Mike Sullivan and Connor Rooney are two ...  \n",
       "58                25  Terry Malloy dreams about being a prize fighte...  \n",
       "96                25  Adult film director Jack Horner is always on t...  \n",
       "24                25  Los Angeles, 1928. A single mother returns fro...  \n",
       "175               25  A war has been raging between the Vampires and...  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df.sort_values('num_users',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = docs_df['plot'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=TOKENIZER_FILTERS)\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = sum(len(seq) for seq in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62430"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total size of the corpus, in words\n",
    "# this will be the number of iterations be epoch\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the document marker is just added as another word to every context\n",
    "# note that it will be averaged with the other words in the context\n",
    "def generate_data(document_sequences, window_size, vocabulary_size):\n",
    "    \n",
    "    maxlen = window_size*2\n",
    "    \n",
    "    for doc_index, word_sequence in enumerate(document_sequences):\n",
    "                  \n",
    "        text_length = len(word_sequence)\n",
    "        \n",
    "        for index_in_document,word in enumerate(word_sequence):\n",
    "                  \n",
    "            # these are the words in the context\n",
    "            contexts = []\n",
    "               \n",
    "            # these are the target words (which we'll predict using the context)\n",
    "            labels = []\n",
    "        \n",
    "            context_start = index_in_document - window_size           \n",
    "            context_end   = index_in_document + window_size\n",
    "            \n",
    "            context_words = []\n",
    "            \n",
    "            for index_in_context in range(context_start, context_end+1):\n",
    "                if index_in_document != index_in_context: # index_in_context is the target word\n",
    "                    if index_in_context >= 0 and index_in_context < text_length: # inner_index must be a valid index\n",
    "                        context_word = word_sequence[index_in_context]\n",
    "                        context_words.append(context_word)\n",
    "                                                                     \n",
    "            labels.append(word)\n",
    "                        \n",
    "            x1 = sequence.pad_sequences([context_words], maxlen=maxlen)\n",
    "                       \n",
    "            # needs to be at least one or the index will be interpreted as a mask    \n",
    "            x2 = np.array([doc_index+1])\n",
    "                                   \n",
    "            x = [x1,x2]\n",
    "            \n",
    "            y = np_utils.to_categorical(labels,vocabulary_size)           \n",
    "            \n",
    "#             print(\"contexts is: {}\".format(contexts))\n",
    "#             print(\"x1 is: {}\".format(x1.shape))\n",
    "#             print(\"x2 is: {}\".format(x2.shape))\n",
    "#             print(\"y is: {}\".format(y.shape))\n",
    "#             return\n",
    "            \n",
    "            yield (x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = len(tokenizer.word_index)+1\n",
    "\n",
    "input1 = Input(shape=(CONTEXT_WINDOW_SIZE*2,))\n",
    "x1 = Embedding(V,output_dim=DIM,name=\"word_embeddings\")(input1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "input2 = Input(shape=(1,))\n",
    "x2 = Embedding(NB_DOCS+1,output_dim=DIM,name=\"document_embeddings\")(input2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "x = Concatenate()([x1,x2])\n",
    "\n",
    "outputs = Dense(V,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvdm = Model(inputs=[input1,input2],outputs=outputs)\n",
    "pvdm.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"387pt\" viewBox=\"0.00 0.00 718.00 387.00\" width=\"718pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-383 714,-383 714,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140372262898600 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140372262898600</title>\n",
       "<polygon fill=\"none\" points=\"42,-332.5 42,-378.5 291,-378.5 291,-332.5 42,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"104.5\" y=\"-351.8\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"167,-332.5 167,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167,-355.5 222,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-332.5 222,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-363.3\">(None, 8)</text>\n",
       "<polyline fill=\"none\" points=\"222,-355.5 291,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256.5\" y=\"-340.3\">(None, 8)</text>\n",
       "</g>\n",
       "<!-- 140372262897984 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140372262897984</title>\n",
       "<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 333,-295.5 333,-249.5 0,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94\" y=\"-268.8\">word_embeddings: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"188,-249.5 188,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"188,-272.5 243,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"243,-249.5 243,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-280.3\">(None, 8)</text>\n",
       "<polyline fill=\"none\" points=\"243,-272.5 333,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288\" y=\"-257.3\">(None, 8, 50)</text>\n",
       "</g>\n",
       "<!-- 140372262898600&#45;&gt;140372262897984 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140372262898600-&gt;140372262897984</title>\n",
       "<path d=\"M166.5,-332.366C166.5,-324.152 166.5,-314.658 166.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"170,-305.607 166.5,-295.607 163,-305.607 170,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140372262899104 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140372262899104</title>\n",
       "<polygon fill=\"none\" points=\"406,-332.5 406,-378.5 655,-378.5 655,-332.5 406,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468.5\" y=\"-351.8\">input_2: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"531,-332.5 531,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"531,-355.5 586,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"586,-332.5 586,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620.5\" y=\"-363.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"586,-355.5 655,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620.5\" y=\"-340.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 140372262874360 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140372262874360</title>\n",
       "<polygon fill=\"none\" points=\"351,-249.5 351,-295.5 710,-295.5 710,-249.5 351,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"458\" y=\"-268.8\">document_embeddings: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"565,-249.5 565,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"565,-272.5 620,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"620,-249.5 620,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"665\" y=\"-280.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"620,-272.5 710,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"665\" y=\"-257.3\">(None, 1, 50)</text>\n",
       "</g>\n",
       "<!-- 140372262899104&#45;&gt;140372262874360 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140372262899104-&gt;140372262874360</title>\n",
       "<path d=\"M530.5,-332.366C530.5,-324.152 530.5,-314.658 530.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"534,-305.607 530.5,-295.607 527,-305.607 534,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140372262896472 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140372262896472</title>\n",
       "<polygon fill=\"none\" points=\"84,-166.5 84,-212.5 339,-212.5 339,-166.5 84,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-185.8\">flatten_1: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"194,-166.5 194,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"194,-189.5 249,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"249,-166.5 249,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-197.3\">(None, 8, 50)</text>\n",
       "<polyline fill=\"none\" points=\"249,-189.5 339,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-174.3\">(None, 400)</text>\n",
       "</g>\n",
       "<!-- 140372262897984&#45;&gt;140372262896472 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140372262897984-&gt;140372262896472</title>\n",
       "<path d=\"M178.796,-249.366C183.559,-240.794 189.094,-230.83 194.243,-221.563\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"197.421,-223.048 199.218,-212.607 191.302,-219.649 197.421,-223.048\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140372262762536 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140372262762536</title>\n",
       "<polygon fill=\"none\" points=\"380,-166.5 380,-212.5 635,-212.5 635,-166.5 380,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"435\" y=\"-185.8\">flatten_2: Flatten</text>\n",
       "<polyline fill=\"none\" points=\"490,-166.5 490,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"490,-189.5 545,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"517.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"545,-166.5 545,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"590\" y=\"-197.3\">(None, 1, 50)</text>\n",
       "<polyline fill=\"none\" points=\"545,-189.5 635,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"590\" y=\"-174.3\">(None, 50)</text>\n",
       "</g>\n",
       "<!-- 140372262874360&#45;&gt;140372262762536 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140372262874360-&gt;140372262762536</title>\n",
       "<path d=\"M524.215,-249.366C521.857,-241.062 519.128,-231.451 516.568,-222.434\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"519.876,-221.27 513.777,-212.607 513.142,-223.183 519.876,-221.27\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140372262762480 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140372262762480</title>\n",
       "<polygon fill=\"none\" points=\"169,-83.5 169,-129.5 550,-129.5 550,-83.5 169,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"253\" y=\"-102.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"337,-83.5 337,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"337,-106.5 392,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"392,-83.5 392,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"471\" y=\"-114.3\">[(None, 400), (None, 50)]</text>\n",
       "<polyline fill=\"none\" points=\"392,-106.5 550,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"471\" y=\"-91.3\">(None, 450)</text>\n",
       "</g>\n",
       "<!-- 140372262896472&#45;&gt;140372262762480 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140372262896472-&gt;140372262762480</title>\n",
       "<path d=\"M251.942,-166.366C269.97,-156.5 291.369,-144.788 310.314,-134.419\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"312.015,-137.478 319.107,-129.607 308.655,-131.338 312.015,-137.478\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140372262762536&#45;&gt;140372262762480 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140372262762536-&gt;140372262762480</title>\n",
       "<path d=\"M467.058,-166.366C449.03,-156.5 427.631,-144.788 408.686,-134.419\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"410.345,-131.338 399.893,-129.607 406.985,-137.478 410.345,-131.338\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140372262722752 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140372262722752</title>\n",
       "<polygon fill=\"none\" points=\"236.5,-0.5 236.5,-46.5 482.5,-46.5 482.5,-0.5 236.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287.5\" y=\"-19.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"338.5,-0.5 338.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"338.5,-23.5 393.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"393.5,-0.5 393.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"438\" y=\"-31.3\">(None, 450)</text>\n",
       "<polyline fill=\"none\" points=\"393.5,-23.5 482.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"438\" y=\"-8.3\">(None, 8980)</text>\n",
       "</g>\n",
       "<!-- 140372262762480&#45;&gt;140372262722752 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140372262762480-&gt;140372262722752</title>\n",
       "<path d=\"M359.5,-83.3664C359.5,-75.1516 359.5,-65.6579 359.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"363,-56.6068 359.5,-46.6068 356,-56.6069 363,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(pvdm,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4683333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_iter_second = 50\n",
    "num_iterations = (nb_samples * NB_EPOCHS)\n",
    "\n",
    "rough_time_in_hours = (num_iterations / avg_iter_second) / (60 * 60)\n",
    "rough_time_in_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xs = []\n",
    "# ys = []\n",
    "\n",
    "# for x, y in generate_data(document_sequences=sequences, window_size=CONTEXT_WINDOW_SIZE, vocabulary_size=len(tokenizer.word_index)+1):\n",
    "#     xs.append(x)\n",
    "#     ys.append(y)\n",
    "# xs[0],ys[0],xs[1],ys[1],xs[2],xs[3],xs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [18:46, 57.17it/s]\n",
      "6it [00:00, 59.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 497002.598744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [18:00, 57.79it/s]\n",
      "6it [00:00, 58.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 469230.909695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [18:02, 57.69it/s]\n",
      "6it [00:00, 58.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 467477.507672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [17:48, 59.01it/s]\n",
      "6it [00:00, 59.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 464970.633603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [17:48, 58.45it/s]\n",
      "6it [00:00, 59.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 462433.857839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [17:50, 58.33it/s]\n",
      "6it [00:00, 51.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 459878.768083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [18:27, 56.40it/s]\n",
      "6it [00:00, 55.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 457281.069936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [18:18, 56.83it/s]\n",
      "7it [00:00, 61.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 454490.672738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [17:59, 57.83it/s]\n",
      "6it [00:00, 58.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 452001.210965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62430it [18:00, 57.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 449520.108989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NB_EPOCHS):\n",
    "    loss = 0.\n",
    "    for x, y in tqdm(generate_data(document_sequences=sequences, window_size=CONTEXT_WINDOW_SIZE, vocabulary_size=V)):\n",
    "        \n",
    "        loss += pvdm.train_on_batch(x, y)\n",
    "    print(epoch, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = PATH_TO_SAVED_MODELS+\"/doc2vec-pvdm-model-{}.p\".format(DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvdm.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_word_vectors_file = VECTORS_DATA_ROOT+'/doc2vec-pvdm-word-vectors-{}.txt'.format(DIM)\n",
    "f = open(path_to_word_vectors_file ,'w')\n",
    "f.write(' '.join([str(V-1), str(DIM)]))\n",
    "f.write('\\n')\n",
    "word_embeddings =  pvdm.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    str_vec = ' '.join(map(str, list(word_embeddings[i, :])))\n",
    "    f.write('{} {}\\n'.format(word, str_vec))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(path_to_word_vectors_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beatrice', 0.7912397384643555),\n",
       " ('whose', 0.7872059941291809),\n",
       " ('unknown', 0.7792308926582336),\n",
       " ('ryan', 0.7753610610961914),\n",
       " ('steffi', 0.7629479169845581),\n",
       " ('throat', 0.75922691822052),\n",
       " ('joining', 0.7590861916542053),\n",
       " ('briegleb', 0.7498750686645508),\n",
       " ('rats', 0.7403017282485962),\n",
       " ('mrs', 0.7386329770088196)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write the document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_document_vectors_file = VECTORS_DATA_ROOT+'/doc2vec-pvdm-document-vectors-{}.txt'.format(DIM)\n",
    "f = open(path_to_document_vectors_file ,'w')\n",
    "f.write(' '.join([str(NB_DOCS), str(DIM)]))\n",
    "f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_embeddings =  pvdm.get_weights()[0]\n",
    "doc_embeddings = pvdm.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8980, 50)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one weight for the bias and another one for each document\n",
    "doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,document_id in enumerate(doc_embeddings):\n",
    "    if i == 0:\n",
    "        continue # bias\n",
    "        \n",
    "    # document_embedding i refers to document i-1\n",
    "    \n",
    "    document_title = docs_df.iloc[i-1]['title']\n",
    "    document_vector = doc_embeddings[i]\n",
    "    \n",
    "    f.write(str(i))\n",
    "    f.write(' ')\n",
    "    f.write(' '.join(map(str, list(document_vector))))\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's see if the pseudo_documents are good representations for the documents.\n",
    "\n",
    "One way to find this is to fetch the most similar documents to a given document￼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_document_vectors_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_title(document_index, source_dataframe):\n",
    "    return source_dataframe.iloc[document_index]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tags(document_index, source_dataframe):\n",
    "    return ','.join(source_dataframe.iloc[document_index]['unique_tags'].split(',')[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(document_index,source_dataframe,gensim_w2v_model):\n",
    "    tuples = gensim_w2v_model.most_similar(positive=[str(document_index+1)])\n",
    "    \n",
    "    print(\"title for source document is: {}\".format(get_title(document_index, source_dataframe)))\n",
    "    \n",
    "    return [ (index, get_title(int(index),source_dataframe), similarity) for index,similarity in tuples ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title for source document is: Star Trek (2009)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('218', 'Severance (2006)', 0.7563555836677551),\n",
       " ('79', 'Jeffrey (1995)', 0.7415332198143005),\n",
       " ('213', 'Jagged Edge (1985)', 0.7302216291427612),\n",
       " ('62', 'Psycho (1960)', 0.7292182445526123),\n",
       " ('83', 'Eyes of Laura Mars (1978)', 0.7071167826652527),\n",
       " ('65', 'Coldblooded (1995)', 0.681449294090271),\n",
       " ('59', 'Rising Sun (1993)', 0.6784266233444214),\n",
       " ('245',\n",
       "  'Prison Terminal: The Last Days of Private Jack Hall (2013)',\n",
       "  0.674137532711029),\n",
       " ('229', 'Team America: World Police (2004)', 0.6681739687919617),\n",
       " ('15', 'Princesas (2005)', 0.6669789552688599)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(227,docs_df,gensim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title for source document is: Psycho (1960)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('248', 'From the Journals of Jean Seberg (1995)', 0.7716283202171326),\n",
       " ('132',\n",
       "  'Cameraman: The Life and Work of Jack Cardiff (2010)',\n",
       "  0.7481696605682373),\n",
       " ('127', 'Fatal Beauty (1987)', 0.7336030006408691),\n",
       " ('84', 'Gordy (1995)', 0.7163759469985962),\n",
       " ('91',\n",
       "  'Once in a Lifetime: The Extraordinary Story of the New York Cosmos (2006)',\n",
       "  0.6946930885314941),\n",
       " ('202', 'Limbo (1999)', 0.6826401948928833),\n",
       " ('235', 'Key Largo (1948)', 0.6813738346099854),\n",
       " ('196', 'Charly (2002)', 0.650294303894043),\n",
       " ('209', 'Grease (1978)', 0.6348586082458496),\n",
       " ('57', 'Carrie (1952)', 0.6332916021347046)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(62,docs_df,gensim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title for source document is: From the Journals of Jean Seberg (1995)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('223', 'Ikiru (1952)', 0.8042960166931152),\n",
       " ('161', 'Zero Effect (1998)', 0.7805737257003784),\n",
       " ('44', 'Click (2006)', 0.7766533493995667),\n",
       " ('29', 'Billy Bathgate (1991)', 0.7697432041168213),\n",
       " ('101', 'Sayonara (1957)', 0.7638599276542664),\n",
       " ('214', 'Mirage (1965)', 0.7635664343833923),\n",
       " ('16', 'Local Hero (1983)', 0.7534139156341553),\n",
       " ('78', 'My Winnipeg (2007)', 0.7447584867477417),\n",
       " ('183', '7 Khoon Maaf (2011)', 0.7432988286018372),\n",
       " ('213', 'Jagged Edge (1985)', 0.7400705218315125)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(248,docs_df,gensim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['can'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
