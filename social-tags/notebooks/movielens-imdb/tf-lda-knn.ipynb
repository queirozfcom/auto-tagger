{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import sklearn\n",
    "import sys\n",
    "import string\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV,ParameterGrid, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier,NearestNeighbors\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(os.getcwd(), os.pardir, '../src')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport data.movielens_20m_imdb\n",
    "%aimport helpers.labels,helpers.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.movielens_20m_imdb import load_or_get_from_cache\n",
    "from helpers.labels import truncate_labels\n",
    "from helpers.neighbours import get_predicted_labels_from_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../data/interim/movielens-ml20m-imdb/\")\n",
    "ML_ROOT = \"/media/felipe/SAMSUNG/movielens/ml-20m/\"\n",
    "IMDB_ROOT = \"/media/felipe/SAMSUNG/imdb/\"\n",
    "\n",
    "PATH_TO_MOVIES = ML_ROOT + \"/movies.csv\"\n",
    "PATH_TO_TAG_ASSIGNMENTS = ML_ROOT + \"/tags.csv\"\n",
    "PATH_TO_MOVIE_PLOTS = IMDB_ROOT+\"/plot.list\"\n",
    "\n",
    "# CONFIGS\n",
    "MAX_NB_WORDS = 4000\n",
    "NB_NEIGHBOURS = 3\n",
    "DISTANCE_METRIC='cosine'\n",
    "WEIGHTS='distance'\n",
    "PREPROC=None\n",
    "STOP_WORDS='english'\n",
    "NB_COMPONENTS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = load_or_get_from_cache(PATH_TO_MOVIES,PATH_TO_TAG_ASSIGNMENTS,PATH_TO_MOVIE_PLOTS,INTERIM_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = docs_df['plot'].values\n",
    "labelsets = docs_df[\"unique_tags\"].map(lambda tagstring: tagstring.split(\",\")).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labelsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't put this into a pipeline because NearestNeighbors is not a normal classifier, I think\n",
    "# I need to customize the pipeline object to be able to call the methods for that class.\n",
    "vect = CountVectorizer(max_features=MAX_NB_WORDS, preprocessor=PREPROC, stop_words=STOP_WORDS)\n",
    "\n",
    "# arsg taken from http://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n",
    "lda = LatentDirichletAllocation(n_components=NB_COMPONENTS, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=NB_NEIGHBOURS, metric=DISTANCE_METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,labelsets,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=3, p=2, radius=1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_train = lda.fit_transform(X_train)\n",
    "nbrs.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "X_test = vect.transform(X_test)\n",
    "X_test = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4734, 30), (1578, 30))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4734, 16787), (1578, 16787))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1578, 3), (1578, 3), (1578, 3, 16787))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = []\n",
    "y_trues = []\n",
    "\n",
    "distances_matrix, indices_matrix = nbrs.kneighbors(X_test)\n",
    "\n",
    "neighbour_labels_tensor = y_train[indices_matrix]    \n",
    "\n",
    "distances_matrix.shape, indices_matrix.shape, neighbour_labels_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1578/1578 [01:52<00:00, 14.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(distances_matrix.shape[0])):\n",
    "          \n",
    "    distances = distances_matrix[i].ravel()  \n",
    "        \n",
    "    neighbour_labels = neighbour_labels_tensor[i]\n",
    "       \n",
    "    y_pred = get_predicted_labels_from_neighbours(neighbour_labels, distances)\n",
    "    \n",
    "    y_true = y_test[i]\n",
    "    \n",
    "    y_preds.append(y_pred)\n",
    "    y_trues.append(y_true)\n",
    "    \n",
    "y_preds = np.array(y_preds)\n",
    "y_trues = np.array(y_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012333420433760126"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_trues,y_preds,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: max miss albert girls maya amanda network electric ginger mall\n",
      "Topic #1: david jake elizabeth john holly casino vince zoo diane jsackste\n",
      "Topic #2: war american world army men president qv government british com\n",
      "Topic #3: school high park cindy football party seth prom angel friends\n",
      "Topic #4: maggie fiona fairy nathan swamp pig phillips shrek jonah twin\n",
      "Topic #5: sam larry annie jason terry loh carol edu doc radio\n",
      "Topic #6: mike ted marcus russian hank pat barbara jennifer spy sully\n",
      "Topic #7: new life man com time friend money help way wants\n",
      "Topic #8: roy jeremy vegas molly perkins sean las lola caesar ac\n",
      "Topic #9: town johnny henry students local sister small sheriff helen teacher\n",
      "Topic #10: ben linda phil junior raymond bernie elsa liz jewel dylan\n",
      "Topic #11: family life father mother love year old new relationship son\n",
      "Topic #12: film tom movie documentary rock music tommy band ray world\n",
      "Topic #13: george jane animals circus jungle ned animal braddock gene brooks\n",
      "Topic #14: arthur lucy au sir cs oz chapman murray muzzle uq\n",
      "Topic #15: rocky la karen lisa kit di vienna mickey ma il\n",
      "Topic #16: andrew project rebecca lillian thought recording tape experiences destroying centuries\n",
      "Topic #17: kenneth chisholm moon kchishol murphy rogers detroit norman jan beverly\n",
      "Topic #18: love john nick meets woman life mary married hotel falls\n",
      "Topic #19: gang food emily carl roger leo japanese japan woody jacob\n",
      "Topic #20: mexico workers restaurant mexican border union rosa chef cooking rat\n",
      "Topic #21: police murder harry killer frank detective case wife crime paul\n",
      "Topic #22: vampire church stephan ed priest harold vampires edu cc wwu\n",
      "Topic #23: billy kate christmas eve kelly fred sidney santa joey angela\n",
      "Topic #24: joe king richard baby story god princess prince son india\n",
      "Topic #25: tony dance club dancer dancing brooklyn ballet valentine contest jasmine\n",
      "Topic #26: earth dr world evil human ship bond planet com crew\n",
      "Topic #27: susan al jesse laura foster ranch pearl willy danny chocolate\n",
      "Topic #28: jack peter charlie ed tracy uncle mindspring flint sutton esutton\n",
      "Topic #29: dave percy glory gwen link crash annie train shadow brings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names = vect.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
