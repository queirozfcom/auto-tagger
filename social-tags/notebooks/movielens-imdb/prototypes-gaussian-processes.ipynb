{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm proceeds as follows:\n",
    "\n",
    " - first the most informative training examples for each class are selected (prototypes)\n",
    " - expand each example into a latent function, given by the prior (this is the step that converts GPs into multi-class GPs)\n",
    " - ...\n",
    " - calculate the posterior for each class, for each sample.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import sklearn\n",
    "import sys\n",
    "import string\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV,ParameterGrid, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier,NearestNeighbors\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = os.path.join(os.getcwd(), os.pardir, '../src')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%aimport data.movielens_20m_imdb\n",
    "%aimport helpers.labels,helpers.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.movielens_20m_imdb import load_or_get_from_cache\n",
    "from helpers.labels import truncate_labels\n",
    "from helpers.neighbours import get_predicted_labels_from_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERIM_DATA_ROOT = os.path.abspath(\"../../data/interim/movielens-ml20m-imdb/\")\n",
    "ML_ROOT = \"/media/felipe/SAMSUNG/movielens/ml-20m/\"\n",
    "IMDB_ROOT = \"/media/felipe/SAMSUNG/imdb/\"\n",
    "\n",
    "PATH_TO_MOVIES = ML_ROOT + \"/movies.csv\"\n",
    "PATH_TO_TAG_ASSIGNMENTS = ML_ROOT + \"/tags.csv\"\n",
    "PATH_TO_MOVIE_PLOTS = IMDB_ROOT+\"/plot.list\"\n",
    "\n",
    "# CONFIGS\n",
    "MAX_NB_WORDS = 4000\n",
    "NB_NEIGHBOURS = 3\n",
    "DISTANCE_METRIC='cosine'\n",
    "WEIGHTS='distance'\n",
    "PREPROC=None\n",
    "STOP_WORDS=None\n",
    "NORM='l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df = load_or_get_from_cache(PATH_TO_MOVIES,PATH_TO_TAG_ASSIGNMENTS,PATH_TO_MOVIE_PLOTS,INTERIM_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = docs_df['plot'].values\n",
    "labelsets = docs_df[\"unique_tags\"].map(lambda tagstring: tagstring.split(\",\")).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labelsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't put this into a pipeline because NearestNeighbors is not a normal classifier, I think\n",
    "# I need to customize the pipeline object to be able to call the methods for that class.\n",
    "vect = CountVectorizer(max_features=MAX_NB_WORDS, preprocessor=PREPROC, stop_words=STOP_WORDS)\n",
    "tfidf = TfidfTransformer(norm=NORM)\n",
    "nbrs = NearestNeighbors(n_neighbors=NB_NEIGHBOURS, metric=DISTANCE_METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,labelsets,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_train = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "X_test = vect.transform(X_test)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
