@INPROCEEDINGS{6040843,
author={P. Hu and M. Yu and J. Li and C. Zhu and T. Zhao},
booktitle={2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology},
title={Semi-supervised Learning Framework for Cross-Lingual Projection},
year={2011},
volume={3},
pages={213-216},
abstract={Cross-lingual projection encounters two major challenges, the noise from word-alignment error and the syntactic divergences between two languages. To solve these two problems, a semi-supervised learning framework of cross-lingual projection is proposed to get better annotations using parallel data. Moreover, a projection model is introduced to model the projection process of labeling from the resource-rich language to the resource-scarce language. The projection model, together with the traditional target model of cross-lingual projection, can be seen as two views of parallel data. Utilizing these two views, an extension of co-training algorithm to structured predictions is designed to boost the result of the two models. Experiments show that the proposed cross-lingual projection method improves the accuracy in the task of POS-tagging projection. And using only one-to-one alignments proves to lead to more accurate results than using all kinds of alignment information.},
keywords={computational linguistics;identification technology;learning (artificial intelligence);resource allocation;POS tagging projection;cotraining algorithm;cross lingual projection;one-to-one alignment;parallel data;resource rich language;resource scarce language;semisupervised learning framework;syntactic divergence;word-alignment error;Accuracy;Data models;Labeling;Natural language processing;Prediction algorithms;Training;Training data;co-training;cross-lingual projection;pos tagging;semi-supervised learning;structured predictions},
doi={10.1109/WI-IAT.2011.58},
month={Aug},}
@INPROCEEDINGS{6005632,
author={K. Jiang and P. Wang and N. Yu},
booktitle={2011 Sixth International Conference on Image and Graphics},
title={ContextRank: Personalized Tourism Recommendation by Exploiting Context Information of Geotagged Web Photos},
year={2011},
pages={931-937},
abstract={In this paper, we propose a method: ContextRank, which utilizes the vast quantity of geo tagged photos in photo sharing website to recommend travel locations. To enhance the personalized recommendation performance, our method exploits different context information of photos, such as textual tags, geotags, visual information, and user similarity. ContextRank first detects landmarks from photos' GPS locations, and estimates the popularity of each landmark. Within each landmark, representative photos and tags are extracted. Furthermore, ContextRank calculates the user similarity based on users' travel history. When a user's geotagged photos are given, the landmark popularity, representative photos and tags, and the user similarity are used to predict the user preference of a landmark from different aspects. Finally a learning to rank algorithm is introduced to combine different preference predictions to give the final recommendation. Experiments performed on a dataset collected from Panoramio show that the ContextRank can obtain a better result than the state-of-the-art method.},
keywords={Web sites;humanities;information analysis;learning (artificial intelligence);recommender systems;ContextRank;context information;geotagged Web photo;learning-to-rank algorithm;personalized tourism recommendation;photo sharing Website;Collaboration;Context;Geology;Global Positioning System;History;Kernel;Visualization;context information;geotagged photos;tourism recommendation},
doi={10.1109/ICIG.2011.48},
month={Aug},}
@ARTICLE{5765494,
author={A. L. Varna and M. Wu},
journal={IEEE Transactions on Information Forensics and Security},
title={Modeling and Analysis of Correlated Binary Fingerprints for Content Identification},
year={2011},
volume={6},
number={3},
pages={1146-1159},
abstract={Multimedia identification via content fingerprints is used in many applications, such as content filtering on user-generated content websites, and automatic multimedia identification and tagging. A compact “fingerprint” is computed for each multimedia signal that captures robust and unique properties of the perceptual content, which is later used for identifying the multimedia. Several different multimedia fingerprinting schemes have been proposed in the literature and have been evaluated through experiments. To complement these experimental evaluations and provide guidelines for choosing system parameters and designing better schemes, this paper develops models for content fingerprinting and provides an analysis of the identification performance under these models. As a first step, bounds on the identification accuracy and the required fingerprint length for the simplest case when the fingerprint bits are modeled as i.i.d. are summarized. Markov Random Fields are then used to address more realistic settings of fingerprints with correlated components. The optimal likelihood ratio detector is derived and a statistical physics inspired approach for computing the probability of detection and probability of false alarm is described. The analysis shows that the commonly used Hamming distance detection criterion is susceptible to correlations among fingerprint bits, whereas the optimal log-likelihood ratio decision rule yields 5-20% improvement in the accuracy over a range of correlations. Simulation results demonstrate the validity of the theoretical predictions.},
keywords={Markov processes;Web sites;information filtering;multimedia computing;Hamming distance detection criterion;Markov random fields;content filtering;content identification;correlated binary fingerprints;detection probability;false alarm probability;log likelihood ratio decision rule;multimedia fingerprinting schemes;multimedia identification;optimal likelihood ratio detector;statistical physics inspired approach;user generated content Websites;Analytical models;Databases;Detectors;Fingerprint recognition;Multimedia communication;Robustness;Videos;Content fingerprinting;Markov random fields;Wang-Landau density of states estimation;content identification;error exponents},
doi={10.1109/TIFS.2011.2152394},
ISSN={1556-6013},
month={Sept},}
@INPROCEEDINGS{5755623,
author={S. Cichos},
booktitle={3rd European Workshop on RFID Systems and Technologies},
title={Predicting the influence of permittive materials on passive inductive coupled RFID-transponders},
year={2007},
pages={1-6},
abstract={Today inductive coupled RFID-systems are widely used, e.g. for access control, item tagging or wireless safety systems. The design and optimization of antennas for inductive coupled RFID-transponders require the determination of their electrical properties. This includes the calculation of the inductance and resistance of the antenna coil as well as the prediction of the parasitic capacitance. The parasitic capacitance is given not only by the geometry and material parameters of the antenna coil and substrate material. It is also influenced by environmental conditions. A recent method to predict electrical properties of planar antennas and the transponder respectively was developed in "Cichos, Verfahren zur Modellierung von planaren Spulen fÃ¿r den Entwurf und die Optimierung von Antennenspulen induktiv gekoppelter RFID-Transponder". Based on this method the influence of permittive material in the environment of a RFID-transponder, e.g. lamination foils, paper, water etc. can be calculated. It has been illustrated how these effects can be considered in the development process and technology selection of antenna coils. This paper is based on unpublished results of "Cichos, Verfahren zur Modellierung von planaren Spulen fÃ¿r den Entwurf und die Optimierung von Antennenspulen induktiv gekoppelter RFID-Transponder" during the research work at the Forschungsschwerpunkt Technologien der Mikroperipherik of the Technische UniversitÃ¿t Berlin.},
keywords={Antennas;Coils;Parasitic capacitance;Transponders;Wire},
month={June},}
@ARTICLE{5750101,
author={N. Saldanha and D. C. Malocha},
journal={IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
title={Improved reflectivity and velocity model for aluminum gratings on YZ LiNbO3},
year={2011},
volume={58},
number={4},
pages={798-807},
abstract={Lithium niobate has recently been used for SAW tags and temperature sensors because of its high coupling coefficient and high reflectivity. To increase the device operating frequency for a given electrode line resolution, harmonic operation of the reflector is a very attractive option. When used in conjunction with harmonically operated transducers, the device operating frequency can be increased for a given photolithographic line width resolution. To design and accurately predict the behavior of these devices, it is necessary to model the electrode reflectivity and velocity for both fundamental and second-harmonic operation. The coupling of modes (COM) model has been used to model these devices, however the COM model uses empirically determined coefficients to model reflectivity. In this paper, the reflectivity and velocity of aluminum electrodes is extracted experimentally for fundamental and second-harmonic operation versus metalization ratios ranging from 0.2 to 0.9 and versus normalized metal thickness ranging from 0.4% to 4%. A least-squares fit is then performed on the data using physical terms in the transmission line model to yield equations that can be used in the COM model to predict device behavior over varying metallization ratios and normalized metal thicknesses. Orthogonal frequency-coded (OFC) SAW tags were designed and fabricated and experimentally obtained data are compared with the COM modeled responses for the tags at fundamental and second-harmonic operation to verify the predictions.},
keywords={aluminium;diffraction gratings;electrodes;harmonic generation;least mean squares methods;lithium compounds;reflectivity;surface acoustic waves;temperature sensors;LiNbO3;YZ lithium niobate;aluminum electrodes;aluminum gratings;coupling coefficient;coupling of modes model;device operating frequency;electrode line resolution;electrode reflectivity;fundamental operation;harmonically operated transducers;least-squares fit;metalization ratios;metallization ratios;normalized metal thickness;orthogonal frequency-coded SAW tags;photolithographic line width resolution;second-harmonic operation;temperature sensors;transmission line model;velocity model;Electrodes;Gratings;Loading;Mathematical model;Metallization;Reflectivity;Acoustics;Algorithms;Aluminum;Computer Simulation;Computer-Aided Design;Electrodes;Equipment Failure Analysis;Materials Testing;Models, Theoretical;Niobium;Oxides;Transducers},
doi={10.1109/TUFFC.2011.1872},
ISSN={0885-3010},
month={April},}
@INPROCEEDINGS{5715137,
author={B. V. N. Silpa and P. R. Panda},
booktitle={2010 International Symposium on Electronic System Design},
title={Introducing Energy Efficiency into Graphics Processors},
year={2010},
pages={10-10},
abstract={Graphics processor (GPU) architectures have evolved rapidly in recent years with increasing performance demanded by 3D graphics applications such as games. However, challenges exist in integrating complex GPUs into mobile devices because of power and energy constraints, motivating the need for energy efficiency in GPUs. While a significant amount of power optimisation research effort has concentrated on the CPU system, GPU power efficiency is a relatively new and important area because the power consumed by GPUs is similar in magnitude to CPU power. Power and energy efficiency can be introduced into GPUs at many different levels: 1) Hardware component level - queue structures, caches, filter arithmetic units, interconnection networks, processor cores, etc., can be optimised for power. 2) Algorithm level - the deep and complex graphics processing computation pipeline can be modified to be energy aware. Shader programs written by the user can be transformed to be energy aware. 3) System level - co-ordination at the level of task allocation, voltage and frequency scaling, etc., requires knowledge and control of several different GPU system components We outline two strategies for applying energy optimisations at different levels of granularity in a GPU: (1) Texture Filter Memory (TFM) - an energy-efficient addition to the texture memory hierarchy component; and (2) an overall system level Dynamic Voltage and Frequency Scaling (DVFS) based energy reduction strategy based on an accurate tile-level slack prediction. Texture Filter Memory is an augmentation of the standard GPU texture cache hierarchy. Instead of a regular data cache hierarchy, we employ a small first level register based structure that is optimised for the relatively predictable memory access stream in the texture filtering computation. Predictability of the memory access patterns leads us to reduce power by using a simpler register access structure. Power is saved by avoiding the expensive tag lookup and - - comparisons present in regular caches. Further, the texture filter memory is a very small structure, whose access energy is much smaller than a data cache of similar performance. Dynamic Voltage and Frequency Scaling, an established energy management technique, can be applied in GPUs by first predicting the workload in a given frame, and, where sufficient slack exists, lowering the voltage and frequency levels so as to save energy while still completing the work within the frame rendering deadline. We apply DVFS in a tiled graphics renderer, where the workload prediction and voltage/frequency adjustment is performed at a tile-level of granularity, which creates opportunities for on-the-fly correction of prediction inaccuracies, ensuring high frame rates while still delivering low power. Tile-level energy management schemes are distinctly superior to schemes that work at the granularity of the entire frame in terms of energy saving and quality of the rendering measured in terms of frames rendered per second. The prediction mechanism relies both on the history - workload observed for the tile in recent frames, as well as rank - a quantification of the tile workload based on the frame structure, consisting of geometry, pixel shading, texture, and raster operations workloads.},
keywords={cache storage;computer graphic equipment;coprocessors;energy conservation;optimisation;3D graphics;GPU architecture;dynamic voltage and frequency scaling;energy efficiency;energy optimisation;graphics processor;memory access pattern predictability;mobile device;texture filter memory;texture filtering;texture memory hierarchy component;tiled graphics;Computer science;Energy management;Graphics processing unit;Registers;Rendering (computer graphics);Tiles;Dynamic Voltage and Frequency Scaling;Graphics Processors;Texture Filter Memory;Tiled Graphics},
doi={10.1109/ISED.2010.61},
month={Dec},}
@INPROCEEDINGS{5701889,
author={A. Papapostolou and H. Chaouchi},
booktitle={2010 Second International Conference on Computational Intelligence, Modelling and Simulation},
title={Deploying Wireless Sensor/Actuator Networks and RFID for Handoff Enhancement},
year={2010},
pages={457-463},
abstract={The architecture for next generation wireless networks aims to integrate various heterogenous access technologies, the synergy of which offers insights for enhancing traditional network functionalities. In this paper, we propose taking advantage of the Radio Frequency Identification (RFID) and Wireless Sensor/Actuator Networks (WSANs) pervasive technologies for enhancing the handoff process at the link and network layers on the principal communication channel, such as Wireless LAN (WLAN). In our system architecture, an RFID tag deployment is used for capturing the movement pattern of a roaming Mobile Node (MN) with an RFID reader-enabled terminal. This information is utilized for predicting its next point of attachment. The WSAN serves as an overlay control network on the top of the WLAN and is responsible for initiating or ceasing the handoff process, performing handoff prediction and communicating handoff-relevant information. Analysis and simulation-based results show considerable benefits of our scheme compared to Standard solutions, regarding energy consumption and handoff latency delay.},
keywords={actuators;mobility management (mobile radio);radiofrequency identification;wireless sensor networks;RFID reader-enabled terminal;RFID tag deployment;WLAN;actuator networks;handoff enhancement;heterogenous access technologies;mobile node;radio frequency identification;simulation-based results;wireless LAN;wireless sensor},
doi={10.1109/CIMSiM.2010.57},
ISSN={2166-8523},
month={Sept},}
@INPROCEEDINGS{5700858,
author={P. Mirowski and S. Chopra and S. Balakrishnan and S. Bangalore},
booktitle={2010 IEEE Spoken Language Technology Workshop},
title={Feature-rich continuous language models for speech recognition},
year={2010},
pages={241-246},
abstract={State-of-the-art probabilistic models of text such as n-grams require an exponential number of examples as the size of the context grows, a problem that is due to the discrete word representation. We propose to solve this problem by learning a continuous-valued and low-dimensional mapping of words, and base our predictions for the probabilities of the target word on non-linear dynamics of the latent space representation of the words in context window. We build on neural networks-based language models; by expressing them as energy-based models, we can further enrich the models with additional inputs such as part-of-speech tags, topic information and graphs of word similarity. We demonstrate a significantly lower perplexity on different text corpora, as well as improved word accuracy rate on speech recognition tasks, as compared to Kneser-Ney back-off n-gram-based language models.},
keywords={natural language processing;neural nets;probability;speech recognition;discrete word representation;energy based models;feature rich continuous language models;neural networks;speech recognition;state-of-the-art probabilistic models;topic information;Speech recognition;natural language;neural networks;probability},
doi={10.1109/SLT.2010.5700858},
month={Dec},}
@INPROCEEDINGS{5695246,
author={L. Meng and S. Oyanagi},
booktitle={2010 First International Conference on Networking and Computing},
title={Control Independence Using Dual Renaming},
year={2010},
pages={264-267},
abstract={Modern Super scalar Processor squashes up all of wrong-path instructions when the branch prediction misses. In deeper pipelines, branch miss prediction penalty increases seriously owing to large number of squashed instructions. Exploiting control independence has been proposed for reducing this penalty. Control Independence method reuses control independent instructions (CI instructions) without squashing when branch prediction misses. Reusing CI instructions at branch miss prediction is not easy because of changing data dependency between squashed instructions and CI instructions. Conventional researches of CI architecture require complex Re-renaming mechanism, or with a limited applicability. This paper proposes a new mechanism named Dual Renaming for reusing CI instructions. It assigns two tags for each source register of CI instruction, and solves data dependency with simple mechanism when branch miss prediction is detected. The simulation result shows that Dual Renaming mechanism increases IPCs by maximum 29.52%.},
keywords={program compilers;branch miss prediction penalty;control independence;control independent instruction;data dependency;dual renaming;re-renaming mechanism;squashed instruction;super scalar processor;wrong-path instruction},
doi={10.1109/IC-NC.2010.16},
month={Nov},}
@INPROCEEDINGS{5695535,
author={S. M. Khan and Y. Tian and D. A. Jimenez},
booktitle={2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture},
title={Sampling Dead Block Prediction for Last-Level Caches},
year={2010},
pages={175-186},
abstract={Last-level caches (LLCs) are large structures with significant power requirements. They can be quite inefficient. On average, a cache block in a 2MB LRU-managed LLC is dead 86% of the time, i.e., it will not be referenced again before it is evicted. This paper introduces sampling dead block prediction, a technique that samples program counters (PCs) to determine when a cache block is likely to be dead. Rather than learning from accesses and evictions from every set in the cache, a sampling predictor keeps track of a small number of sets using partial tags. Sampling allows the predictor to use far less state than previous predictors to make predictions with superior accuracy. Dead block prediction can be used to drive a dead block replacement and bypass optimization. A sampling predictor can reduce the number of LLC misses over LRU by 11.7% for memory-intensive single-thread benchmarks and 23% for multi-core workloads. The reduction in misses yields a geometric mean speedup of 5.9% for single-thread benchmarks and a geometric mean normalized weighted speedup of 12.5% for multi-core workloads. Due to the reduced state and number of accesses, the sampling predictor consumes only 3.1% of the of the dynamic power and 1.2% of the leakage power of a baseline 2MB LLC, comparing favorably with more costly techniques. The sampling predictor can even be used to significantly improve a cache with a default random replacement policy.},
keywords={cache storage;program processors;LRU-managed LLC;bypass optimization;cache block;dead block replacement;last-level caches;leakage power;memory-intensive single-thread benchmarks;multicore workloads;partial tags;power requirements;program counters;sampling dead block prediction;sampling predictor;cache;dead block prediction;microarchitecture},
doi={10.1109/MICRO.2010.24},
ISSN={1072-4451},
month={Dec},}
@INPROCEEDINGS{5686601,
author={P. C. Lin},
booktitle={TENCON 2010 - 2010 IEEE Region 10 Conference},
title={Personal speech calendar with timing keywords aware and schedule time prediction functions},
year={2010},
pages={746-750},
abstract={Speech calendar functionality to provide users with voice recording for schedule database and to retrieve it by speech query inputs. For example, users can record a database sentence: "Go to attend the TENCON conference in Fukuoka, Japan, on November 24" as a personal schedule, and use a nature sentence input, such as "Any schedule on November 24?" to retrieve the database. To implement this spoken document retrieval (SDR) system on embedded systems, we have previously made the column-based row-based (CBRB) partial matching algorithm and the whole-matching-plane-based (WMPB) accumulation algorithm. Without using a speech recognizer, the CBRB and WMPB computes feature distances between database sentences and query sentence. If common words appear, such as "November" and "24", the similarity score would be high. However; if a query sentence: "Any trip in next week?" the system will not be able to use the CBRB or WMPB algorithm for SDR, because there is no matched word (common word) in both sentences. In addition; if an itinerary is recorded as "Go to TENCON conference on next Monday" such a speech sentence will face difficulties for the future SDR. The timing keywords "next Monday" which is not a datable schedule leads to a query input: "Any trip on November 24?" will not be able to find the itinerary. Moreover, the system cannot determine whether this kind of indeterminate schedule should be automatically deleted or not if users do not delete this kind of schedule on their own. Another problem is that if the keyword "Monday" appears in the query, this schedule will be continuously retrieved every time in the future. To solve the above problems; this paper presents a personal speech calendar with timing keywords aware and schedule time prediction functions. After a schedule to be recorded, system takes down the recording-time and determines the timing keywords, then makes a timing-tag which indicates the expected timing information including the fields of year, month,- - date and time of the schedule. The timing-tag can provide explicit schedule timing for the future comparison with the speech query inputs.},
keywords={embedded systems;natural language processing;query processing;speech processing;word processing;Fukuoka;Japan;TENCON conference;column based row based partial matching algorithm;database sentences;embedded systems;nature sentence input;personal speech calendar;query sentence;schedule time prediction function;speech query;spoken document retrieval system;voice recording;whole matching plane based accumulation algorithm;CBRB Algorithm;Partial Matching;Spoken Document Retrieval},
doi={10.1109/TENCON.2010.5686601},
ISSN={2159-3442},
month={Nov},}
@INPROCEEDINGS{5685430,
author={Y. C. Maa and M. H. Yen and Y. T. Wang},
booktitle={2010 International Computer Symposium (ICS2010)},
title={Evaluating and improving variable length history branch predictors},
year={2010},
pages={656-663},
abstract={With the never ending quest for high performance and cost/power efficient processor design in recent years, how to provide performance on adequate hardware and power budgets has become an important issue. In this paper, we review and evaluate several variable length history branch predictors for high performance processors and propose a modified branch predictor, f-TAGE, to improve critical path delay for highly accurate TAGE (TAgged GEometric history length) branch predictor f-TAGE applies Priority Multiplexer to reduce multi-level gate delays. We analyze and empirically study our proposed scheme along with variable length history prediction schemes, including the Fast Path-Based Neural Branch Predictor (FPB), Piecewise Linear Branch Predictor (PLB) and TAGE as well as Optimized GEometric History Length branch predictor (O-GEHL) with respect to critical path delay, branch prediction accuracy and hardware overhead. It is shown that f-TAGE reduces critical path delay and preserves prediction accuracy at the cost of modest hardware overhead. From our evaluation, the proposed scheme can lower TAGE critical path delay by up to 21% at little hardware overhead.},
keywords={computer architecture;logic design;microprocessor chips;optimisation;performance evaluation;power aware computing;cost efficient processor design;f-TAGE;fast path based neural branch predictor;optimized geometric history length branch predictor;piecewise linear branch predictor;power efficient processor design;priority multiplexer;tagged geometric history length;variable length history branch predictors;Accuracy;Delay;Hardware;History;Indexes;Multiplexing;Training;branch prediction;critical path delay;f-TAGE;processor architecture;variable length history predictor},
doi={10.1109/COMPSYM.2010.5685430},
month={Dec},}
@INPROCEEDINGS{5601198,
author={B. Li and Y. He and K. She and Z. Hou and Y. Zhu and B. Li and F. Guo},
booktitle={2010 6th International Conference on Wireless Communications Networking and Mobile Computing (WiCOM)},
title={Prediction of Passive UHF RFID's Discrimination Based on LVQ Neural Network Method},
year={2010},
pages={1-4},
abstract={The discrimination of passive Ultra High Frequency (UHF) Radio Frequency Identification (RFID) system can be affected by several factors. To measure the discrimination of UHF RFID systems, a measurement system based on virtual instruments which can adjust the speed, position and angle of tag is built in this paper. The learning vector quantization neural network based on genetic algorithm (GA-LVQ) is introduced to predict the discrimination of UHF RFID systems. To enhance the searching efficiency, the GA is modified adaptively. Prediction results are found to be good in agreement with experimental data.},
keywords={genetic algorithms;learning (artificial intelligence);neural nets;radiofrequency identification;telecommunication computing;vector quantisation;virtual instrumentation;LVQ neural network method;genetic algorithm;learning vector quantization neural network;measurement system;passive UHF RFID discrimination;ultrahigh frequency radio frequency identification;virtual instruments;Artificial neural networks;Biological cells;Classification algorithms;Gallium;Radiofrequency identification;Support vector machine classification;Training},
doi={10.1109/WICOM.2010.5601198},
ISSN={2161-9646},
month={Sept},}
@INPROCEEDINGS{5556328,
author={N. Y. Kozlovski and D. C. Malocha},
booktitle={2010 IEEE International Frequency Control Symposium},
title={Multi-track low-loss SAW tags with flexible impedance matching for passive wireless sensor applications},
year={2010},
pages={279-286},
abstract={This paper presents recent results on a NASA program to build a low-loss, multi-sensor, SAW temperature sensor system. Multi-track CDMA tags have been previously studied, which helps to balance the tag reflectivity from chip-to-chip. Normally the IDT's beam extends over all tracks and the bandwidth is the same for all tracks, and there is no significant advantage over a single-track using this approach. Wideband tags using orthogonal frequency coding (OFC) can use multi-frequency chips subdivided into multi-tracks with low loss operation. Each track has one or more chips, with each chip having a different chip frequency. The track-transducer is then designed to operate only over the required frequency bands; making each non-interacting track low loss. The overall transducer embodiment is now tailored for optimum performance for loss, coding and chip reflectivity. If all tracks are electrically in parallel, the overall transducer Q remains the same as a short wideband IDT, but the electrical reflection coefficient is chosen for minimum loss or matching. Measured parallel track OFC Sn response was measured where the reflection coefficient is nearly optimized for minimum unmatched loss. In comparison, for a short wideband transducer of equivalent bandwidth, the reflection coefficient is close to unity with large unmatched loss. An analytic, synthesis model and the coupling-of-modes model (COM) were developed for predictions. Experimental devices were fabricated on YZ LiNbO3 at 250, 500 and 915 MHz for evaluation. Several frequency, track number and chip configurations were designed and fabricated having various beam widths. The Sn response illustrates the rotation on the Smith chart around the constant Q arc. Current designs indicate that an unmatched sensor loss is approaching 10 dB, which is 20-40 dB less loss than typical CDMA performance. This paper will present the approaches, analysis, design, layout, and results of several multi-track OFC devices, ha- - ving several differing operating frequencies and embodiments. The experimental results agree remarkably well with analysis and predictions and confirm the advantageous of the multi-track approaches. The results of this work will ultimately produce lowloss SAW sensor platforms, which lead to greater sensor system range and performance.},
keywords={encoding;impedance matching;surface acoustic waves;temperature sensors;wireless sensor networks;SAW temperature sensor system;coupling-of-modes model;electrical reflection coefficient;flexible impedance matching;frequency 250 MHz;frequency 500 MHz;frequency 915 MHz;orthogonal frequency coding;passive wireless sensor;unmatched sensor loss;wideband transducer;Analytical models;Bandwidth;Gratings;Multiaccess communication;Performance evaluation;Surface acoustic waves;Transducers},
doi={10.1109/FREQ.2010.5556328},
ISSN={2327-1914},
month={June},}
@INPROCEEDINGS{5517870,
author={J. Xiang and A. Cheng and M. Wang and H. Chang and S. Zhang and A. Cheng and M. Wang and D. Zhu and R. Jia and Q. Luo and H. Cui and Y. Zhou and Y. Wang and Z. Xu and Z. Chen and X. Chen and X. Wang and A. Cheng and X. Chen},
booktitle={2010 4th International Conference on Bioinformatics and Biomedical Engineering},
title={Prediction of B Cell Epitopes and Overexpression of Truncated VP19c of Duck Enteritis Virus in Escherichia Coli},
year={2010},
pages={1-5},
abstract={Prediction of B cell epitopes of duck enteritis virus (DEV) VP19c protein encoded by UL38 gene and expression in prokaryotic system were described in the present study. The major antigenic portion of VP19c protein of DEV was predicted and corresponding gene was amplified from the extracted DNA and cloned. The recombinant expression construction(pPAL7-truncated UL38) was identified by the polymerase chain reaction, restriction enzyme and sequencing analysis. The profinity eXact affinity-tagged fusion truncated VP19c protein with a molecular mass of 35 kDa was expressed by IPTG induction and was purified to near homogeneity by extracting inclusion bodies(IBs) as judged by sodium dodesyl sulfate-polyacrylamide gel electrophoresis analysis. The purified truncated VP19c protein was recognized by antibody to DEV in western blot analysis.},
keywords={bioinformatics;cellular biophysics;diseases;electrophoresis;genetics;microorganisms;molecular biophysics;proteins;B cell epitope prediction;DNA;Escherichia coli;IPTG induction;UL38 gene;duck enteritis virus;extracting inclusion bodies;gene expression;overexpression;polymerase chain reaction;prokaryotic system;recombinant expression construction;restriction enzyme analysis;sequencing analysis;sodium dodesyl sulfate-polyacrylamide gel electrophoresis analysis;truncated VP19c protein;western blot analysis;Animals;Capacitive sensors;DNA;Diseases;Hemorrhaging;Humans;Kinetic theory;Laboratories;Packaging;Proteins},
doi={10.1109/ICBBE.2010.5517870},
ISSN={2151-7614},
month={June},}
@INPROCEEDINGS{5505441,
author={C. R. Medeiros and J. R. Costa and C. A. Fernandes},
booktitle={Proceedings of the Fourth European Conference on Antennas and Propagation},
title={UHF tag for suitcase RFID application in airports},
year={2010},
pages={1-5},
abstract={This paper presents a passive UHF tag configuration for suitcase security and tracking in airport luggage operation. The proposed solution is based on conformal geometry tag, consisting of a folded dipole with orthogonal arms, appropriate for integration into the wall of injection moulded suitcases during its fabrication process. The ALIEN Higgs-2 integrated circuit is used. Simulated frequency dependence of the proposed UHF passive tag is presented and maximum detection range was measured in free space and within the suitcase in several test environments. The experimental results are compared with a commercial tag and demonstrate good agreement with predictions.},
keywords={Airports;Arm;Circuit simulation;Fabrication;Frequency dependence;Frequency measurement;Geometry;RFID tags;Security;UHF measurements},
ISSN={2164-3342},
month={April},}
@INPROCEEDINGS{5489511,
author={Iswanjono and B. Budiardjo and K. Ramli},
booktitle={2010 Second International Conference on Computer Research and Development},
title={Simulation for RFID-Based Red Light Violation Detection: Violation Detection and Flow Prediction},
year={2010},
pages={742-746},
abstract={The Scilab is freeware as launched by INRIA and ENPC. This paper explains the experience result of the simulation by Scilab to simulate RFID-based for red light violation detection. This simulation gives evidence of violation and prediction of vehicle flow. The violation can detect if the vehicle's IDs have moved form one RFID Reader to the others. The flow prediction is executed by channel forward as distance form the RFID Reader. A randomization generates vehicle IDs, vehicle numbers and vehicle branch destination that can show the function of RFID reader to detect tags.},
keywords={automated highways;radiofrequency identification;vehicles;RFID based red light violation detection;Scilab;flow prediction;vehicle branch destination;vehicle flow prediction;vehicle numbers destination;violation detection;Access control;Digital cameras;Intrusion detection;Libraries;Licenses;Predictive models;Process control;Radiofrequency identification;Signal processing algorithms;Vehicle detection;Flow prediction;RFID;Red light violation;Scilab},
doi={10.1109/ICCRD.2010.168},
month={May},}
@ARTICLE{5389052,
author={D. B. Davison and J. F. Burke},
journal={IBM Journal of Research and Development},
title={Brute force estimation of the number of human genes using EST clustering as a measure},
year={2001},
volume={45},
number={3.4},
pages={439-447},
abstract={A current question of considerable interest to both the medical and nonmedical communities concerns the number of human transcription units (which, for the purposes of this paper, are “genes”) and proteins. Even with the recent announcement of the completion of the draft sequence of the human genome, it is still extremely difficult to predict the number of genes present in the genome. There are several methods for gene prediction, all involving computational tools. One way to approach this question, involving both computation and experiment, is to look at copies of fragments of messenger ribonucleic acid (mRNA) called expressed sequence tags (ESTs). The mRNA comes only from a gene being expressed, or translated, into RNA; by clustering mRNA fragments, we can try to reconstruct the expressed gene. While the final result is a very rough representation of the “true expressed transcript,” it is probably within 20% of the real number. Here, we review the issues involved in EST clustering and present an estimate of the total number of human genes. Our results to date indicate that there are some 70000 transcription units, with an average of 1.2 different transcripts per transcription unit. Thus, we estimate the total number of human proteins to be at least 85 000. The total number of proteins will be higher because of post-translational modification.},
doi={10.1147/rd.453.0439},
ISSN={0018-8646},
month={May},}
@INPROCEEDINGS{5416659,
author={M. U. Farooq and L. Chen and L. Kurian},
booktitle={HPCA - 16 2010 The Sixteenth International Symposium on High-Performance Computer Architecture},
title={Value Based BTB Indexing for indirect jump prediction},
year={2010},
pages={1-11},
abstract={History-based branch direction predictors for conditional branches are shown to be highly accurate. Indirect branches however, are hard to predict as they may have multiple targets corresponding to a single indirect branch instruction. We propose the Value Based BTB Indexing (VBBI), a correlation-based target address prediction scheme for indirect jump instructions. For each static hard-to-predict indirect jump instruction, the compiler identifies a `hint instruction', whose output value strongly correlates with the target address of the indirect jump instruction. At run time, multiple target addresses of the indirect jump instruction are stored and subsequently accessed from the BTB at different indices computed using the jump instruction PC and the hint instruction output values. In case the hint instruction has not finished its execution when the jump instruction is fetched, a second and more accurate target address prediction is made when the hint instruction output is available, thus reducing the jump misprediction penalty. We compare our design to the regular BTB design and the best previously proposed indirect jump predictor, the tagged target cache (TTC). Our evaluation shows that the VBBI scheme improves the indirect jump target prediction accuracy by 48% and 18%, compared with the baseline BTB and TTC designs, respectively. This results in average performance improvement of 16.4% over the baseline BTB scheme, and 13% improvement over the TTC predictor. Out of this performance improvement 2% is contributed by target prediction overriding which is accurate 96% of the time.},
keywords={indexing;prediction theory;Indirect branches;conditional branches;history-based branch direction predictors;indirect jump instruction;indirect jump target prediction;jump misprediction;tagged target cache;value based BTB indexing;Accuracy;Computer aided instruction;Engines;Functional programming;Hardware;History;Indexing;Java;Object oriented modeling;Object oriented programming;branch target prediction;compiler guided branch prediction;correlation-based branch prediction;indirect branches},
doi={10.1109/HPCA.2010.5416659},
ISSN={1530-0897},
month={Jan},}
@ARTICLE{5433096,
author={G. Marrocco and E. Di Giampaolo and R. Aliberti},
journal={IEEE Antennas and Propagation Magazine},
title={Estimation of UHF RFID Reading Regions in Real Environments},
year={2009},
volume={51},
number={6},
pages={44-57},
abstract={The reading range is one of the most critical performance indicators of radio-frequency identification (RFID) systems. It depends on many physical and geometrical parameters. Typically, in the ultra-high-frequency band (UHF: 860 MHz to 960 MHz), the maximum size of the reading region is estimated by the free-space propagation model. This is based on the Friis formula, even if much more accurate predictions may be accomplished nowadays by time-consuming electromagnetic simulations, accounting for the antennas and the interaction with the nearby environment. This paper proposes a general parameterization of the three-dimensional reading region. This done having introduced all of the accessible system data, such as the emitted power, the reader and tag-over-object radiation patterns, and also the interrogation duty cycle, the scenario features, and the safety regulation constraints. Within this framework, the opportunity and some improvements of the free-space model are analyzed. They are compared with measurements and with more-accurate three-dimensional simulations of realistic environments. The discussion demonstrates the validity range of the free-space approximations, and evaluates the improvement achieved by including the main interactions with the environment. The derived formulas are ready to use and to be applied for the planning and optimization of reader-tag networks.},
keywords={UHF antennas;antenna radiation patterns;approximation theory;radiofrequency identification;Friis formula;UHF RFID reading region;free-space approximation;free-space propagation model;frequency 860 MHz to 960 MHz;interrogation duty cycle;radio-frequency identification;reader-tag network;safety regulation constraint;tag-over-object radiation pattern;Antenna radiation patterns;Antennas and propagation;Electromagnetic propagation;Electromagnetic radiation;Power system modeling;Predictive models;Radiation safety;Radio frequency;Radiofrequency identification;UHF propagation;RFID;antenna radiation patterns;ray tracing;read zone;reader;safety;tag},
doi={10.1109/MAP.2009.5433096},
ISSN={1045-9243},
month={Dec},}
@ARTICLE{5415522,
author={D. R. Gallagher and M. W. Gallagher and N. Saldanha and J. M. Pavlina and D. C. Malocha},
journal={IEEE Transactions on Microwave Theory and Techniques},
title={Spread Spectrum Orthogonal Frequency Coded SAW Tags and Sensors Using Harmonic Operation},
year={2010},
volume={58},
number={3},
pages={674-679},
abstract={This paper presents a preliminary investigation of orthogonal frequency coding (OFC) surface acoustic wave tags and sensors at a 500- and 900-MHz operational frequency range using conventional contact lithography techniques. The higher frequency devices are achieved using second harmonic operation; eliminating the need for advanced lithography techniques. The objective of this effort is to increase the technology readiness level of wideband OFC tags at higher frequencies. Measured device results are presented and compared with coupling of modes model predictions to demonstrate performance. The fundamental and harmonic device response is compared for devices designed for operation in the 900-MHz frequency band. The experimental correlation against an ideal matched filter is also presented.},
keywords={UHF detectors;harmonic generation;orthogonal codes;surface acoustic wave sensors;SAW sensors;SAW tags;frequency 500 MHz;frequency 900 MHz;harmonic device response;lithography;mode coupling;second harmonic operation;spread spectrum orthogonal frequency code;surface acoustic wave sensors;surface acoustic wave tags;wideband OFC tags;Acoustic sensors;Acoustic waves;Frequency;Lithography;Power harmonic filters;Predictive models;Spread spectrum communication;Surface acoustic wave devices;Surface acoustic waves;Wideband;Acoustic devices;SAW devices;harmonic generation;microsensors;multisensor systems;orthogonal frequency coding (OFC);sensors;spread spectrum communication;surface acoustic waves (SAWs)},
doi={10.1109/TMTT.2010.2040347},
ISSN={0018-9480},
month={March},}
@INPROCEEDINGS{5412656,
author={N. W. Lo and E. Winata and K. H. Yeh},
booktitle={2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC)},
title={Adaptive Delay Splitting for Efficient RFID Tag Identification},
year={2009},
pages={79-82},
abstract={In an RFID system, the tag-to-reader signal collision may induce longer transmission delay and higher communication overhead while a reader intend to identify all existing tags at the same time. The issue of designing an efficient anti-collision scheme for RFID systems has been promptly focused by research community and scholars in recent years. In this paper, we present an RFID anti-collision protocol, called adaptive delay splitting (ADS), which adopts two new concepts, the collision prediction technique and the queuing technique, to raise the system efficiency on tag identification. The simulation results show that ADS significantly outperforms two ALOHA-based anticollision schemes, i.e. Q-algorithm and ABS, in terms of signal transmission delay and data communication overhead.},
keywords={protocols;queueing theory;radiofrequency identification;ALOHA-based anticollision schemes;Q-algorithm;RFID anticollision protocol;adaptive delay splitting;collision prediction technique;data communication overhead;efficient RFID tag identification;efficient anticollision scheme;queuing technique;radiofrequency identification;signal transmission delay;tag-to-reader signal collision;Adaptive control;Communication system control;Delay;Feedback;Information management;Programmable control;Protocols;RFID tags;Radiofrequency identification;Signal processing},
doi={10.1109/ICICIC.2009.69},
month={Dec},}
@INPROCEEDINGS{5370515,
author={Y. Chun-Yan and M. Jun and Z. Yu-Yan},
booktitle={2009 International Conference on Information Management, Innovation Management and Industrial Engineering},
title={Online Price Extraction and Decision Support for Agricultural Products},
year={2009},
volume={4},
pages={337-340},
abstract={It is a significant task to extract market data from different Web pages for prediction and analysis. A prototype decision support system of an agricultural product market is designed and developed in this paper. It can extract online price information of a certain agricultural product from Web sites of agricultural wholesale, predict the product price in the future months, and provide further decision support on such issues as which cities the product should be sent to for sale and which cities should be in the transport route. To achieve these goals, an algorithm named MDT-E (market data table extraction) is proposed to extract the maximum data table in a Web page. Based on the common practice that "the price data are usually displayed in the largest table on a Web page with the structure of "<td>" and "</td>" tags", our market data extraction algorithm detects the largest table on a Web page at first, then transforms the table into a DOM tree,and further obtains the node values of the "<td>" tags. This algorithm can automatically detect market data without an assigned data extraction region. The designed system uses a quadratic forcasting model of linear time series to predict the price, and compares the prediction results by using different time series and different sample data to find the best forecasting model to forecast the price in cites. In addition, it provides the decision support to determine the transport route based on the transport costs and product prices.},
keywords={Web sites;agricultural products;decision support systems;information retrieval;pricing;time series;DOM tree;Web page;Web sites;agricultural product market;decision support system;linear time series;market data table extraction;online price extraction;Agricultural products;Cities and towns;Data mining;Decision support systems;Economic forecasting;Marketing and sales;Predictive models;Product design;Prototypes;Web pages;Web data extraction;decision support;prediction},
doi={10.1109/ICIII.2009.541},
ISSN={2155-1456},
month={Dec},}
@INPROCEEDINGS{5283882,
author={W. T. Fu and T. G. Kannampallil and R. Kang},
booktitle={2009 International Conference on Computational Science and Engineering},
title={A Semantic Imitation Model of Social Tag Choices},
year={2009},
volume={4},
pages={66-73},
abstract={We describe a semantic imitation model of social tagging that integrates formal representations of semantics and a stochastic tag choice process to explain and predict emergent behavioral patterns. The model adopts a probabilistic topic model to separately represent external word-topic and internal word-concept relations. These representations are coupled with a tag-based topic inference process that predicts how existing tags may influence the semantic interpretation of a document. The inferred topics influence the choice of tags assigned to a document through a random utility model of tag choices. We show that the model is successful in explaining the stability in tag proportions across time and power-law frequency-rank distributions of tag co-occurrences for semantically general and narrow tags. The model also generates novel predictions on how emergent behavioral patterns may change when users with different domain expertise interact with a social tagging system. The model demonstrates the weaknesses of single-level analyses and highlights the importance of adopting a multi-level modeling approach to explain online social behavior.},
keywords={Internet;document handling;human computer interaction;social networking (online);external word-topic;internal word-concept relations;multi-level modeling approach;online social behavior;probabilistic topic model;random utility model;semantic imitation model;semantics formal representations;social tagging system;stochastic tag choice process;Cognitive science;Computational modeling;Dictionaries;Frequency;Human factors;Power system modeling;Predictive models;Stability;Stochastic processes;Tagging;Computational Cognitive Model;Multi-level Social Behavior Modeling;Semantic Imitation;Social Tagging},
doi={10.1109/CSE.2009.382},
month={Aug},}
@ARTICLE{5280500,
author={W. P. Segars and D. S. Lalush and E. C. Frey and D. Manocha and M. A. King and B. M. W. Tsui},
journal={IEEE Transactions on Nuclear Science},
title={Improved Dynamic Cardiac Phantom Based on 4D NURBS and Tagged MRI},
year={2009},
volume={56},
number={5},
pages={2728-2738},
abstract={We previously developed a realistic phantom for the cardiac motion for use in medical imaging research. The phantom was based upon a gated magnetic resonance imaging (MRI) cardiac study and using 4D non-uniform rational b-splines (NURBS). Using the gated MRI study as the basis for the cardiac model had its limitations. From the MRI images, the change in the size and geometry of the heart structures could be obtained, but without markers to track the movement of points on or within the myocardium, no explicit time correspondence could be established for the structures. Also, only the inner and outer surfaces of the myocardium could be modeled. We enhance this phantom of the beating heart using 4D tagged MRI data. We utilize NURBS surfaces to analyze the full 3D motion of the heart from the tagged data. From this analysis, time-dependent 3D NURBS surfaces were created for the right (RV) and left ventricles (LV). Models for the atria were developed separately since the tagged data only covered the ventricles. A 4D NURBS surface was fit to the 3D surfaces of the heart creating time-continuous 4D NURBS models. Multiple 4D surfaces were created for the left ventricle (LV) spanning its entire volume. The multiple surfaces for the LV were spline-interpolated about an additional dimension, thickness, creating a 4D NURBS solid model for the LV with the ability to represent the motion of any point within the volume of the LV myocardium at any time during the cardiac cycle. Our analysis of the tagged data was found to produce accurate models for the RV and LV at each time frame. In a comparison with segmented structures from the tagged dataset, LV and RV surface predictions were found to vary by a maximum of 1.5 mm's and 3.4 mm's respectively. The errors can be attributed to the tag spacing in the data (7.97 mm's). The new cardiac model was incorporated into the 4D NURBS-based Cardiac-Torso (NCAT) phantom widely used in imaging research. With its enhanced abilities, the mode- l will provide a useful tool in the study of cardiac imaging and the effects of cardiac motion in medical images.},
keywords={biomedical MRI;cardiology;medical image processing;phantoms;3D NURBS surfaces;4D NURBS solid model;4D NURBS surface;4D NURBS-based Cardiac-Torso phantom;4D nonuniform rational b-splines;LV surface prediction;NCAT phantom;RV surface prediction;cardiac motion;dynamic cardiac phantom;gated magnetic resonance imaging cardiac study;heart 3D motion;left ventricle myocardium;medical imaging research;multiple 4D surfaces;right ventricle;tagged MRI;tagged data;time-continuous 4D NURBS models;Biomedical imaging;Geometry;Heart;Imaging phantoms;Magnetic resonance imaging;Myocardium;Spline;Surface fitting;Surface reconstruction;Surface topography;Cardiac;medical imaging;phantom;simulation},
doi={10.1109/TNS.2009.2016196},
ISSN={0018-9499},
month={Oct},}
@INPROCEEDINGS{5236391,
author={T. Lin and G. w. Lei and R. y. You and Z. Chen},
booktitle={2009 IEEE International Symposium on IT in Medicine Education},
title={A novel noise-removed algorithm for tagging effects in intermolecular multiple-quantum coherence magnetic resonance images},
year={2009},
volume={1},
pages={394-396},
abstract={Since the acquired images are often distorted by noise resulting from various experimental and other sources (e.g., the RF tagging effects) in magnetic resonance imaging (MRI), removing noise is a very important work and at the same time useful information should be well preserved. In this paper, a novel, fast denoising algorithm has been proposed to make tradeoff between reducing noise and enlarging contrast of MRI images. Finally the computed results are in good agreement with our theoretical prediction.},
keywords={biomedical MRI;image denoising;medical image processing;MRI image contrast;RF tagging effect;fast-image denoising algorithm;image acquisition;intermolecular multiple-quantum coherence MRI;magnetic resonance imaging;noise-removal algorithm;Biology computing;Filters;Magnetic noise;Magnetic resonance;Magnetic resonance imaging;Noise figure;Noise reduction;Physics;Signal to noise ratio;Tagging},
doi={10.1109/ITIME.2009.5236391},
month={Aug},}
@INPROCEEDINGS{5234104,
author={K. P. Chavan and A. Zeid and S. Kamarthi},
booktitle={2009 IEEE International Conference on Automation Science and Engineering},
title={A server centric authentication protocol for a RFID system},
year={2009},
pages={227-232},
abstract={A large scale implementation of RFID technology in many practical applications including supply chain and retail stores require the resolution of the either-or dichotomy between low-cost RFID tags and secure RFID systems. This research proposes an approach in which the complexity and hence the cost of RFID tags can be drastically reduce by eliminating the security-assuring computational resources from the RFID tags and placing the security burden on the data processing server. This approach can make it possible to carry out secure transactions even with simple and inexpensive RFID tags. This research investigates a multiple ID authentication protocol based on this approach. The paper presents an empirical formula for the prediction of the performance of the protocol in terms of the number of spoofs per transaction for a given protocol configuration.},
keywords={client-server systems;computer networks;radiofrequency identification;security of data;RFID system;RFID tags;data processing server;server centric authentication protocol;Access protocols;Application software;Authentication;Costs;Cryptography;Data security;Information security;Protection;RFID tags;Radiofrequency identification},
doi={10.1109/COASE.2009.5234104},
ISSN={2161-8070},
month={Aug},}
@INPROCEEDINGS{5206729,
author={J. Wang and Y. G. Jiang and S. F. Chang},
booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
title={Label diagnosis through self tuning for web image search},
year={2009},
pages={1390-1397},
abstract={Semi-supervised learning (SSL) relies on partial supervision information for prediction, where only a small set of samples are associated with labels. Performance of SSL is significantly degraded if the given labels are not reliable. Such problems arise in realistic applications such as Web image search using noisy textual tags. This paper proposes a novel and efficient graph based SSL method with the unique capacity of pruning contradictory labels and inferring new labels through a bidirectional and alternating optimization process. The objective is to automatically identify the most suitable samples for manipulation, labeling or unlabeling, and meanwhile estimate a smooth classification function over a weighted graph. Different from other graph based SSL approaches, the proposed method employs a bivariate objective function and iteratively modifies label variables on both labeled and unlabeled samples. Starting from such a SSL setting, we present a relearning framework to improve the performance of base learner, particularly for the application of Web image search. Besides the toy demonstration on artificial data, we evaluated the proposed method on flicker image search with unreliable textual labels. Experimental results confirm the significant improvements of the method over the baseline text based search engine and the state-of-the-art SSL methods.},
keywords={Internet;content-based retrieval;graph theory;image retrieval;learning (artificial intelligence);search engines;Web image search;baseline text based search engine;bidirectional optimization process;flicker image search;graph method;label diagnosis;noisy textual tag;partial supervision information;semisupervised learning;smooth classification function;weighted graph;Data acquisition;Degradation;Filters;Geometry;Labeling;Optimization methods;Search engines;Semisupervised learning;Supervised learning;Training data},
doi={10.1109/CVPR.2009.5206729},
ISSN={1063-6919},
month={June},}
@INPROCEEDINGS{5206369,
author={P. Solic and N. Rozic and S. Marinovic},
booktitle={2009 10th International Conference on Telecommunications},
title={RFID-based visitors modeling for galleries using Markov model},
year={2009},
pages={105-110},
abstract={RFID are becoming increasingly popular and are widely used in many applications. Tags can be used for environment and habit monitoring, healthcare applications, home automation and pedestrian or vehicle traffic control. This paper describes the method of building a robust N-state Markov model that describes visitor's behavior in a gallery room. The built model can be used in planning of exhibitions, in modeling of visitor's preferences, and/or in generation of predictions related to exhibition lasting, expected sales and pricing.},
keywords={Markov processes;radiofrequency identification;RFID-based visitors modeling;robust N-state Markov model;visitor behavior;Computerized monitoring;Home automation;Marketing and sales;Medical services;Predictive models;Pricing;Radiofrequency identification;Robustness;Traffic control;Vehicles;Algorithm describing visitor's behavior;Markov model of visitors;RFID based applications;Visitors tracking},
month={June},}
@INPROCEEDINGS{5194427,
author={J. Yu and P. Lou and X. Wu},
booktitle={2009 IITA International Conference on Control, Automation and Systems Engineering (case 2009)},
title={A Dual-Core Real-Time Embedded System for Vision-Based Automated Guided Vehicle},
year={2009},
pages={207-211},
abstract={As a cell of flexible manufacturing system (FMS), automated guided vehicle (AGV) is widely used in factory. In this paper, we presented a novel technology used for vision-guided AGV. An embedded dual-core processor system with real-time operating system (RTOS) DSP/BIOS is designed for system manager and image processor. We adopt DSP TMS320DM642 as image processor and ARM LPC2210 as controller. The embedded RTOS DSP/BIOS is transplanted on DSP to construct a software development platform for tasks management, which enhance reliability and real-time response of system. Two CCD cameras are fixed on vehicle to capture the scene of lane. One, on the front of vehicle, is used for prediction, the other, at the center of vehicle, is used for accurate positioning. Radio frequency identification (RFID) reader is loaded on vehicle to collect the information stored in RFID tag which placed by the side of lane. The experimental results demonstrate the advantages of real-time and robust.},
keywords={CCD image sensors;automatic guided vehicles;digital signal processing chips;embedded systems;flexible manufacturing systems;industrial robots;mobile robots;multiprocessing systems;operating systems (computers);radiofrequency identification;reduced instruction set computing;robot vision;software reliability;AGV;ARM;BIOS;CCD camera;DSP;FMS;RFID;RTOS;advanced RISC machine;basic input output system;digital signal processing;dual-core real-time embedded system;embedded dual-core processor system;factory robot;flexible manufacturing system;image processor;radio frequency identification reader;real-time operating system;software development platform;system manager;system reliability;task management;vision-based automated guided vehicle;Digital signal processing;Embedded system;Flexible manufacturing systems;Operating systems;Production facilities;Programming;Radiofrequency identification;Real time systems;Software development management;Vehicles;Automated Guided Vehicle;Computer Vision;DSP/BIOS;Embedded System;Robot Navigation},
doi={10.1109/CASE.2009.139},
month={July},}
@INPROCEEDINGS{5176114,
author={W. Kammergruber and M. Viermetz and C. N. Ziegler},
booktitle={2009 International Conference on Computational Aspects of Social Networks},
title={Discovering Communities of Interest in a Tagged On-Line Environment},
year={2009},
pages={143-148},
abstract={Tagging and social networks have come into increasing use in concert with the rise of collaborative and interactive on-line media. The focus of tagging is herein twofold: First of all the plain annotation of existing data by a governing instance in order to increase the semantic content of unstructured data, and secondly the application of such meta-information by a community or a group of like minded users. The information contained in such social tagging reflects the point of view and understanding of the community, presenting a valuable source of information for the discovery of community structure,content and intent. This paper proposes an approach aimed at the use of community based tagging to address problems in link prediction and the discovery of complex user groups in a fleeting and unstructured Web-based environment. The ideas presented in this paper are applied to a real world scenario, and the results show a distinct opportunity in community detection and support. This result will be incorporated into emerging knowledge management systems within Siemens AG in the near future.},
keywords={Internet;groupware;interactive systems;knowledge management;social networking (online);collaborative work;community based tagging;community discovering;interactive on-line media;knowledge management system;social network;tagged on-line environment;unstructured Web-based environment;Computer networks;Facebook;Information resources;International collaboration;Internet;Knowledge management;Organizing;Social network services;Tagging;Taxonomy;Communities;Social Network Analysis;Tagging;Text Mining},
doi={10.1109/CASoN.2009.22},
month={June},}
@INPROCEEDINGS{5165643,
author={D. R. Gallagher and M. W. Gallagher and N. Saldanha and J. M. Pavlina and D. C. Malocha},
booktitle={2009 IEEE MTT-S International Microwave Symposium Digest},
title={Spread spectrum orthogonal frequency coded SAW Tags and sensors using harmonic operation},
year={2009},
pages={105-108},
abstract={Wideband SAW devices with orthogonal frequency coding (OFC) are expected to be highly advantageous for various applications in NASA's exploration effort. Surface acoustic wave (SAW)-based sensors can offer wireless, passive operation in numerous environments, with various device embodiments used for retrieval of the sensed data information. Single sensor systems typically can use a single carrier frequency and a simple device embodiment because tagging is not required. In a multi-sensor environment, orthogonal frequency coding (OFC) permits the system to both identify the sensor and retrieve the sensed information discriminately. Previous research efforts have concentrated on a relatively lower operational frequency in the 250 MHz range due to available fabrication technology limitations. Using harmonic frequency operation, as shown in this paper, higher frequency devices are possible while continuing to work within the same limitations of contact lithography resolution. This paper presents a preliminary investigation of OFC SAW tags and sensors at a 900 MHz operational frequency range using conventional contact lithography techniques. The higher frequency devices are achieved using second harmonic operation. The objective of this effort is to increase the technology readiness level (TRL) of wideband OFC tags at higher frequencies. Measured device results are presented and compared with coupling of modes (COM) model predictions to demonstrate performance.},
keywords={harmonic analysis;orthogonal codes;spread spectrum communication;surface acoustic wave sensors;contact lithography resolution;coupling of mode model;data information retrieval;frequency 250 MHz;frequency 900 MHz;harmonic frequency operation;lower operational frequency;multisensor environment;orthogonal frequency coding;single carrier frequency;surface acoustic wave based sensor;technology readiness level;wideband SAW devices;Acoustic sensors;Acoustic waves;Frequency;Information retrieval;Lithography;Sensor systems;Spread spectrum communication;Surface acoustic wave devices;Surface acoustic waves;Wideband},
doi={10.1109/MWSYM.2009.5165643},
ISSN={0149-645X},
month={June},}
@INPROCEEDINGS{5138763,
author={F. Miyawaki and T. Tsunoi and Hiromi Namiki and Takashi Yaginuma and K. Yoshimitsu and D. Hashimoto and Y. Fukui},
booktitle={2009 4th IEEE Conference on Industrial Electronics and Applications},
title={Development of automatic acquisition system of surgical-instrument informantion in endoscopic and laparoscopic surgey},
year={2009},
pages={3058-3063},
abstract={To compensate for severe shortage of scrub nurses, we have been developing the scrub nurse robot (SNR) system that is capable of functioning as a skilled human scrub nurse, who is able to accurately predict which surgical instrument a surgeon will request next and to give it to the surgeon without any delay. In order to achieve this accurate prediction, we have been acquiring surgical-instrument information in laparoscopic and endoscopic surgery (ELS). To facilitate the acquisition, we developed an automatic acquisition system of surgical-instrument information (AASSI) using RFID technology, and evaluated it. The main components of the RFID hardware were an RFID antenna connecting to a trocar cannula and an RFID tag attaching to a surgical instrument. The AASSI detected insertion of the tagged instrument into the RFID-antenna trocar cannula and its extraction as well because the insertion started RF communication between the tag and antenna and the extraction ended the communication. However, electrocautery used frequently in ELS can interrupt the RF communication, thereby resulting in false recognition of insertion and extraction. We investigated and specified the conditions under which the electromagnetic interference occurred. Next, to prevent such incorrect recognition, we proposed a software-based solution, developed an algorithm against electromagnetic interference and verified that it worked in a laboratory setting. In conclusion, the AASSI is able to facilitate acquisition of intraoperative information on surgical instruments and also contribute to creation of extremely precise and accurate operative records.},
keywords={electromagnetic interference;endoscopes;medical computing;medical robotics;radiofrequency identification;surgery;RFID antenna;RFID hardware;RFID tag;automatic acquisition system;electromagnetic interference;endoscopic surgery;laparoscopic surgery;scrub nurse robot;surgical-instrument information;Data mining;Electromagnetic interference;Humans;Joining processes;Minimally invasive surgery;Radio frequency;Radiofrequency identification;Robotics and automation;Surges;Surgical instruments;RFID;automatic acquisition;electromagnetic interference;operative record;scrub nurse robot;software-based solution;surgical instrument;trrocar cannula},
doi={10.1109/ICIEA.2009.5138763},
ISSN={2156-2318},
month={May},}
@ARTICLE{4694115,
author={H. C. Wang* and T. H. Huang},
journal={IEEE Transactions on Biomedical Engineering},
title={Prediction of EST Functional Relationships via Literature Mining With User-Specified Parameters},
year={2009},
volume={56},
number={4},
pages={969-977},
abstract={The massive amount of expressed sequence tags (ESTs) gathered over recent years has triggered great interest in efficient applications for genomic research. In particular, EST functional relationships can be used to determine a possible gene network for biological processes of interest. In recent years, many researchers have tried to determine EST functional relationships by analyzing the biological literature. However, it has been challenging to find efficient prediction methods. Moreover, an annotated EST is usually associated with many functions, so successful methods must be able to distinguish between relevant and irrelevant functions based on user specifications. This paper proposes a method to discover functional relationships between ESTs of interest by analyzing literature from the Medical Literature Analysis and Retrieval System Online, with user-specified parameters for selecting keywords. This method performs better than the multiple kernel documents method in setting up a specific threshold for gathering materials. The method is also able to uncover known functional relationships, as shown by a comparison with the Kyoto Encyclopedia of Genes and Genomes database. The reliable EST relationships predicted by the proposed method can help to construct gene networks for specific biological functions of interest.},
keywords={bioinformatics;data mining;genetics;genomics;information retrieval systems;molecular biophysics;EST functional relationship;Kyoto Encyclopedia of Genes and Genomes database;Medical Literature Analysis and Retrieval System Online;expressed sequence tags;gene network;genomic research;literature mining;Biochemistry;Bioinformatics;Biological materials;Biological processes;Couplings;Databases;Encyclopedias;Genomics;Information management;Kernel;Organisms;Prediction methods;Expressed sequence tags (ESTs);Medical Literature Analysis and Retrieval System Online (MEDLINE);functional relationship;literature mining;Algorithms;Expressed Sequence Tags;Information Storage and Retrieval;MEDLINE;Models, Statistical;Random Allocation;Seeds;User-Computer Interface;Vocabulary, Controlled},
doi={10.1109/TBME.2008.2009765},
ISSN={0018-9294},
month={April},}
@INPROCEEDINGS{4797210,
author={C. Y. Tseng and H. C. Chen},
booktitle={2009 WRI International Conference on Communications and Mobile Computing},
title={The Design of Way-Prediction Scheme in Set-Associative Cache for Energy Efficient Embedded System},
year={2009},
volume={3},
pages={3-7},
abstract={Embedded system develops rapidly, functions turn into more complicate, and multi-media applications are growing daily and they consume more electrical power. Therefore, how to improve stand-by time will become a very important issue. Related researches indicate that the power consumption of processor cache is accounted for a big proportion. Way-prediction and LRU (least recently used) algorithms improve hit rate and would help in reducing the number of tag comparisons, and therefore save energy consumption. In this paper, we use MRU (most recently used) table to record the most used block for each index and use modified pseudo LRU (MPLRU) replacement algorithm for reducing hardware complexity and cache miss rate.Experiments show our prediction hit rate reach 90.15%, thus save 64.12% energy. The experimental results are obtained by using Wattch cache simulator for SPEC95 benchmarks.},
keywords={cache storage;embedded systems;low-power electronics;microprocessor chips;MRU algorithm;Wattch cache simulator;cache miss rate;energy efficient embedded system;hardware complexity;least recently used algorithm;modified pseudo LRU replacement algorithm;most recently used algorithm;multimedia application;power consumption reduction;set-associative processor cache;way-prediction scheme design;Decoding;Embedded computing;Embedded system;Energy consumption;Energy efficiency;Hardware;Mobile communication;Mobile computing;Multimedia systems;Multiplexing;Embedded System;Energy Efficiency;Set-Associative Cache},
doi={10.1109/CMC.2009.306},
month={Jan},}
@INPROCEEDINGS{4777769,
author={A. Us Saeed and M. T. Afzal and A. Latif and K. Tochtermann},
booktitle={2008 IEEE International Multitopic Conference},
title={Citation rank prediction based on bookmark counts: Exploratory case study of WWW06 papers},
year={2008},
pages={392-397},
abstract={New developments in the collaborative and participatory role of Web has emerged new web based fast lane information systems like tagging and bookmarking applications. Same authors have shown elsewhere, that for same papers tags and bookmarks appear and gain volume very quickly in time as compared to citations and also hold good correlation with the citations. Studying the rank prediction models based on these systems gives advantage of gaining quick insight and localizing the highly productive and diffusible knowledge very early in time. This shows that it may be interesting to model the citation rank of a paper within the scope of a conference or journal issue, based on the bookmark counts (i-e count representing how many researchers have shown interest in a publication.) We used linear regression model for predicting citation ranks and compared both predicted citation rank models of bookmark counts and coauthor network counts for the papers of WWW06 conference. The results show that the rank prediction model based on bookmark counts is far better than the one based on coauthor network with mean absolute error for the first limited to the range of 5 and mean absolute error for second model above 18. Along with this we also compared the two bookmark prediction models out of which one was based on total citations rank as a dependent variable and the other was based on the adjusted citation rank. The citation rank was adjusted after subtracting the self and coauthor citations from total citations. The comparison reveals a significant improvement in the model and correlation after adjusting the citation rank. This may be interpreted that the bookmarking mechanisms represents the phenomenon similar to global discovery of a publication. While in the coauthor nets the papers are communicated personally and this communication or selection may not be captured within the bookmarking systems.},
keywords={Internet;citation analysis;regression analysis;WWW06 papers;Web based fast lane information systems;bookmark prediction models;bookmarking applications;bookmarking systems;citation rank prediction;coauthor network;linear regression model;mean absolute error;Citation analysis;Collaboration;Collaborative work;Knowledge management;Linear regression;Management information systems;Paper technology;Predictive models;Tagging;Technology management;Bookmarking;Citation rank prediction;Coauthor networks;Knowledge diffusion},
doi={10.1109/INMIC.2008.4777769},
month={Dec},}
@INPROCEEDINGS{4763169,
author={A. Agarwal and G. S. Raghuwanshi and N. K. Meena and A. K. Verma and A. R. Harish},
booktitle={2008 International Conference on Recent Advances in Microwave Theory and Applications},
title={Real time location estimation using active RFID system},
year={2008},
pages={540-542},
abstract={The accuracy issues in the location prediction system using active RFID tags is addressed in this paper. First we present the location prediction accuracy in different environmental conditions. Later on, we propose a new technique to improve the prediction accuracy. The proposed technique is validated with measured data obtained under different propagation environments.},
keywords={radio direction-finding;radiofrequency identification;radiowave propagation;active RFID system;active radio frequency identification tag;radiolocation prediction system;radiowave propagation environment;real time location estimation;Accuracy;Active RFID tags;Area measurement;Assembly;Machine shops;Microwave technology;Production facilities;Radiofrequency identification;Real time systems;Yttrium;Real Time Location System;active RFID;multipath},
doi={10.1109/AMTA.2008.4763169},
month={Nov},}
@INPROCEEDINGS{4751805,
author={R. Aliberti and E. Di Giampaolo and G. Marrocco},
booktitle={2008 38th European Microwave Conference},
title={A model to estimate the RFID read-region in real environments},
year={2008},
pages={1711-1714},
abstract={The reading range is one of the most critical performance indicators of a radiofrequency identification system and depends on many physical and geometrical parameters. An accurate prediction of the read zone may be accomplished by a time-consuming electromagnetic modelling accounting for the antennas and the interaction with the environment. This paper proposed, instead, a fast prediction model, based on a small set of data and parametric antenna representation, which is demonstrated to achieve the same accuracy of a fullwave 3D model in application to realistic environments. The derived formulas are ready to use and maybe useful for the planning and optimization of reader-tag networks.},
keywords={microwave antennas;radiofrequency identification;RFID read-region;electromagnetic modelling;fullwave 3D model;parametric antenna representation;Antennas and propagation;Electromagnetic modeling;Electromagnetic propagation;Inventory management;Logistics;Power system modeling;Predictive models;Radiofrequency identification;Solid modeling;Switches},
doi={10.1109/EUMC.2008.4751805},
month={Oct},}
@INPROCEEDINGS{4753864,
author={R. Aliberti and E. Di Giampaolo and G. Marrocco},
booktitle={2008 European Conference on Wireless Technology},
title={A model to estimate the RFID read-region in real environments},
year={2008},
pages={290-293},
abstract={The reading range is one of the most critical performance indicators of a radiofrequency identification system and depends on many physical and geometrical parameters. An accurate prediction of the read zone may be accomplished by a time-consuming electromagnetic modelling accounting for the antennas and the interaction with the environment. This paper proposed, instead, a fast prediction model, based on a small set of data and parametric antenna representation, which is demonstrated to achieve the same accuracy of a fullwave 3D model in application to realistic environments. The derived formulas are ready to use and maybe useful for the planning and optimization of reader-tag networks..},
keywords={antennas;radiofrequency identification;RFID read-region;electromagnetic modelling;fullwave 3D model;parametric antenna representation;radiofrequency identification system;read zone;reader-tag networks;reading range;Antennas and propagation;Electromagnetic modeling;Electromagnetic propagation;Inventory management;Logistics;Power system modeling;Predictive models;Radiofrequency identification;Solid modeling;Switches},
doi={10.1109/EUMC.2008.4751805},
month={Oct},}
@INPROCEEDINGS{4751540,
author={M. Rusu and M. Hirvonen and H. Rahimi and P. Enoksson and C. Rusu and N. Pesonen and O. Vermesan and H. Rustad},
booktitle={2008 38th European Microwave Conference},
title={Minkowski Fractal Microstrip Antenna for RFID Tags},
year={2008},
pages={666-669},
abstract={The unique properties of fractals have been exploited to develop a new class of antenna element designs that are multi band and compact in size. These properties are very important for RFID (Radio Frequency IDentification) tags where the small size, planar geometries, multi band operation and low cost are essential for many applications. This paper presents a one loop Minkowski modified antenna using a unique configuration and operating at 868 MHz and 2.45 GHz that has been realized on a Rogers Duroid substrate. Experimental results confirm the theoretical prediction. In addition, the principle applied in this design could be used to create even smaller devices by using different substrates.},
keywords={antenna accessories;fractal antennas;microstrip antennas;radiofrequency identification;Minkowski fractal antenna;RFID tags;Rogers Duroid substrate;antenna element designs;frequency 2.45 GHz;frequency 868 MHz;microstrip antenna;radio frequency identification;Dual band;Fractal antennas;Frequency;Geometry;Microstrip antennas;Microwave antennas;RFID tags;Radiofrequency identification;Slot antennas;Transponders},
doi={10.1109/EUMC.2008.4751540},
month={Oct},}
@INPROCEEDINGS{4724492,
author={J. Ni and S. Sakai and T. Shimizu and S. Nakamura},
booktitle={2008 Second International Symposium on Universal Communication},
title={Prosody Modeling from Tone to Intonation in Chinese using a Functional F0 Model},
year={2008},
pages={397-404},
abstract={Chinese is a tonal language. It has both lexical tones and intonation. The fundamental frequency (F0) contours thereby consist of tone and intonation components. This paper presents an approach to modeling the two components in separate ways and combining them to form the final F0 contours based on a functional F0 model. We analyze tonal patterns as sparse target points (tonal F0 peaks and valleys) and model them using classification and regression trees (CART) with contextual linguistic features. As a first step, we stylize expressive intonation using a few piecewise linear patterns specified by a few markup tags. Both tonal and intonational patterns are represented in a parametric form within the framework of this F0 model. Our experimental results indicated that very low F0 prediction errors were achieved by the CART-based modeling of the tonal patterns uttered by two female and male speakers. In a listening test, the native speakers could identify 90% of synthesized stimuli with enhancing emphasis in word. Also, the linguistic features related to the lexical tone context and distinction between voiced and unvoiced initials played the most important role in characterizing the tonal patterns.},
keywords={regression analysis;speaker recognition;trees (mathematics);CART-based modeling;Chinese intonation;classification and regression trees;contextual linguistic features;fundamental frequency contours;lexical tone context;Classification tree analysis;Communications technology;Context modeling;Frequency;Hidden Markov models;Natural languages;Pattern analysis;Piecewise linear techniques;Regression tree analysis;Speech synthesis;CART;Chinese;F0 model;Prosody modeling;intonation;speech synthesis;tone},
doi={10.1109/ISUC.2008.37},
month={Dec},}
@INPROCEEDINGS{4724257,
author={C. Glasner and J. Volkert},
booktitle={2008 International Symposium on Parallel and Distributed Computing},
title={An Architecture for an Adaptive Run-time Prediction System},
year={2008},
pages={275-282},
abstract={This article describes a system for run-time prediction of applications in heterogeneous environments. To exploit the power of computational grids, scheduling systems need profound information about the job to be executed. The run-time of a job is - beside others - not only dependent of its kind and complexity but also of the adequacy and load of the remote host where it will be executed. Accounting and billing are additional aspects that have to be considered when creating a schedule. Currently predictions are achieved by using descriptive models of the applications or by applying statistical methods to former jobs mostly neglecting the behaviour of users. Motivated by this, we propose a method that is not only based on the characteristics of a job but also takes the behaviour of single users and groups of similar users respectively into account. The basic idea of our approach is to cluster users, hosts and jobs and apply multiple methods in order to detect similarities and create forecasts. This is achieved by tagging jobs with attributes and by deriving predictions for similar attributed jobs whereas the recent behaviour of a user determines which predictions are finally taken.},
keywords={grid computing;resource allocation;scheduling;statistical analysis;system monitoring;adaptive job run-time prediction system;computational grid;heterogeneous environment;load balancing;scheduling system;statistical method;Adaptive systems;Computer architecture;Distributed computing;Graphics;Grid computing;Predictive models;Processor scheduling;Runtime environment;Statistical analysis;Weather forecasting;Forecasting;Grid Computing;Run-Time Prediction;User Behaviour},
doi={10.1109/ISPDC.2008.34},
ISSN={2379-5352},
month={July},}
@INPROCEEDINGS{4662581,
author={R. G. Wright},
booktitle={2008 IEEE AUTOTESTCON},
title={Multiresolution sensor fusion approach to PCB fault detection and isolation},
year={2008},
pages={41-46},
abstract={This paper describes a novel approach to printed circuit board (PCB) testing that fuses the products of individual, non-traditional sensors to draw conclusions regarding overall PCB health and performance. This approach supplements existing parametric test capabilities with the inclusion of sensors for electromagnetic emissions, laser Doppler vibrometry, off-gassing and material parameters, and X-ray and Terahertz spectral images of the PCB. This approach lends itself to the detection and prediction of entire classes of anomalies, degraded performance, and failures that are not detectable using current automatic test equipment (ATE) or other test devices performing end-to-end diagnostic testing of individual signal parameters. This greater performance comes with a smaller price tag in terms of non-recurring development and recurring maintenance costs over currently existing test program sets. The complexities of interfacing diverse and unique sensor technologies with the PCB are discussed from both the hardware and software perspective. Issues pertaining to creating a whole-PCB interface, not just at the card-edge connectors, are addressed. In addition, we discuss methods of integrating and interpreting the unique software inputs obtained from the various sensors to determine the existence of anomalies that may be indicative of existing or pending failures within the PCB. Indications of how these new sensor technologies may comprise future test systems, as well as their retrofit into existing test systems, will also be provided.},
keywords={automatic test equipment;fault simulation;printed circuit testing;sensor fusion;PCB fault detection;PCB health;automatic test equipment;card-edge connectors;end-to-end diagnostic testing;fault isolation;individual nontraditional sensors;multiresolution sensor fusion approach;parametric test capabilities;printed circuit board testing;test program sets;whole-PCB interface;Automatic testing;Circuit testing;Electrical fault detection;Fault detection;Fuses;Printed circuits;Sensor fusion;Signal resolution;System testing;X-ray lasers;ATE;EME;ICs;TPS;X-ray;automatic test equipment;electromagnetic emissions;integrated circuits;nanotechnology;printed circuit board;sensor fusion;test program set},
doi={10.1109/AUTEST.2008.4662581},
ISSN={1088-7725},
month={Sept},}
@INPROCEEDINGS{4650030,
author={C. M. Yanofsky and R. E. Kearney and S. Lesimple and J. J. M. Bergeron and D. Boismenu and B. Carrillo and A. W. Bell},
booktitle={2008 30th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title={A Bayesian approach to peptide identification using Accurate Mass and Time tags from LC-FTICR-MS proteomics experiments},
year={2008},
pages={3775-3778},
abstract={In high-throughput proteomics, one promising approach presently being explored is the Accurate Mass and Time (AMT) tag approach, in which reversed-phase liquid chromatography coupled to high accuracy mass spectrometry provide measurements of both the masses and chromatographic retention times of tryptic peptides in complex mixtures. These measurements are matched to the mass and predicted retention times of peptides in library. There are two varieties of peptides in the library: peptides whose retention time predictions are derived from previous peptide identifications and therefore are of high precision, and peptides whose retention time predictions are derived from a sequence-based model and therefore have lower precision. We present a Bayesian statistical model that provides probability estimates for the correctness of each match by separately modeling the data distributions of correct matches and incorrect matches. For matches to peptides with high-precision retention time predictions, the model distinguishes correct matches from incorrect matches with high confidence. For matches to peptides having low-precision retention time predictions, match probabilities do not approach certainty; however, even moderate probability matches may provide biologically interesting findings, motivating further investigations.},
keywords={Bayesian methods;Biomedical engineering;Data analysis;Extraterrestrial measurements;Mass spectroscopy;Peptides;Proteins;Proteomics;Sequences;Time measurement;Algorithms;Automatic Data Processing;Bayes Theorem;Chromatography, Liquid;Humans;Mass Spectrometry;Monte Carlo Method;Peptides;Probability;Proteomics;Reproducibility of Results;Time Factors;Trypsin},
doi={10.1109/IEMBS.2008.4650030},
ISSN={1094-687X},
month={Aug},}
@INPROCEEDINGS{4630896,
author={Cheng-Hong Yang and Chang-Hsuan Ho and Li-Yeh Chuang},
booktitle={2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)},
title={Improved tag SNP selection using binary particle swarm optimization},
year={2008},
pages={854-860},
abstract={Single nucleotide polymorphisms (SNPs) hold much promise as a basis for disease-gene association. However, they are limited by the cost of genotyping the tremendous number of SNPs. It is therefore essential to select only informative subsets (tag SNPs) out of all SNPs. Several promising methods for tag SNP selection have been proposed, such as the haplotype block-based and block-free approaches. The block-free methods are preferred by some researchers because most of the block-based methods rely on strong assumptions, such as prior block-partitioning, bi-allelic SNPs, or a fixed number or locations for tagging SNPs. We employed the feature selection idea of binary particle swarm optimization (binary PSO) to find informative tag SNPs. This method is very efficient, as it does not rely on block partitioning of the genomic region. Using four public data sets, the method consistently identified tag SNPs with considerably better prediction ability than STAMPA. Moreover, this method retains its performance even when a very small number and 100% prediction accuracy are used for the tag SNPs.},
keywords={diseases;genetics;particle swarm optimisation;prediction theory;bi-allelic SNP;binary particle swarm optimization;block-based methods;block-free methods;disease-gene association;feature selection;prior block-partitioning;single nucleotide polymorphisms;tag SNP selection;Accuracy;Bioinformatics;Costs;Diseases;Genetics;Genomics;Humans;Particle swarm optimization;Partitioning algorithms;Tagging},
doi={10.1109/CEC.2008.4630896},
ISSN={1089-778X},
month={June},}
@INPROCEEDINGS{4602485,
author={C. Hurjui and C. Turcu and A. Graur},
booktitle={2008 11th International Conference on Optimization of Electrical and Electronic Equipment},
title={Management system of the products on warranty based on RFID technologies},
year={2008},
pages={231-236},
abstract={The RFID technology (radio frequency identification) is used in the view of data transmission, by the help of mobile transponders, known as tags and for receiving that information, by means of reading devices, known as readers. Radio frequency identification (RFID) has become specific for tracking the items and carrying out solutions of data achieving within the supply chains of enterprises, factories, trading companies or automation technologies. This present paper proposes creation of a computerized system dedicated to selling companies, manufacturers and service units, with a view of using products' information and estimating by a prediction algorithm the return time towards the customers of changed or repaired products being on warranty or post-warranty time.},
keywords={data communication;maintenance engineering;mobile radio;product life cycle management;radiofrequency identification;transponders;RFID technologies;automation technologies;computerized system;data transmission;mobile transponders;product management system;radio frequency identification;supply chains;Authentication;Business;Databases;Maintenance engineering;Radiofrequency identification;Security;Supply chains;RFID reader;RFID tag;prediction algorithm},
doi={10.1109/OPTIM.2008.4602485},
month={May},}
@INPROCEEDINGS{4459538,
author={E. Y. Chung and C. H. Kim and S. W. Chung},
booktitle={4th IEEE International Symposium on Electronic Design, Test and Applications (delta 2008)},
title={An Accurate and Energy-Efficient Way Determination Technique for Instruction Caches by Early Tab Matching},
year={2008},
pages={190-195},
abstract={This paper proposes an accurate and energy-efficient way determination (instead of prediction) technique for reducing energy consumption in the instruction cache by using early tag matching. Way prediction has been considered as one of the most efficient techniques to reduce energy consumption in the caches. The proposed scheme allows early tag matching for accurate way determination. With this feature, our scheme drastically improves the way determination accuracy compared to the previous way prediction techniques. To enable the early tag matching, the tag lookup stage is inserted prior to the fetch stage in the pipeline architecture. The tag matching is performed during the tag lookup stage, and then only one way is accessed during the fetch stage, leading to good energy efficiency. Simulation results show that the proposed technique reduces the energy consumption in the instruction cache by 55.1% on average. Moreover, our technique guarantees negligible performance degradation by overlapping two pipeline stages in case of branch misprediction.},
keywords={cache storage;instruction sets;memory architecture;pipeline processing;power aware computing;early tag matching;energy consumption reduction;energy-efficient way determination technique;instruction caches;pipeline architecture;tag lookup stage;Accuracy;Application software;Computer aided instruction;Degradation;Design engineering;Electronic equipment testing;Energy consumption;Energy efficiency;Pipelines;Power engineering and energy;Instruction cache;low power;way predictioin},
doi={10.1109/DELTA.2008.57},
month={Jan},}
@INPROCEEDINGS{4425311,
author={Shung Han Cho and Jinseok Lee and Sangjin Hong},
booktitle={2007 IEEE Conference on Advanced Video and Signal Based Surveillance},
title={Passive sensor based dynamic object association with particle filtering},
year={2007},
pages={206-211},
abstract={This paper develops and evaluates the threshold based algorithm proposed in [S.H. Cho, J. Lee, and S. Hong, "Passive Sensor Based Dynamic Object Association Method in Wireless Sensor Network," Proceedings of MWSCAS07 and NEWCAS07, Aug. 2007. ] for dynamic data association in wireless sensor networks. The sensor node incorporates RFID reader and acoustic sensor where the signals are fused for tracking and associating multiple objects. The RFID tag is used for object identification and acoustic sensor is used for estimating object movement. For the better data association, we apply the particle filtering for the prediction of an object. The algorithm with the particle filtering has an effect on increasing the association case where even objects overlap. The simulation result is compared to that using only the original algorithm. The association performance under single node coverage and multiple node coverage is evaluated as a function of sampling time.},
keywords={object detection;particle filtering (numerical methods);radiofrequency identification;sensor fusion;wireless sensor networks;RFID reader;acoustic sensor;dynamic data association;object identification;object movement estimation;particle filtering;passive sensor based dynamic object association;radiofrequency identification;threshold based algorithm;wireless sensor network;Acoustic sensors;Filtering algorithms;Particle filters;Passive filters;RFID tags;Radiofrequency identification;Sampling methods;Sensor phenomena and characterization;Target tracking;Wireless sensor networks},
doi={10.1109/AVSS.2007.4425311},
month={Sept},}
@INPROCEEDINGS{4413826,
author={Wen-Chih Peng and WangTing Huang and YiLing Chen and PeiChing Liao},
booktitle={2007 IEEE International Conference on Systems, Man and Cybernetics},
title={TagFree: Identifying users without tags in smart home environments},
year={2007},
pages={3690-3697},
abstract={Since family members have their unique features when living in a smart home environment, user identifications are able to achieve without any tags. In this paper, we propose TagFree system in which users freely move in a smart home environment and TagFree system is able to intelligently identify family member according to sensed data. Specifically, TagFree system consists of two phases: the training phase and the prediction phase. In the training phase, sensed data are collected and then, given a huge amount of sensed data, the profile of users, including the most common sensed data (i.e., tones, weights and location), are discovered. Once the profile of users is built up, in the prediction phase, we propose two scoring algorithms to generate likelihood scores according to the sensed data given. A simulation is implemented to verify the correctness of our proposed system and extensive experiments are conducted. Experimental results show that our proposed TagFree is able to achieve high accuracy of identifying family member without any tags. Furthermore, from experimental results, we also provided some guidelines to set some important parameters for TagFree.},
keywords={home computing;TagFree systems;family member;generate likelihood scores;prediction phase;scoring algorithms;smart home environments;training phase;Computer science;Guidelines;Intelligent sensors;Monitoring;Pervasive computing;Smart homes;Target tracking;Temperature measurement;Temperature sensors;Wireless sensor networks;Smart home;classification;pervasive computing;sensor networks},
doi={10.1109/ICSMC.2007.4413826},
ISSN={1062-922X},
month={Oct},}
@INPROCEEDINGS{4375562,
author={M. Park and D. L. Falcone and K. Y. Yun and K. M. Daniels},
booktitle={2007 IEEE 7th International Symposium on BioInformatics and BioEngineering},
title={Detection and Prediction of Alternative Splicing within Acceptor/Donor Sites in pre-mRNA of Arabidopsis thaliana},
year={2007},
pages={180-186},
abstract={Alternative splicing is an important process in gene expression. Presently, most studies aimed at detecting alternatively spliced genes use ESTs (expressed sequence tags). However, reliance on ESTs might have some weaknesses in predicting alternative splicing. It is difficult to predict whether or not alternative splicing exists for those genes where ESTs are not available. In addition, since the EST libraries are often not clearly organized and annotated, we can pick erroneous ESTs. To address these issues and to improve the quality of detection and prediction for alternative splicing, we propose a method that primarily uses pre-mRNAs. It is achieved by a decision tree algorithm using codons, three nucleotides, as attributes for each chromosome in Arabidopsis thaliana. Each decision tree shows that alternative and normal splicing have different splicing patterns according to triplet nucleotides. Based on the patterns, alternative splicing of unlabeled genes can also be predicted.},
keywords={biology computing;cellular biophysics;decision trees;genetics;molecular biophysics;Arabidopsis thaliana;acceptor sites;alternative splicing;chromosome;codons;decision tree algorithm;donor sites;expressed sequence tags;gene expression;nucleotides;pre-mRNA;Bioinformatics;DNA;Data mining;Gene expression;Genomics;Libraries;Probes;Proteins;Sequences;Splicing},
doi={10.1109/BIBE.2007.4375562},
month={Oct},}
@ARTICLE{4317567,
author={J. Keshet and S. Shalev-Shwartz and Y. Singer and D. Chazan},
journal={IEEE Transactions on Audio, Speech, and Language Processing},
title={A Large Margin Algorithm for Speech-to-Phoneme and Music-to-Score Alignment},
year={2007},
volume={15},
number={8},
pages={2373-2382},
abstract={We describe and analyze a discriminative algorithm for learning to align an audio signal with a given sequence of events that tag the signal. We demonstrate the applicability of our method for the tasks of speech-to-phoneme alignment (ldquoforced alignmentrdquo) and music-to-score alignment. In the first alignment task, the events that tag the speech signal are phonemes while in the music alignment task, the events are musical notes. Our goal is to learn an alignment function whose input is an audio signal along with its accompanying event sequence and its output is a timing sequence representing the actual start time of each event in the audio signal. Generalizing the notion of separation with a margin used in support vector machines for binary classification, we cast the learning task as the problem of finding a vector in an abstract inner-product space. To do so, we devise a mapping of the input signal and the event sequence along with any possible timing sequence into an abstract vector space. Each possible timing sequence therefore corresponds to an instance vector and the predicted timing sequence is the one whose projection onto the learned prediction vector is maximal. We set the prediction vector to be the solution of a minimization problem with a large set of constraints. Each constraint enforces a gap between the projection of the correct target timing sequence and the projection of an alternative, incorrect, timing sequence onto the vector. Though the number of constraints is very large, we describe a simple iterative algorithm for efficiently learning the vector and analyze the formal properties of the resulting learning algorithm. We report experimental results comparing the proposed algorithm to previous studies on speech-to-phoneme and music-to-score alignment, which use hidden Markov models. The results obtained in our experiments using the discriminative alignment algorithm are comparable to results of state-of-the-art systems.},
keywords={audio signal processing;iterative methods;learning (artificial intelligence);minimisation;music;signal classification;speech processing;speech synthesis;support vector machines;abstract inner-product space;abstract vector space;audio signal alignment;binary classification;discriminative alignment algorithm;event sequence;hidden Markov model;iterative algorithm;large margin algorithm;learning task;minimization problem;music-to-score alignment;speech-to-phoneme alignment;support vector machine;timing sequence;Algorithm design and analysis;Iterative algorithms;Machine learning;Multiple signal classification;Signal analysis;Signal mapping;Speech;Support vector machine classification;Support vector machines;Timing;Forced alignment;large margin and kernel methods;music;speech processing;support vector machines (SVMs)},
doi={10.1109/TASL.2007.903928},
ISSN={1558-7916},
month={Nov},}
@INPROCEEDINGS{4270267,
author={M. Kim and V. Pavlovic},
booktitle={2007 IEEE Conference on Computer Vision and Pattern Recognition},
title={Discriminative Learning of Dynamical Systems for Motion Tracking},
year={2007},
pages={1-8},
abstract={We introduce novel discriminative learning algorithms for dynamical systems. Models such as conditional random fields or maximum entropy Markov models outperform the generative hidden Markov models in sequence tagging problems in discrete domains. However, continuous state domains introduce a set of constraints that can prevent direct application of these traditional models. Instead, we suggest to learn generative dynamic models with discriminative cost functionals. For linear dynamical systems, the proposed methods provide significantly lower prediction error than the standard maximum likelihood estimator, often comparable to nonlinear models. As a result, the models with lower representational capacity but computationally more tractable than nonlinear models can be used for accurate and efficient state estimation. We evaluate the generalization performance of our methods on the 3D human pose tracking problem from monocular videos. The experiments indicate that the discriminative learning can lead to improved accuracy of pose estimation with no increase in computational cost of tracking.},
keywords={hidden Markov models;image motion analysis;image sequences;learning (artificial intelligence);maximum entropy methods;maximum likelihood estimation;pose estimation;state estimation;3D human pose tracking problem;conditional random fields;discriminative cost functionals;discriminative learning;generative hidden Markov model;linear dynamical systems;maximum entropy Markov model;maximum likelihood estimator;monocular videos;motion tracking;pose estimation;sequence tagging problems;state estimation;Cost function;Entropy;Heuristic algorithms;Hidden Markov models;Humans;Maximum likelihood estimation;Predictive models;State estimation;Tagging;Tracking},
doi={10.1109/CVPR.2007.383242},
ISSN={1063-6919},
month={June},}
@INPROCEEDINGS{4258542,
author={I. Aib and R. Boutaba},
booktitle={2007 10th IFIP/IEEE International Symposium on Integrated Network Management},
title={Business-Driven Optimization of Policy-Based Management solutions},
year={2007},
pages={254-263},
abstract={We consider whether the off-line compilation of a set of Service Level Agreements (SLAs) into low-level management policies can lead to the runtime maximization of the overall business profit for a service provider. Using a simple Web application hosting SLA template for a utility service provider, we derive low-level QoS management policies and validate their consistency. We show how the default first come first served (FCFS) mechanism for the runtime scheduling of triggered policies fails to deliver an all times maximum business profit for the service provider. To achieve a better business profit, first a penalty/reward model that is derived from the SLA Service Level Objectives (SLOs) is used to assign runtime utility tags to triggered policies. Then three policy scheduling algorithms, which are based on the prediction of the future state of the running SLAs, are used to drive the runtime actions of the Policy Decision Point (PDP). The prediction function per see involved the unsolved problem of predicting in realtime the evolution of the transient state of a variant of an M/M/Ct/Ct queue. A simple approximative solution to the latter problem is provided. Finally, using the VS policy simulator tool, comparative simulation results for the business profit generated by each of the proposed policy scheduling algorithms are presented. VS is a novel tool which we have developed to respond to the increasing need of benchmarking SLA and policy-based management solutions.},
keywords={Web services;business data processing;optimisation;quality of service;queueing theory;scheduling;utility theory;Web application;business-driven optimization;first come first serve mechanism;low-level QoS management policy;policy decision point;policy scheduling algorithm;policy-based management solution;prediction function;queueing theory;runtime business profit maximization;service level agreement;service level objective;utility service provider;Application software;Computer science;Cost function;Heart;Management information systems;Quality management;Quality of service;Runtime;Scheduling algorithm;Stability},
doi={10.1109/INM.2007.374790},
ISSN={1573-0077},
month={May},}
@INPROCEEDINGS{4193379,
author={Z. Qian and D. Metaxas and L. Axel},
booktitle={2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro},
title={LEARNING METHODS IN SEGMENTATION OF CARDIAC TAGGED MRI},
year={2007},
pages={688-691},
abstract={In this paper we present a learning framework for segmentation and tracking in 2D cardiac tagged MRI sequences. We employ a transformed component analysis (TCA) algorithm to estimate the shape variations, and at the same time, eliminate the rotation distortions of the training shapes. This method also integrates the motion and the static local appearance features and generates accurate boundary criteria via a boosting approach. We extend the conventional Adaboost classifier into a posterior probability form, which can be embedded in a particle filter based shape tracking framework. The TCA shape representation is used to constrain the shape variations and lower the dimensionality, so that it makes the tracking process more robust and faster. We also learn two shape dynamic models for systole and diastole separately to predict the shape evolution. Our segmentation and tracking method incorporates the static appearance, the motion appearance, the shape constraints, and the dynamic prediction in a unified way. The proposed method has been applied to 50 tagged MRI sequences. The experimental results show the accuracy and robustness of our approach},
keywords={biomedical MRI;cardiology;image classification;image motion analysis;image segmentation;image sequences;learning (artificial intelligence);medical image processing;probability;shape measurement;tracking;Adaboost classifier;MRI sequences;boosting approach;boundary criteria;cardiac MRI;diastole;dynamic prediction;image segmentation;image tracking;learning methods;magnetic resonance imaging;motion appearance;motion integration;particle filter;posterior probability form;rotation distortions;shape constraints;shape dynamic models;shape evolution;shape tracking framework;shape variations;static appearance;static local appearance features;systole;tagged MRI;training shapes;transformed component analysis;Active shape model;Boosting;Heart;Image motion analysis;Image segmentation;Learning systems;Magnetic resonance imaging;Myocardium;Principal component analysis;Robustness},
doi={10.1109/ISBI.2007.356945},
ISSN={1945-7928},
month={April},}
@ARTICLE{4118117,
author={J. He and A. Zelikovsky},
journal={IEEE Transactions on NanoBioscience},
title={Informative SNP Selection Methods Based on SNP Prediction},
year={2007},
volume={6},
number={1},
pages={60-67},
abstract={The search for the association between complex diseases and single nucleotide polymorphisms (SNPs) or haplotypes has recently received great attention. For these studies, it is essential to use a small subset of informative SNPs, i.e., tag SNPs, accurately representing the rest of the SNPs. Tag SNP selection can achieve: 1) considerable budget savings by genotyping only a limited number of SNPs and computationally inferring all other SNPs or 2) necessary reduction of the huge SNP sets (obtained, e.g., from Affymetrix) for further fine haplotype analysis. In this paper, we show that the tag SNP selection strongly depends on how the chosen tags will be used-advantage of one tag set over another can only be considered with respect to a certain prediction method. We show how to separate tag selection from SNP prediction and propose greedy and local-minimization algorithms for tag SNP selection. We give two novel approaches to SNP prediction based on multiple linear regression (MLR) and support vector machines (SVMs). An extensive experimental study on various datasets including ten regions from hapMap project shows that the MLR prediction combined with stepwise tag selection uses fewer tags than the state-of-the-art method of Halperin The MLR-based method also uses on average 30% fewer tags than IdSelect for statistical covering all SNPs. The tag selection based on SVM SNP prediction uses fewer tags to achieve the same prediction accuracy as the methods of Halldorsson},
keywords={DNA;diseases;greedy algorithms;medical computing;minimisation;molecular biophysics;molecular configurations;polymorphism;prediction theory;regression analysis;support vector machines;Affymetrix;SNP prediction;SVM;complex diseases;genotyping;greedy algorithm;hapMap project;haplotypes;informative SNP selection methods;local-minimization algorithm;multiple linear regression;single nucleotide polymorphisms;stepwise tag selection;support vector machines;tag selection separation;Accuracy;Bioinformatics;Biological cells;Computer science;Diseases;Genomics;Helium;Linear regression;Prediction methods;Support vector machines;Genotypes;haplotypes;informative single nucleotide polymorphism (SNP);single nucleotide polymorphism (SNP);tag selection;Algorithms;Artificial Intelligence;Base Sequence;Computer Simulation;DNA Mutational Analysis;Expressed Sequence Tags;Genotype;Haplotypes;Linkage Disequilibrium;Models, Genetic;Models, Statistical;Molecular Sequence Data;Pattern Recognition, Automated;Polymorphism, Single Nucleotide;Sequence Alignment},
doi={10.1109/TNB.2007.891901},
ISSN={1536-1241},
month={March},}
@INPROCEEDINGS{4075737,
author={A. P. Sakis Meliopoulos and G. J. Cokkinides and O. Wasynczuk and E. Coyle and M. Bell and C. Hoffmann and C. Nita-Rotaru and T. Downar and L. Tsoukalas and R. Gao},
booktitle={2006 IEEE PES Power Systems Conference and Exposition},
title={PMU Data Characterization and Application to Stability Monitoring},
year={2006},
pages={151-158},
abstract={This paper provides a methodology to characterize the accuracy of PMU data (GPS-synchronized) and the applicability of this data for monitoring system stability. GPS-synchronized equipment (PMUs) is in general higher precision equipment as compared to typical SCADA systems. Conceptually, PMU data are time tagged with precision better than 1 microsecond and magnitude accuracy that is better than 0.1%. This potential performance is not achieved in an actual field installation due to errors from instrumentation channels and system imbalances. Presently, PMU data precision from substation installed devices is practically unknown. On the other hand, specific applications of PMU data require specific accuracy of data. Applications vary from simple system monitoring to wide area protection and control to voltage instability prediction and transient stability monitoring. The paper focuses on the last application, i.e. transient stability monitoring. We propose an approach that is based on the energy functions (Lyapunov indirect method). Specifically, we provide a methodology for determining the required data accuracy for the reliable real time estimation of the energy function. When the data meet these requirements, the estimated energy function can be visualized and animated providing a powerful visual tool for observing the transient stability or instability of the system},
keywords={Global Positioning System;Lyapunov methods;computerised instrumentation;phase measurement;power engineering computing;power system measurement;power system transient stability;GPS-synchronized equipment;Lyapunov indirect method;PMU data characterization;energy functions;instrumentation channels;phasor measurement unit;substation installed devices;system stability monitoring;transient stability monitoring;voltage instability prediction;wide area protection;Control systems;Data visualization;Instruments;Monitoring;Phasor measurement units;Power system reliability;SCADA systems;Stability;Substation protection;Voltage control},
doi={10.1109/PSCE.2006.296290},
month={Oct},}
@INPROCEEDINGS{4076612,
author={G. J. Cokkinides and A. P. Sakis Meliopoulos and G. Stefopoulos and R. Alaileh and A. Mohan},
booktitle={System Sciences, 2007. HICSS 2007. 40th Annual Hawaii International Conference on},
title={Visualization and Characterization of Stability Swings via GPS-Synchronized Data},
year={2007},
pages={120-120},
abstract={This paper provides a methodology to characterize the accuracy of PMU data (GPS-synchronized) and the applicability of this data for monitoring system stability via visualization methods. GPS-synchronized equipment (PMUs) is in general higher precision equipment as compared to typical SCADA systems. Conceptually, PMU data are time tagged with precision better than 1 microsecond and magnitude accuracy that is better than 0.1%. This potential performance is not achieved in an actual field installation due to errors from instrumentation channels and system imbalances. Presently, PMU data precision from substation installed devices is practically unknown. On the other hand, specific applications of PMU data require specific accuracy of data. Applications vary from simple system monitoring to wide area protection and control to voltage instability prediction and transient stability monitoring. The paper focuses on the last application, i.e. transient stability monitoring. We propose an approach that is based on accurate evaluation of the system energy function (Lyapunov indirect method) and extraction of stability properties from the energy function. Specifically, we provide a methodology for determining the required data accuracy for the reliable real time estimation of the energy function. When the data meet these requirements, the estimated energy function can be visualized and animated providing a powerful visual tool for observing the transient stability or instability of the system},
keywords={Global Positioning System;data visualisation;power system analysis computing;power system measurement;power system transient stability;substations;GPS-synchronized PMU data;animation;energy function estimation;power system stability;stability swings;substations;transient stability monitoring;visualization;Control systems;Data mining;Data visualization;Instruments;Monitoring;Phasor measurement units;SCADA systems;Stability;Substation protection;Voltage control},
doi={10.1109/HICSS.2007.607},
ISSN={1530-1605},
month={Jan},}
@INPROCEEDINGS{4057919,
author={V. Rizzoli and A. Costanzo and M. Rubini and D. Masotti},
booktitle={2006 European Microwave Conference},
title={Rigorous Investigation of Interactions between Passive RFID Tags by Means of Nonlinear/Electromagnetic Co-simulation},
year={2006},
pages={722-725},
abstract={The paper proposes a rigorous approach to the prediction of electromagnetic interaction between tags of an RFID system powered by the incident field radiated by the reader. The design of a 2.45 GHz band passive transponder and its integrated antenna is first developed making use of a numerical optimization based on EM analysis coupled with the harmonic-balance technique. A couple of tags, located at varying mutual positions, is then analysed under digitally modulated RF drive. The results show a significant modification of the electrical and radiation performance of each tag and suggest the need for a multi-tag design procedure to account for these coupling effects},
keywords={harmonic analysis;interference (signal);radiofrequency identification;transponders;2.45 GHz;harmonic analysis;interference;nonlinear circuits;nonlinear/electromagnetic co-simulation;passive RFID tags;passive transponder;Design optimization;Digital modulation;Electromagnetic fields;Electromagnetic radiation;Harmonic analysis;Mutual coupling;Passive RFID tags;RFID tags;Radio frequency;Transponders;harmonic analysis;interference;nonlinear circuits;passive RFID},
doi={10.1109/EUMC.2006.281003},
month={Sept},}
@ARTICLE{4016175,
author={A. I. Veress and W. P. Segars and J. A. Weiss and B. M. W. Tsui and G. T. Gullberg},
journal={IEEE Transactions on Medical Imaging},
title={Normal and Pathological NCAT Image and Phantom Data Based on Physiologically Realistic Left Ventricle Finite-Element Models},
year={2006},
volume={25},
number={12},
pages={1604-1616},
abstract={The four-dimensional (4-D) NURBS-based cardiac-torso (NCAT) phantom, which provides a realistic model of the normal human anatomy and cardiac and respiratory motions, is used in medical imaging research to evaluate and improve imaging devices and techniques, especially dynamic cardiac applications. One limitation of the phantom is that it lacks the ability to accurately simulate altered functions of the heart that result from cardiac pathologies such as coronary artery disease (CAD). The goal of this work was to enhance the 4-D NCAT phantom by incorporating a physiologically based, finite-element (FE) mechanical model of the left ventricle (LV) to simulate both normal and abnormal cardiac motions. The geometry of the FE mechanical model was based on gated high-resolution X-ray multislice computed tomography (MSCT) data of a healthy male subject. The myocardial wall was represented as a transversely isotropic hyperelastic material, with the fiber angle varying from -90deg at the epicardial surface, through 0deg at the midwall, to 90deg at the endocardial surface. A time-varying elastance model was used to simulate fiber contraction, and physiological intraventricular systolic pressure-time curves were applied to simulate the cardiac motion over the entire cardiac cycle. To demonstrate the ability of the FE mechanical model to accurately simulate the normal cardiac motion as well as the abnormal motions indicative of CAD, a normal case and two pathologic cases were simulated and analyzed. In the first pathologic model, a subendocardial anterior ischemic region was defined. A second model was created with a transmural ischemic region defined in the same location. The FE-based deformations were incorporated into the 4-D NCAT cardiac model through the control points that define the cardiac structures in the phantom which were set to move according to the predictions of the mechanical model. A simulation study was performed using the FE-NCAT combination to investigate how- - the differences in contractile function between the subendocardial and transmural infarcts manifest themselves in myocardial Single photon emission computed tomography (SPECT) images. The normal FE model produced strain distributions that were consistent with those reported in the literature and a motion consistent with that defined in the normal 4-D NCAT beating heart model based on tagged magnetic resonance imaging (MRI) data. The addition of a subendocardial ischemic region changed the average transmural circumferential strain from a contractile value of -0.09 to a tensile value of 0.02. The addition of a transmural ischemic region changed average circumferential strain to a value of 0.13, which is consistent with data reported in the literature. Model results demonstrated differences in contractile function between subendocardial and transmural infarcts and how these differences in function are documented in simulated myocardial SPECT images produced using the 4-D NCAT phantom. Compared with the original NCAT beating heart model, the FE mechanical model produced a more accurate simulation for the cardiac motion abnormalities. Such a model, when incorporated into the 4-D NCAT phantom, has great potential for use in cardiac imaging research. With its enhanced physiologically based cardiac model, the 4-D NCAT phantom can be used to simulate realistic, predictive imaging data of a patient population with varying whole-body anatomy and with varying healthy and diseased states of the heart that will provide a known truth from which to evaluate and improve existing and emerging 4-D imaging techniques used in the diagnosis of cardiac disease},
keywords={biomedical MRI;blood vessels;cardiology;deformation;diseases;finite element analysis;haemodynamics;phantoms;physiological models;single photon emission computed tomography;SPECT;average transmural circumferential strain;cardiac motion;coronary artery disease;deformations;epicardial surface;fiber contraction;finite-element mechanical model;four-dimensional NURBS-based cardiac-torso phantom;gated high-resolution X-ray multislice computed tomography;heart;magnetic resonance imaging;medical imaging;myocardial wall;normal NCAT image;normal human anatomy;pathological NCAT image;physiological intraventricular systolic pressure-time curves;physiologically realistic left ventricle finite element models;respiratory motion;single photon emission computed tomography images;strain distributions;subendocardial anterior ischemic region;subendocardial infarcts;subendocardial ischemic region;time-varying elastance model;transmural infarcts;transmural ischemic region;transversely isotropic hyperelastic material;Computational modeling;Coronary arteriosclerosis;Finite element methods;Heart;Imaging phantoms;Iron;Magnetic field induced strain;Myocardium;Pathology;Predictive models;Cardiac imaging research;NURBS-based cardiac-torso (NCAT);SPECT phantom;finite element (FE);ischemia;left ventricle;mechanical model;Algorithms;Artifacts;Computer Simulation;Finite Element Analysis;Heart Ventricles;Humans;Imaging, Three-Dimensional;Models, Anatomic;Models, Cardiovascular;Movement;Phantoms, Imaging;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Tomography, X-Ray Computed;Ventricular Dysfunction, Left},
doi={10.1109/TMI.2006.884213},
ISSN={0278-0062},
month={Dec},}
@ARTICLE{4014172,
author={L. C. Lynnworth and R. Cohen and J. L. Rose and J. O. Kim and E. R. Furlong},
journal={IEEE Sensors Journal},
title={Vortex Shedder Fluid Flow Sensor},
year={2006},
volume={6},
number={6},
pages={1488-1496},
abstract={This paper was motivated by the possibility of extracting from a vortex-shedding strut, in addition to flow velocity V, information on fluid density rho or temperature T, and combining them to obtain mass flowrate. Shedder shapes were diamond and bluff polygon. These shapes are compared as vortex shedders in flowing air or water. V is obtained from the shedding frequency f. In water, V ranged from 0.5 to 4 m/s and, in air, from 0.3 to 15 m/s. Clamp-on ultrasonic transducers generated and, on the diagonally opposite side of the pipe, received the beam that obliquely traversed the wake of the shedder. A continuous-wave transmission across the fluid was modulated by vortices passing through the beam. The modulation frequency yielded f. In air, the bluff polygon yielded f over a 50 : 1 flow range, which was better than the diamond's flow range of 20 : 1. Whether the shedder was a diamond or a bluff polygon, and the fluid air or water, f correlated approximately linearly with the flow velocity V. Using one path of an ultrasonic tag clamp-on flowmeter system, the measured vortex-shedding frequencies were found to be in reasonable agreement with computational-fluid-dynamic predictions for diamond and for bluff-polygon struts. Collectively, the pipe Reynolds number (Re) range was 1000-200 000. With both shedders, operation was demonstrated in laminar- and turbulent-flow regimes. In water flow tests, rotating the diamond (aspect ratio=3) through 90deg about its axis, from broadside to airfoil, diminished the Strouhal number by 17%. When the diamond shedder was tested as a torsional density sensor in flowing air or water, no torsional transit time effect of V was observed, confirming for the first time a 1989 prediction. The negative result in flowing water implies that there were no attached bubbles or microbubbles},
keywords={boundary layer turbulence;computational fluid dynamics;flow sensors;laminar flow;ultrasonic transducers;vortices;Strouhal number;bluff polygon shedder;computational-fluid-dynamic predictions;continuous-wave transmission;diamond shedder;flow-velocity sensor;laminar flow;torsional density sensor;turbulent flow;ultrasonic transducers;vortex shedder fluid flow sensor;vortex shedders;vortex-shedding strut;water flow tests;Data mining;Fluid flow;Frequency measurement;Frequency modulation;Linear approximation;Optical modulation;Shape;Temperature sensors;Testing;Ultrasonic transducers;Flow-velocity sensor;vortex shedder},
doi={10.1109/JSEN.2006.883856},
ISSN={1530-437X},
month={Dec},}
@INPROCEEDINGS{1709472,
author={A. P. S. Meliopoulos and G. J. Cokkinides and O. Wasynczuk and E. Coyle and M. Bell and C. Hoffmann and C. Nita-Rotaru and T. Downar and L. Tsoukalas and R. Gao},
booktitle={2006 IEEE Power Engineering Society General Meeting},
title={PMU data characterization and application to stability monitoring},
year={2006},
pages={8 pp.-},
abstract={This paper provides a methodology to characterize the accuracy of PMU data (GPS-synchronized) and the applicability of this data for monitoring system stability. GPS-synchronized equipment (PMUs) is in general higher precision equipment as compared to typical SCADA systems. Conceptually, PMU data are time tagged with precision better than 1 microsecond and magnitude accuracy that is better than 0.1%. This potential performance is not achieved in an actual field installation due to errors from instrumentation channels and system imbalances. Presently, PMU data precision from substation installed devices is practically unknown. On the other hand, specific applications of PMU data require specific accuracy of data. Applications vary from simple system monitoring to wide area protection and control to voltage instability prediction and transient stability monitoring. The paper focuses on the last application, i.e. transient stability monitoring. We propose an approach that is based on the energy functions (Lyapunov indirect method). Specifically, we provide a methodology for determining the required data accuracy for the reliable real time estimation of the energy function. When the data meet these requirements, the estimated energy function can be visualized and animated providing a powerful visual tool for observing the transient stability or instability of the system},
keywords={Lyapunov methods;SCADA systems;computerised instrumentation;phase measurement;power engineering computing;power system measurement;power system transient stability;GPS-synchronization;Lyapunov indirect method;PMU data characterization;SCADA systems;energy functions;instrumentation channels;real time estimation;substation installed devices;system imbalances;system stability monitoring;transient stability monitoring;voltage instability prediction;wide area protection;Control systems;Data visualization;Instruments;Monitoring;Phasor measurement units;Power system reliability;SCADA systems;Stability;Substation protection;Voltage control;Data Accuracy;Energy Function;GPS-synchronization;PMU;Transient Stability},
doi={10.1109/PES.2006.1709472},
ISSN={1932-5517},
month={},}
@INPROCEEDINGS{1607275,
author={S. Harrusi and A. Averbuch and A. Yehudai},
booktitle={Data Compression Conference (DCC'06)},
title={XML syntax conscious compression},
year={2006},
pages={10 pp.-411},
abstract={XML is the standard format of content representation and sharing on the Web. XML is a highly verbose language, especially regarding the duplication of meta-data in the form of elements and attributes. As XML content is becoming more widespread so is the demand to compress XML data volume. The paper presents the best XML compression ratios reported to date. Its advantage over other XML compression techniques is that it uses syntactic information to enhance compression. Therefore, it is a fully syntactic based XML compression. The syntactic information is parsed from XML documents by an innovative XML parser. We developed a new XML parser-generator for that purpose. Our parser-generator is based on a syntactic dictionary (DTD, XML-Schema, etc.) of the XML in order to create an efficient and compact XML parsers. This XML parser-generator is adopted to streaming technologies and can be used in a wide variety of XML applications such as validators, converters, gateways, routers, browsers editors etc. The parsers' symbols are encoded by a partial prediction matching (PPM) codec. We compare between the performance of our algorithm and other existing XML compression techniques. The proposed compression algorithm achieves better compression ratio in comparison to other XML compression techniques that do not utilize syntactic structure. The superiority of our compression technique is more evident when it is tested on XML data sets that contain only tags and not free text},
keywords={XML;computational linguistics;data compression;grammars;meta data;XML data sets;XML syntax conscious compression;compression enhancement;metadata duplication;parser-generator;partial prediction matching codec;syntactic dictionary;verbose language;Codecs;Compression algorithms;Computer science;Data compression;Dictionaries;Production;Tagging;Testing;Uniform resource locators;XML},
doi={10.1109/DCC.2006.85},
ISSN={1068-0314},
month={March},}
@INPROCEEDINGS{1610138,
author={I. Jalaly and I. D. Robertson},
booktitle={2005 European Microwave Conference},
title={Capacitively-tuned split microstrip resonators for RFID barcodes},
year={2005},
volume={2},
pages={4 pp.-},
abstract={A new method of realising RF barcodes is presented using arrays of identical microstrip dipoles capacitively tuned to be resonant at different frequencies within the desired licensed-free ISM bands. When interrogated, the reader detects each dipole's resonance frequency and with n resonant dipoles, potentially 2n-1 items in the field can be tagged and identified. Results for RF barcode elements in the 5.8 GHz band are presented. It is shown that with accurate centre frequency prediction and by operating over multiple ISM and other license-exempt bands, a useful number of information bits can be realised. Further increase may be possible using ultra-wideband (UWB) technology. Low cost lithographic printing techniques based on using metal ink on low cost substrates could lead to an economical alternative to current RFID systems in many applications.},
keywords={microstrip antenna arrays;microstrip resonators;microwave antenna arrays;radio tracking;radiofrequency identification;ultra wideband technology;5.8 MHz;licensed-free ISM bands;microstrip antennas;microstrip resonators;radio frequency identification;radio tracking;ultra wideband technology;Costs;Ink;Microstrip antenna arrays;Microstrip resonators;Printing;Radio frequency;Radiofrequency identification;Resonance;Resonant frequency;Ultra wideband technology},
doi={10.1109/EUMC.2005.1610138},
month={Oct},}
@INPROCEEDINGS{1609233,
author={R. G. Wright and M. Zgol and D. Adebimpe and E. Keenan and R. Mulligan and L. V. Kirkland},
booktitle={IEEE Autotestcon, 2005.},
title={Multiresolution nanoscale sensor-based circuit board testing},
year={2005},
pages={766-772},
abstract={This paper describes a novel approach to printed circuit board testing capable of providing unprecedented failure detection and prognostic capabilities. In contrast to today's bulky automatic test equipment (ATE) and expensive test program sets (TPSs) that perform simple parametric testing, this approach utilizes nanoscale sensor technology in conjunction with novel molecular electronics-based computational capabilities to sense the physical and chemical bi-products of electronic component degradation and failure directly at the circuit board itself, combined with terahertz sensing to localize defect parameters within the circuit board and electronic components. This approach lends itself to the detection and prediction of entire classes of anomalies, degraded performance, and failures that are not capable of being detected using the latest state-of-the-art ATE or other test equipment performing end-to-end diagnostic testing of individual signal parameters. This greater performance comes with a price tag that is smaller in nonrecurring development and recurring maintenance costs},
keywords={automatic test equipment;failure analysis;molecular electronics;nanoelectronics;printed circuit testing;automatic test equipment;defect parameter localization;electronic component degradation;end-to-end diagnostic testing;failure detection;molecular electronics;multiresolution nanoscale sensor;printed circuit board testing;signal parameters;terahertz sensing;test program sets;Automatic testing;Chemical sensors;Chemical technology;Circuit testing;Degradation;Electronic components;Electronic equipment testing;Performance evaluation;Printed circuits;Signal resolution},
doi={10.1109/AUTEST.2005.1609233},
ISSN={1088-7725},
month={Sept},}
@INPROCEEDINGS{1592316,
author={Xiao Yong and Yang Yanping and Zhou Xingming},
booktitle={Eighth International Conference on High-Performance Computing in Asia-Pacific Region (HPCASIA'05)},
title={Revised stride data value predictor design},
year={2005},
pages={6 pp.-531},
abstract={Stride data value predictor is widely used by researchers in data value prediction study. Compared with context-based hybrid data value predictors, stride data value predictors are simple. But when encountering non-stride repeated sequences, a stride value predictor does not perform as well as a context-based hybrid data value predictor. In this paper, a revised stride data value predictor is introduced. With a little augment to a traditional stride data value predictor, the new predictor can make correct predictions on some patterns that can only be done by the context-based data value predictors. Simulation results show that the new predictor works well with most value predictable instructions. Design decisions such as predictor size, confidence mechanism and storing partial tag are analyzed},
keywords={data analysis;context-based data value predictor;stride data value predictor design;value predictable instruction;Bandwidth;Costs;Counting circuits;Distributed processing;History;Laboratories;Predictive models},
doi={10.1109/HPCASIA.2005.88},
month={July},}
@INPROCEEDINGS{1592202,
author={J. Adiego and P. de la Fuente and G. Navarro},
booktitle={Sixth Mexican International Conference on Computer Science (ENC'05)},
title={Combining structural and textual contexts for compressing semistructured databases},
year={2005},
pages={68-73},
abstract={We describe a compression technique for semistructured documents, called SCMPPM, which combines the prediction by partial matching technique with structural contexts model (SCM) technique. SCMPPM takes advantage of the context information usually implicit in the structure of the text. The idea is to use a separate PPM model to compress the text that lies inside each different structure type (e.g., different XML tag). The intuition is that the distribution of the texts that belong to a given structure type should be similar, and different from that of other structure types. This should allow PPM to make better predictions. We test our idea against plain PPM modelling, as well as against other structure-aware techniques. Results show that the new compression method obtains significant improvements in compression ratios.},
keywords={data compression;database management systems;text analysis;XML tag;compression technique;partial matching;semistructured database;semistructured document;structural context model;textual context;Compressors;Context modeling;Databases;Huffman coding;Libraries;Natural languages;Predictive models;Testing;Vocabulary;XML;Compression Model;PPM;Semistructured Documents.},
doi={10.1109/ENC.2005.15},
ISSN={1550-4069},
month={Sept},}
@ARTICLE{1593376,
author={D. Puccio and D. C. Malocha and N. Saldanha and D. R. Gallagher and J. H. Hines},
journal={IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
title={Orthogonal frequency coding for SAW tagging and sensors},
year={2006},
volume={53},
number={2},
pages={377-384},
abstract={Surface acoustic wave (SAW)-based sensors can offer wireless, passive operation in numerous environments, and various device embodiments are used for retrieval of the sensed data information. Single sensor systems typically can use a single carrier frequency and a simple device embodiment because tagging is riot required. In a multisensor environment, it is necessary to both identify the sensor and retrieve the sensed information. This paper presents the concept of orthogonal frequency coding (OFC) for implications to SAW sensor technology. The OFC offers all advantages inherent to spread spectrum communications, including enhanced processing gain and lower interrogation power spectral density (PSD). It is shown that the time ambiguity in the OFC compressed pulse is significantly reduced as compared with a single frequency tag having the same code length, and additional coding can be added using a pseudo-noise (PN) sequence. The OFC approach is general and should be applicable to many differing SAW sensors for temperature, pressure, liquid, gases, etc. Device embodiments are shown, and a potential transceiver is described. Measured device results are presented and compared with coupling of modes (COM) model predictions to demonstrate performance. Devices then are used in computer simulations of the proposed transceiver design, and the results of an OFC sensor system are discussed.},
keywords={pseudonoise codes;sensor fusion;spread spectrum communication;surface acoustic waves;SAW tagging;coupling of modes model;multisensor environment;orthogonal frequency coding;power spectral density;pseudo-noise sequence;spread spectrum communications;surface acoustic wave;Acoustic sensors;Acoustic waves;Frequency;Information retrieval;Sensor systems;Surface acoustic wave devices;Surface acoustic waves;Tagging;Temperature sensors;Transceivers;Computer-Aided Design;Equipment Design;Equipment Failure Analysis;Information Storage and Retrieval;Product Labeling;Radio Waves;Telecommunications;Telemetry},
doi={10.1109/TUFFC.2006.1593376},
ISSN={0885-3010},
month={Feb},}
@INPROCEEDINGS{1581574,
author={A. Masters and K. Michael},
booktitle={Second IEEE International Workshop on Mobile Commerce and Services},
title={Humancentric Applications of RFID Implants: The Usability Contexts of Control, Convenience and Care},
year={2005},
pages={32-41},
abstract={Recent developments in the area of RFID have seen the technology expand from its role in industrial and animal tagging applications, to being implantable in humans. With a gap in literature identified between current technological development and future humancentric possibility, little has been previously known about the nature of contemporary humancentric applications. This paper utilizes usability context analyses, to provide a cohesive study on the current development state of humancentric applications, detached from the emotion and prediction which plagues this particular technology},
keywords={radiofrequency identification;RFID implants;animal tagging;human tagging;humancentric RFID applications;humancentric applications;industrial tagging;Application software;Computer industry;Computer science;Humans;Implants;Information technology;National security;Radiofrequency identification;Transponders;Usability},
doi={10.1109/WMCS.2005.11},
month={July},}
@INPROCEEDINGS{1579798,
author={A. P. Sakis Meliopoulos and G. J. Cokkinides and F. Galvan and B. Fardanesh},
booktitle={Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)},
title={GPS-Synchronized Data Acquisition: Technology Assessment and Research Issues},
year={2006},
volume={10},
pages={244c-244c},
abstract={GPS-synchronized equipment (PMUs) is in general higher precision equipment as compared to typical SCADA systems. Conceptually, PMU data are time tagged with accuracy of better than 1 microsecond and magnitude accuracy that is better than 0.1%. This potential performance is not achieved in an actual field installation due to errors from instrumentation channels and system imbalances. Presently, PMU data precision from substation installed devices is practically unknown. On the other hand, specific applications of PMU data require specific accuracy of data. Applications vary from simple system monitoring to wide area protection and control to voltage instability prediction. Each application may have different accuracy requirements. For example for simple system monitoring in steady state highly accurate data may not be critical while for transient instability prediction high precision may be critical. For addressing data precision requirements for a variety of applications, it is necessary to quantify the accuracy of the collected PMU data. We discuss data precision requirements for a variety of applications and we propose a methodology for characterizing data errors. In particular, we propose a new approach for improving data accuracy via estimation methods. The proposed methodology quantifies the expected error of the filtered data. Examples are provided that define the instrumentation requirements for specific applications.},
keywords={Data Accuracy;GPS-synchronized equipment;State Estimation;Calibration;Control systems;Data acquisition;Error correction;Instrument transformers;Monitoring;Phasor measurement units;SCADA systems;State estimation;Voltage control;Data Accuracy;GPS-synchronized equipment;State Estimation},
doi={10.1109/HICSS.2006.199},
ISSN={1530-1605},
month={Jan},}
@INPROCEEDINGS{1574051,
author={D. Puccio and D. Malocha and N. Saldanha},
booktitle={Proceedings of the 2005 IEEE International Frequency Control Symposium and Exposition, 2005.},
title={Implementation of orthogonal frequency coded SAW devices using apodized reflectors},
year={2005},
pages={892-896},
abstract={Recently, orthogonal frequency coding (OFC) has been presented as a novel method for coding SAW tags and sensors (Malocha et al.,2004). Orthogonal frequency coding is a spread spectrum technique and has been shown to provide enhanced processing gain and reduced time ambiguity resulting in greater range and increased sensitivity when compared with single carrier frequency devices. The sensor works both as a tag and a sensor with the ability to send back "tagged" sensor information in a multi-sensor environment. The tag information is provided by a series of reflectors which map into a known chip sequence. The time-chip- sequence is coded by differing OFC and PN sequences. Therefore, the implementation of an OFC sensor requires reflectors having differing local carrier frequencies. In the case of narrow fractional bandwidths or high reflectivity (such as on LiNbO3), it is desirable to adjust the reflectivity per electrode in the various chips. For varying system requirements, the use of weighted reflectors is an option; both apodization and variable weighted reflectors are investigated. Experimental results on cosine weighted apodized reflectors will be compared to COM predictions on YZ LiNbO3. This paper presents several OFC SAW device embodiments that are employed using wideband input transducers and multiple weighted reflector gratings. The devices operate in the differential mode using gratings on either side of the transducer. The advantages of using the weighted reflector gratings in OFC SAW devices are discussed. OFC temperature sensor device experimental results are presented using weighted reflectors to obtain the proper time coded response and compared to predictions},
keywords={sequential codes;surface acoustic wave sensors;temperature sensors;LiNbO3;OFC SAW device;OFC sensor;PN sequences;apodized reflectors;multisensor environment;orthogonal frequency coding;single carrier frequency devices;spread spectrum technique;temperature sensor device;time-chip-sequence;weighted reflector gratings;Bandwidth;Electrodes;Frequency;Gratings;Reflectivity;Spread spectrum communication;Surface acoustic wave devices;Surface acoustic waves;Transducers;Wideband},
doi={10.1109/FREQ.2005.1574051},
ISSN={2327-1914},
month={Aug},}
@INPROCEEDINGS{1572183,
author={V. V. Stankovic and N. Z. Milenkovic},
booktitle={TELSIKS 2005 - 2005 uth International Conference on Telecommunication in ModernSatellite, Cable and Broadcasting Services},
title={DRAM Controller with a Complete Predictor: Preliminary Results},
year={2005},
volume={2},
pages={593-596},
abstract={In the arsenal of solutions for computer memory system performance improvement, predictors have gained an increasing role in the past years. They enable hiding the latencies when accessing cache or main memory. Recently the technique of using temporal parameters of cache memory accesses and tag patterns observing has been applied by some authors for prediction of data prefetching. In this paper a possibility of applying analog techniques on controlling DRAM rows opening/closing, is being researched. Obtained results confirm such a possibility, in a form of a complete predictor, which predicts not only when to close the currently open row but also which is the next row to be opened. Using such a predictor can decrease the average DRAM latency, which is very important in many areas, including telecommunications},
keywords={DRAM chips;DRAM controller;analog techniques;computer memory system;data prefetching;Cache memory;DRAM chips;Delay;Digital images;Prefetching;Random access memory;System performance;Table lookup;Telecommunication buffers;Telecommunication control;DRAM;DRAM controller;latency;policy;predictor},
doi={10.1109/TELSKS.2005.1572183},
month={Sept},}
@INPROCEEDINGS{1563039,
author={S. Seznec},
booktitle={Computer Architecture, 1996 23rd Annual International Symposium on},
title={Don't Use the Page Number, but a Pointer to It},
year={1996},
pages={104-104},
abstract={Most newly announced high performance microprocessors support 64-bit virtual addresses and the width of physical addresses is also growing. As a result, the size of the address tags in the L1 cache is increasing. The impact of on chip area is particularly dramatic when small block sizes are used. At the same time, the performance of high performance microprocessors depends more and more on the accuracy of branch prediction and for reasons similar to those in the case of caches the size of the Branch Target Buffer is also increasing linearly with the address width.In this paper, we apply the simple principle stated in the title for limiting the tag size of on-chip caches. In the resulting indirect-tagged cache, the duplication of the page number in processors (in TLB and in cache tags) is removed. The tag check is then simplified and the tag cost does not depend on the address width. Applying the same principle to Branch Target Buffers, we propose the Reduced Branch Target Buffer. The storage size in a Reduced Branch Target Buffer does not depend on the address width and is dramatically smaller than the size of the conventional implementation of a Branch Target Buffer.},
keywords={address width;indirect-tagged caches;reduced branch target buffers;tag implementation cost;Buffer storage;Costs;Hardware;Information retrieval;Microprocessors;Silicon;address width;indirect-tagged caches;reduced branch target buffers;tag implementation cost},
doi={10.1145/232973.232985},
ISSN={1063-6897},
month={May},}
@INPROCEEDINGS{524569,
author={B. Calder and D. Grunwald},
booktitle={Proceedings 22nd Annual International Symposium on Computer Architecture},
title={Next cache line and set prediction},
year={1995},
pages={287-296},
abstract={Accurate instruction fetch and branch prediction is increasingly important on today's wide-issue architectures. Fetch prediction is the process of determining the next instruction to request from the memory subsystem. Branch prediction is the process of predicting the likely out-come of branch instructions. Several researchers have proposed very effective fetch and branch prediction mechanisms including branch target buffers (BTB) that store the target addresses of taken branches. An alternative approach fetches the instruction following a branch by using an index into the cache instead of a branch target address. We call such an index a next cache line and set (NLS) predictor. A NLS predictor is a pointer into the instruction cache, indicating the target instruction of a branch. In this paper we examine the use of NLS predictors for efficient and accurate fetch and branch prediction. Previous studies associated each NLS predictor with a cache line and provided only one-bit conditional branch predictors. Our study examines the use of NLS predictors with highly accurate two-level correlated conditional branch architectures. We examine the performance of decoupling the NLS predictors from the cache line and storing them in a separate tag-less memory buffer. Our results show that the decoupled architecture performs better than associating the NLS predictors with the cache line, that the NLS architecture benefits from reduced cache miss rates, and it is particularly effective for programs containing many branches. We also provide an in-depth comparison between the NLS and BTB architectures, showing that the NLS architecture is a competitive alternative to the BTB design.},
keywords={computer architecture;performance evaluation;branch prediction;branch target buffers;fetch prediction;instruction fetch;next cache line and set prediction;performance;two-level correlated conditional branch architectures;Buffer storage;Computer architecture;Computer science;Decoding;Degradation;Distributed computing;Permission;Pipelines;Process design},
ISSN={1063-6897},
month={June},}
@INPROCEEDINGS{1029577,
author={A. Efthymiou and J. D. Garside},
booktitle={Proceedings of the International Symposium on Low Power Electronics and Design},
title={An adaptive serial-parallel CAM architecture for low-power cache blocks},
year={2002},
pages={136-141},
abstract={There is an on-going debate about which consumes less energy: a RAM-tagged associative cache with an intelligent order of accessing its tags and ways (e.g. way prediction), or a CAM-tagged high associativity cache. If a CAM search can consume less than twice the energy of reading a tag RAM, it would probably be the preferred option for low-power applications. Based on memory traces - which usually cause tag mismatch within the lower four bits - a new serial CAM organisation is proposed which consumes just 45% more than a single tag RAM read and is only 25% slower than the conventional, parallel CAM. Furthermore, it can optionally be operated as a parallel CAM, at no speed penalty, and still reduce energy consumption.},
keywords={VLSI;adaptive systems;cache storage;content-addressable storage;integrated memory circuits;low-power electronics;memory architecture;CAM-tagged high associativity cache;adaptive serial-parallel CAM architecture;low-power cache blocks;parallel CAM;serial CAM organisation;CADCAM;Computer aided manufacturing;Computer architecture;Computer science;Energy consumption;Permission;Random access memory;Read-write memory;Silicon;Very large scale integration},
doi={10.1109/LPE.2002.146726},
month={},}
@INPROCEEDINGS{1414555,
author={A. Kongmunvattana and E. Tiamkaew},
booktitle={2004 IEEE Region 10 Conference TENCON 2004.},
title={Exploring design space of scalable per-address branch predictors},
year={2004},
volume={B},
pages={156-159 Vol. 2},
abstract={While a scalable per-address (SPA) branch predictor reduces the cost of implementing per-address two-level branch predictors by about 50% through the exploitation of value locality in the history of branch outcomes, it suffers from internal conflict within the pattern history table (PHT), called pattern aliasing or interference. In this paper, we propose and evaluate alternative designs of SPA predictor to reduce aliasing or interference rate in its PHT as well as to improve its prediction accuracy. Several PHT designs are evaluated against a direct-mapped PHT used in the original SPA branch predictor design. Our experimental results on eight SPEC2000 benchmark programs reveal that a SPA predictor with 4-way set-associative PHT using 7-tag bit yields the highest prediction accuracy.},
keywords={benchmark testing;instruction sets;parallel architectures;program compilers;table lookup;PHT;aliasing;branch outcomes;branch prediction;interference rate;internal conflict;pattern aliasing;pattern history table;scalable per-address branch predictor;value locality;Space exploration},
doi={10.1109/TENCON.2004.1414555},
month={Nov},}
@INPROCEEDINGS{1415870,
author={S. Holm and O. B. Hovind and S. Rostad and R. Holm},
booktitle={Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.},
title={Indoors data communications using airborne ultrasound},
year={2005},
volume={3},
pages={iii/957-iii/960 Vol. 3},
abstract={We have tested an indoor data communications system based on ultrasound which is the core of an indoor positioning system. Unlike most other such systems, it relies on ultrasound alone. No radio or infrared channel nor any tether is used for communication. The main hardware components are a tag and a detector. The detector has an Ethernet interface and uses digital signal processing to cope with the acoustic environment and its noise, reverberations and Doppler shift. The attainable range is 10-20 meters and, by making a comparison with the range for speech, we find that the range predictions are consistent with our experience. The channel efficiency of the system is found to be somewhat less than for human speech which also has to deal with a similar environment. This comparison is done by using the Shannon channel capacity theorem.},
keywords={Doppler shift;acoustic noise;acoustic signal processing;channel capacity;data communication;indoor communication;information theory;random noise;reverberation;speech;ultrasonic applications;10 to 20 m;Doppler shift;Ethernet interface;Shannon channel capacity theorem;acoustic noise;airborne ultrasound;channel efficiency;detector;digital signal processing;hardware components;indoor data communications;indoor positioning system;infrared channel;radio channel;reverberations;tag;Acoustic signal detection;Data communication;Detectors;Digital signal processing;Ethernet networks;Hardware;Optical fiber communication;Speech;System testing;Ultrasonic imaging},
doi={10.1109/ICASSP.2005.1415870},
ISSN={1520-6149},
month={March},}
@INPROCEEDINGS{1418470,
author={D. Puccio and D. C. Malocha and D. Gallagher and J. Hines},
booktitle={Proceedings of the 2004 IEEE International Frequency Control Symposium and Exposition, 2004.},
title={SAW sensors using orthogonal frequency coding},
year={2004},
pages={307-310},
abstract={This paper presents a spread spectrum approach using orthogonal frequency coding (OFC) for encoding SAW sensors. The encoding technique is similar to M-ary FSK in terms of its implementation, where a transducer or reflector is built with the desired code. It is shown that the time ambiguity in the autocorrelation due to the OFC is significantly reduced as compared to a single frequency tag having the same code length. The OFC approach is general and could be applicable to many differing SAW sensors for temperature, pressure, liquids, gases, etc. Device embodiments are shown and a discussion is provided for device design considerations such as the number of chips used, chip length, transducer fractional band-width, and chosen piezoelectric material. Measured device results are presented and compared with COM model predictions to demonstrate performance. Devices are then used in computer simulations of multiple transceiver designs and the results are discussed.},
keywords={frequency shift keying;radiofrequency identification;spread spectrum communication;surface acoustic wave sensors;surface acoustic wave transducers;M-ary FSK;OFC;SAW ID tags;SAW sensor encoding;SAW sensors;autocorrelation time ambiguity reduction;coded reflector;coded transducer;multiple transceivers;multisensor environments;orthogonal frequency coding;piezoelectric material;spread spectrum method;transducer fractional bandwidth;Autocorrelation;Encoding;Frequency shift keying;Gases;Liquids;Piezoelectric materials;Piezoelectric transducers;Spread spectrum communication;Surface acoustic waves;Temperature sensors},
doi={10.1109/FREQ.2004.1418470},
ISSN={1075-6787},
month={Aug},}
@INPROCEEDINGS{1410084,
author={C. F. Chen and S. H. Yang and B. Falsafi and A. Moshovos},
booktitle={Software, IEE Proceedings-},
title={Accurate and complexity-effective spatial pattern prediction},
year={2004},
pages={276-287},
abstract={Recent research suggests that there are large variations in a cache's spatial usage, both within and across programs. Unfortunately, conventional caches typically employ fixed cache line sizes to balance the exploitation of spatial and temporal locality, and to avoid prohibitive cache fill bandwidth demands. The resulting inability of conventional caches to exploit spatial variations leads to suboptimal performance and unnecessary cache power dissipation. We describe the spatial pattern predictor (SPP), a cost-effective hardware mechanism that accurately predicts reference patterns within a spatial group (i.e., a contiguous region of data in memory) at runtime. The key observation enabling an accurate, yet low-cost, SPP design is that spatial patterns correlate well with instruction addresses and data reference offsets within a cache line. We require only a small amount of predictor memory to store the predicted patterns. Simulation results for a 64-Kbyte 2-way set-associative Ll data cache with 64-byte lines show that: (1) a 256-entry tag-less direct-mapped SPP can achieve, on average, a prediction coverage of 95%, over-predicting the patterns by only 8%, (2) assuming a 70 nm process technology, the SPP helps reduce leakage energy in the base cache by 41% on average, incurring less than 1% performance degradation, and (3) prefetching spatial groups of up to 512 bytes using SPP improves execution time by 33% on average and up to a factor of two.},
keywords={cache storage;pattern recognition;spatial data structures;cache line;cache's spatial usage;data cache;hardware mechanism;instruction address;predictor memory;reference pattern;set-associative Ll data cache;spatial group;spatial pattern predictor;Bandwidth;CMOS technology;Computer architecture;Degradation;Delay;Design optimization;Energy dissipation;Laboratories;Power dissipation;Prefetching},
doi={10.1109/HPCA.2004.10010},
ISSN={1530-0897},
month={Feb},}
@INPROCEEDINGS{1409614,
author={Hua-jui Peng and Chi-ching Chen and Chiu-yu Tseng and Keh-jiann Chen},
booktitle={2004 International Symposium on Chinese Spoken Language Processing},
title={Predicting prosodic words from lexical words - a first step towards predicting prosody from text},
year={2004},
pages={173-176},
abstract={Much remains unsolved in how to predict prosody from text for unlimited Mandarin Chinese TTS. The interactions and the rules between syntactic structure and prosodic structure are still unresolved challenges. By using part-of-speech (POS) tagging, for which text lexical information is required, we aim to find significant patterns of word grouping from analyzing real speech data and such lexical information. The paper reports discrepancies found between lexical words (LW) parsed from text and prosodic words (PW) annotated from speech data, and proposes a statistical model to predict PWs from LWs. In the statistical model, the length of the word and the tagging from POS are two essential features to predict PWs, and the results show approximately 90% of prediction for PWs; however, it does leave more room for extension. We believe that evidence from PW predictions is a first step towards building prosody models from text.},
keywords={natural language interfaces;speech synthesis;statistical analysis;text analysis;lexical words;part-of-speech tagging;prosodic structure;prosodic word prediction;rule-based model;statistical model;syntactic structure;unlimited Mandarin Chinese TTS;unlimited TTS;word grouping;Algorithm design and analysis;Data analysis;Frequency;Government;Information analysis;Information science;Predictive models;Speech analysis;Speech synthesis;Tagging},
doi={10.1109/CHINSL.2004.1409614},
month={Dec},}
@INPROCEEDINGS{1403810,
author={Jingwu He and A. Zelikovsky},
booktitle={The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title={Linear reduction methods for tag SNP selection},
year={2004},
volume={2},
pages={2840-2843},
abstract={It is widely hoped that constructing a complete human haplotype map will help to associate complex diseases with certain SNP's. Unfortunately, the number of SNP's is huge and it is very costly to sequence many individuals. Therefore, it is desirable to reduce the number of SNP's that should be sequenced to considerably small number of informative representatives, so called tag SNP's. In this paper, we propose a new linear algebra based method for selecting and using tag SNP's. Our method is purely combinatorial and can be combined with linkage disequilibrium (LD) and block based methods. We measure the quality of our tag SNP selection algorithm by comparing actual SNP's with SNP's linearly predicted from linearly chosen tag SNP's. We obtain an extremely good compression and prediction rates. For example, for long haplotypes (>25000 SNP's), knowing only 0.4% of all SNP's we predict the entire unknown haplotype with 2% accuracy while the prediction method is based on a 10% sample of the population.},
keywords={biochemistry;biology computing;combinatorial mathematics;diseases;linear algebra;molecular biophysics;organic compounds;polymorphism;block based methods;combinatorial method;human haplotype map;linear algebra based method;linear reduction methods;linkage disequilibrium methods;tag single nucleotide polymorphism selection algorithm;Accuracy;Computer science;Couplings;Diseases;Genomics;Helium;Humans;Linear algebra;Prediction methods;Technical Activities Guide -TAG;Single nucleotide polymorphism;linear independence;tag SNP},
doi={10.1109/IEMBS.2004.1403810},
month={Sept},}
@INPROCEEDINGS{1403809,
author={A. Lal and S. Radhakrishnan and S. S. Srinivas and K. Najarian and L. E. Mays},
booktitle={The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
title={Splice site detection using pruned maximum likelihood model},
year={2004},
volume={2},
pages={2836-2839},
abstract={In this paper we propose a novel method for splice site prediction using the maximum likelihood model. We performed maximum likelihood over the acceptor and donor datasets, and calculated sensitivity to measure the prediction performance. Then, by aggressive pruning of less informative nucleotide sites, while maintaining the high sensitivity of the method, we improved the model's performance in terms of the computational speed. In addition, after pruning fewer nucleotide sites need to be tagged, which in turn simplifies the development of an assay. The proposed method was tested on the human splice dataset. The results indicate that the proposed method was successful at splice site prediction with optimal sensitivity.},
keywords={biology computing;genetics;macromolecules;maximum likelihood detection;molecular biophysics;neural nets;organic compounds;prediction theory;acceptor datasets;donor datasets;human splice dataset;neural nets;nucleotide sites;optimal sensitivity;pruned maximum likelihood model;splice site detection;DNA;Genetics;Humans;Maximum likelihood detection;Predictive models;Proteins;RNA;Sequences;Splicing;Testing;Bioinformatics;Maximum Likelihood;Neural Networks;Splice Site Prediction},
doi={10.1109/IEMBS.2004.1403809},
month={Sept},}
@INPROCEEDINGS{1347942,
author={A. Veidenbaum and D. Nicolaescu},
booktitle={IEEE International Conference on Computer Design: VLSI in Computers and Processors, 2004. ICCD 2004. Proceedings.},
title={Low energy, highly-associative cache design for embedded processors},
year={2004},
pages={332-335},
abstract={Many embedded processors use highly associative data caches implemented using a CAM-based tag search. When high-associativity is desirable, CAM designs can offer performance advantages due to fast associative search. However, CAMs are not energy efficient. This paper describes a CAM-based cache design which uses prediction to reduce energy consumption. A last used prediction is shown to achieve an 86% prediction accuracy, on average. A new design integrating such predictor in the CAM tag store is described. A 30% average D-cache energy reduction is demonstrated for the MiBench programs with little additional hardware or impact on processor performance. Even better results can be achieved with another predictor design which increases prediction accuracy. Significant static energy reduction is also possible using this approach for the RAM data store.},
keywords={cache storage;content-addressable storage;embedded systems;random-access storage;CAM based tag search;D-cache energy reduction;MiBench programs;RAM data store;associative data cache design;embedded processors;energy consumption;static energy reduction;Accuracy;CADCAM;Computer aided manufacturing;Computer science;Delay;Energy consumption;Energy efficiency;Hardware;Process design;Read-write memory},
doi={10.1109/ICCD.2004.1347942},
ISSN={1063-6404},
month={Oct},}
@INPROCEEDINGS{1332442,
author={H. Matsui and K. Sato and Y. Sakakibara},
booktitle={Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.},
title={Pair stochastic tree adjoining grammars for aligning and predicting pseudoknot RNA structures},
year={2004},
pages={290-299},
abstract={Since the whole genome sequences for many species are currently available, computational predictions of RNA secondary structures and computational identifications of those non-coding RNA regions by comparative genomics have become important, and require more advanced alignment methods. Recently, an approach of structural alignments for RNA sequences has been introduced to solve these problems. By structural alignments, we mean a pair-wise alignment to align an unfolded RNA sequence into a folded RNA sequence of known secondary structure. Pair HMMs on tree structures (PHMMTSs) proposed by Sakakibara are efficient automata-theoretic models for structural alignments of RNA secondary structures, but are incapable of handling pseudoknots. On the other hand, tree adjoining grammars (TAGs) is a subclass of context-sensitive grammar, which is suitable for modeling pseudoknots. Our goal is to extend PHMMTSs by incorporating TAGs to be able to handle pseudoknots. We propose the pair stochastic tree adjoining grammars (PSTAGs) for modeling RNA secondary structures including pseudoknots and show the strong experimental evidences that modeling pseudoknot structures significantly improves the prediction accuracies of RNA secondary structures. First, we extend the notion of PHMMTSs defined on alignments of 'trees' to PSTAGs defined on alignments of "TAG (derivation) trees", which represent a top-down parsing process of TAGs and are functionally equivalent to derived trees of TAGs. Second, we modify PSTAGs so that it takes as input a pair of a linear sequence and a TAG tree representing a pseudoknot structure of RNA to produce a structural alignment. Then, we develop a polynomial-time algorithm for obtaining an optimal structural alignment by PSTAGs, based on dynamic programming parser. We have done several computational experiments for predicting pseudoknots by PSTAGs, and our computational experiments suggests that prediction of RNA pseudoknot structures by our method are more efficient and biologically plausible than by other conventional methods. The binary code for PSTAG method is freely available from our website at http://www.dna.bio.keio.ac.jp/pstag/.}, 