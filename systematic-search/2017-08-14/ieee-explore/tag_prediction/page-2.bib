@INPROCEEDINGS{7410782,
author={Z. Liu and P. Luo and X. Wang and X. Tang},
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)},
title={Deep Learning Face Attributes in the Wild},
year={2015},
pages={3730-3738},
abstract={Predicting face attributes in the wild is challenging due to complex face variations. We propose a novel deep learning framework for attribute prediction in the wild. It cascades two CNNs, LNet and ANet, which are fine-tuned jointly with attribute tags, but pre-trained differently. LNet is pre-trained by massive general object categories for face localization, while ANet is pre-trained by massive face identities for attribute prediction. This framework not only outperforms the state-of-the-art with a large margin, but also reveals valuable facts on learning face representation. (1) It shows how the performances of face localization (LNet) and attribute prediction (ANet) can be improved by different pre-training strategies. (2) It reveals that although the filters of LNet are fine-tuned only with image-level attribute tags, their response maps over entire images have strong indication of face locations. This fact enables training LNet for face localization with only image-level annotations, but without face bounding boxes or landmarks, which are required by all attribute recognition works. (3) It also demonstrates that the high-level hidden neurons of ANet automatically discover semantic concepts after pre-training with massive face identities, and such concepts are significantly enriched after fine-tuning with attribute tags. Each attribute can be well explained with a sparse linear combination of these concepts.},
keywords={face recognition;feedforward neural nets;image representation;learning (artificial intelligence);ANet;CNN;LNet;attribute recognition;automatic semantic concept discovery;complex face variations;deep learning face attribute prediction;face identities;face localization;face representation learning;image-level annotations;image-level attribute tags;pretraining strategies;Face;Face recognition;Feature extraction;Image recognition;Machine learning;Support vector machines;Training},
doi={10.1109/ICCV.2015.425},
month={Dec},}
@INPROCEEDINGS{7396504,
author={M. Cheung and J. She and X. Li},
booktitle={2015 IEEE International Conference on Data Science and Data Intensive Systems},
title={Non-user Generated Annotation on User Shared Images for Connection Discovery},
year={2015},
pages={204-209},
abstract={Social graphs, representing the online friendships among users, are one of the most fundamental types of data for many social media applications, such as recommendation, virality prediction and marketing. However, this data may be unavailable due to the privacy concerns of users, or kept privately by social network operators, which makes such applications difficult. One of the possible solutions to discover user connections is to use shared content, especially images on online social networks, such as Flickr and Instagram. This paper investigates how non-user generated labels annotated on shared images can be used for connection discovery with different color-based and feature-based methods. The label distribution is computed to represent users, and followee/follower relationships are recommended based on the distribution similarity. These methods are evaluated with over 200k images from Flickr and it is proven that with non-user generated labels, user connections can be discovered, regardless of the method used. Feature-based methods are also proven to be 95% better than color-based methods, and 65% better than tag-based methods.},
keywords={graph theory;image colour analysis;social networking (online);Flickr;color-based methods;connection discovery;feature-based methods;nonuser generated annotation;online friendships;online social networks;social graphs;Histograms;Image color analysis;Media;Tagging;Visualization;annotation;big data;connection discovery;online social network;recommendation},
doi={10.1109/DSDIS.2015.113},
month={Dec},}
@INPROCEEDINGS{7396606,
author={L. Yu and Y. Zhifan and P. Nie and X. Zhao and Y. Zhang},
booktitle={2015 12th Web Information System and Application Conference (WISA)},
title={Multi-source Emotion Tagging for Online News},
year={2015},
pages={49-52},
abstract={With the rapid growth of social media and online news services, users nowadays can respond to online news by rating subjective emotions such as happiness, surprise or anger actively. Once the user ratings is over a certain range, it begins to show up a tendency of what most people think and feel, which can help us understand the preferences and perspectives of most users, and help news providers to provide users with more positive news. Thus it has become a pregnant research problem to tag emotion automatically. This paper tackles the task of emotion tagging for online news with multi-source including news article and comment, as emotion is not only tagged after reading news article, but also can be incorporated in comment with what they feel. In this paper, a novel classification model are proposed with two layer logistic regression. The new approach get outputs from basic classifiers and combine them in a new classifier, making a more accurate prediction when compared with a single source method. An extensive set of experimental results on a real dataset from a popular online news service demonstrate the effectiveness of the proposed approach.},
keywords={electronic publishing;pattern classification;regression analysis;sentiment analysis;social networking (online);classification model;multisource emotion tagging;news article;news comment;online news services;social media;subjective emotion rating;two-layer logistic regression;Blogs;Dictionaries;Logistics;Media;Robustness;Tagging;Training;Meta Classification;Multiple Source;Online News;Sentiment Tagging},
doi={10.1109/WISA.2015.24},
month={Sept},}
@INPROCEEDINGS{7398680,
author={P. C. Lin},
booktitle={2015 IEEE 4th Global Conference on Consumer Electronics (GCCE)},
title={Database-driven quality prediction for mobile wireless networks in smart home environments},
year={2015},
pages={271-272},
abstract={In this paper we propose a database-driven quality prediction system for mobile wireless networks in smart home environments. Smart handheld devices obtain location information from smart home tags such as Bluetooth Low Energy and Near Field Communication tags, and collect various quality measurement of mobile wireless networks. The measurement reports are uploaded to the database server periodically or on demand. By applying machine learning techniques which use the measurement reports as the training data, the quality in the smart home environments could be predicted.},
keywords={home computing;learning (artificial intelligence);mobile computing;mobile handsets;mobile radio;network servers;prediction theory;radiotelemetry;Bluetooth low energy-near field communication tag;database server;database-driven quality prediction system;machine learning technique;mobile wireless network;smart handheld device;smart home tag environment;Current measurement;Databases;Mobile communication;Mobile computing;Servers;Smart homes;Wireless networks;Mobile wireless networks;Smart home},
doi={10.1109/GCCE.2015.7398680},
month={Oct},}
@INPROCEEDINGS{7382979,
author={R. Trusov and A. Natekin and P. Kalaidin and S. Ovcharenko and A. Knoll and A. Fazylova},
booktitle={2015 Artificial Intelligence and Natural Language and Information Extraction, Social Media and Web Search FRUCT Conference (AINL-ISMW FRUCT)},
title={Multi-representation approach to text regression of financial risks},
year={2015},
pages={110-117},
abstract={Different approaches for textual feature extraction have been proposed starting with simple word count features and continuing with deeper representations capturing distributional semantics. In recent publications word embedding methods have been successfully used as a representation basis for a large number of NLP tasks like text classification, part of speech tagging and many others. In this article we explore opportunities of using multiple text representations simultaneously within one regression task in order to exploit conventional bag of words approach with the more semantically rich embeddings. We investigate performance of this multi-representation approach on the financial risk prediction problem. Publicly available 10-K reports filled by US trading companies are used as the basis for predicting next year change in stock price volatility. Our study shows that models based on single representations achieve performance that is comparable to the previously published results on risk prediction and models with multiple representations benefit from complementary information and outperform both baseline and single representation models.},
keywords={financial management;pricing;regression analysis;stock markets;text analysis;US trading companies;bag-of-words approach;complementary information;distributional semantics;financial risk prediction problem;multiple text representations;publicly available 10-K reports;risk prediction;stock price volatility prediction;text regression;textual feature extraction;word count features;word embedding methods;Databases;Optimization;Predictive models;Radio frequency;Visualization},
doi={10.1109/AINL-ISMW-FRUCT.2015.7382979},
month={Nov},}
@INPROCEEDINGS{7373936,
author={S. M. Yang and C. M. Chen and C. M. Yu},
booktitle={2015 IIAI 4th International Congress on Advanced Applied Informatics},
title={Assessing the Attention Levels of Students by Using a Novel Attention Aware System Based on Brainwave Signals},
year={2015},
pages={379-384},
abstract={Rapid progress in information and communication technologies (ICTs) has fueled the popularity of e-learning for educational purposes. However, an e-learning environment is limited in that online instructors cannot monitor immediately whether students remain focus during online autonomous learning. Therefore, this study develops a novel attention aware system (AAS) capable of recognizing students' attention levels accurately based on EEG signals, thus having high potential to be applied in providing timely alert for conveying low-attention level feedback to online instructors in an e-learning environment. To construct AAS, attention responses of students and their corresponding EEG signals are gathered on a continuous performance test (CPT), i.e. An attention assessment test. Next, the AAS is constructed by using training and testing data by the NeuroSky brainwave detector and the support vector machine (SVM), a well-known machine learning model. Additionally, based on the discrete wavelet transform (DWT), the collected EEG signals are decomposed into five primary bands (i.e. Alpha, beta, gamma, theta and delta) as well as each primary band contains five statistical parameters (including approximate entropy, total variation, energy, skewness and standard deviation), thus generating twenty five potential brainwave features associated with students' attention level for constructing the AAS. An attempt based on genetic algorithm (GA) is also made to enhance the prediction performance of the proposed AAS in terms of identifying students' attention levels. According to GA, the seven most influential features are selected from twenty-five considered features, parameters of the proposed AAS are optimized as well. Analytical results indicate that the proposed AAS can accurately recognize individual student's attention state as either a high or low level, and the average accuracy rate reaches as high as 90.39 %. Moreover, the proposed AAS is integrated with a video lectu- e tagging system to examine whether the proposed AAS can accurately detect students' low-attention periods while learning about electrical safety in the workplace via a video lecture. An experiment is designed to assess the prediction performance of the proposed AAS in terms of identifying the periods of video lecture with high-or low-attention levels during learning processes. Analytical results indicate that the proposed AAS can accurately identify the low-attention periods of video lecture generated by students when engaging in a learning activity with video lecture. Results of this study demonstrate that the proposed AAS is an effective attention aware system, capable of assisting online instructors in evaluating students' attention levels to enhance their online learning performance.},
keywords={computer aided instruction;electroencephalography;entropy;genetic algorithms;learning (artificial intelligence);support vector machines;wavelet transforms;AAS;CPT;DWT;EEG signals;GA;ICT;NeuroSky brainwave detector;SVM;alpha band;analytical analysis;approximate entropy;attention assessment test;attention aware system;average accuracy rate;beta band;brainwave signals;continuous performance test;delta band;discrete wavelet transform;e-learning environment;educational purposes;electrical safety;energy;gamma band;genetic algorithm;high-attention levels;information and communication technologies;low-attention level feedback;low-attention levels;low-attention period identification;machine learning model;online autonomous learning;online instructors;prediction performance assessment;skewness;standard deviation;statistical parameters;student attention level recognition;student attention responses;student low-attention period detection;support vector machine;testing data;theta band;total variation;training data;video lecture tagging system;Discrete wavelet transforms;Electroencephalography;Electronic learning;Entropy;Feature extraction;Headphones;Training;CPT;EEG;Genetic Algorithm;Support Vector Machines;Wavelet Transform},
doi={10.1109/IIAI-AAI.2015.224},
month={July},}
@INPROCEEDINGS{7371501,
author={W. Zhang and S. Zhou and J. Luo and H. Cheng and Y. Liao},
booktitle={2015 IEEE 2nd International Conference on Cyber Security and Cloud Computing},
title={A Lightweight Detection of the RFID Unauthorized Reading Using RF Scanners},
year={2015},
pages={317-322},
abstract={Many RFID tags store valuable information that can easily be subject to unauthorized reading, leading to system security and privacy risks. The detection methods existed are not only complex and impractical, but also unable to extract more information about the abnormal signal. In this paper, we propose a lightweight detection approach for the unauthorized reading without affecting the operation of RFID systems. Such an approach contains three parts: RF signal scanner, signalevent model construction and abnormal feature extraction. In particular, we design and implement a RF scanner to acquire RF signals and measure RSSI values. After that, we build a signal-event model to analyze how the RSSI value is related to the RFID event. The detection of unauthorized reading is to investigate the deviation of observed RSSI values from their expected values. Finally, we extract and separate abnormal RSSI values to estimate the risk of unauthorized reading. The primary experimental results show that our approach can achieve high prediction accuracy in detecting unauthorized reading and make better performance in extracting abnormal features.},
keywords={RSSI;feature extraction;radiofrequency identification;RF signal scanner;RFID tag;RFID unauthorized reading;RSSI value;feature extraction;lightweight detection approach;radiofrequency identification;signal event model construction;Data mining;Feature extraction;Intrusion detection;Radio frequency;Radiofrequency identification;Training;abnormal features;scanner;signal-event model;unauthorized reading},
doi={10.1109/CSCloud.2015.34},
month={Nov},}
@INPROCEEDINGS{7365949,
author={Xingfeng Pan and Jin Yang and Xiaofeng Qiu},
booktitle={2015 International Conference on Behavioral, Economic and Socio-cultural Computing (BESC)},
title={A multi-label model to predict undisclosed attributes in microblogging},
year={2015},
pages={6-12},
abstract={In this paper, the automatic prediction of micro-blog users' attribute information is modeled as a multi-label classification process considering the relevance and co-occurrence of user attributes instead of single-label or regression, where each user has more than one attribute. Two basic and one improved multi-label classification methods are evaluated and compared in this task. Taking micro-blogging as the background, we conduct a series of experiments, comparison and analysis to prove that the multi-label classification is a very effective method to predict the user profiles considering the relevance and co-occurrence of user attributes. In feature selection stage, we consider a variety of attribute information of users such as user nickname, user tags and user personal description. The results show that a relatively great performance is obtained. Finally, we analyze the user profiling and the user preferred vocabulary in the associated attributes.},
keywords={Web sites;feature selection;pattern classification;user interfaces;feature selection;microblogging;multilabel classification process;user attribute information;user nickname;user personal description;user preferred vocabulary;user profile prediction;user profiling;user tags;Convergence;Data acquisition;Data models;Data preprocessing;Entertainment industry;Loss measurement;Telecommunications;micro-blogging;multi-label classification;user profiles},
doi={10.1109/BESC.2015.7365949},
month={Oct},}
@INPROCEEDINGS{7356551,
author={H. M. Nguyen and S. H. Kim and D. T. Le and S. Heo and J. Im and D. Kim},
booktitle={2015 5th International Conference on the Internet of Things (IOT)},
title={Optimizations for RFID-based IoT applications on the Cloud},
year={2015},
pages={80-87},
abstract={Internet of Things (IoT) has received a lot of attentions recently as a network of virtual representations of physical objects using technologies like radio-frequency identification (RFID) to identify and tracking objects' tags. While some research work has attempted to deliver IoT applications into the real-world, a scalable deployment has not yet been seen. Therefore, by utilizing Cloud technology as a well-proven way of real-world deployment for thousands of vendors, we propose our Cloud solution with optimizations for scalable RFID-based IoT applications deployment. In this paper, we first outline the challenges of deployment of RFID-based IoT applications, then our Cloud solution with load prediction and migration management optimizations is proposed. For our experiments, various results including prediction accuracy, migration delay and load balancing performance are presented.},
keywords={Internet of Things;cloud computing;radiofrequency identification;Internet of Things;RFID based IoT optimizations;cloud computing;load prediction;migration management optimizations;radio frequency identification;Cloud computing;Computer architecture;Internet of things;Load management;Optimization;Protocols;Radiofrequency identification;Cloud optimizations;IoT;RFID;load balancing},
doi={10.1109/IOT.2015.7356551},
month={Oct},}
@INPROCEEDINGS{7344830,
author={J. D. Chen and H. Y. Kao},
booktitle={2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
title={LDA based semi-supervised learning from streaming short text},
year={2015},
pages={1-8},
abstract={With the rapidly growing of real-time social media, like Twitter, many users share and discuss their interest topics through such platforms. Hashtag is a type of metadata tag which allows users to annotate their topics of tweets. For research usage, for example, hashtags can help the performance of event detection by observing the trend of hashtags. Although Twitter grows rapidly, hashtag growth is not as expected. Our dataset shows that there are less than 20% of all tweets containing hashtags. We think that it is caused by that most users may have no idea what hashtags are suitable for tweets they post. If we can recommend suitable hashtags to users, it can be one of the solutions to solve the problem of low usage rate of hashtag. Hashtag recommendation belongs to supervised learning problem. More labeled data for training the learning model can get higher performance in prediction. However, labeled data in hashtag recommendation is not so much due to low usage rate of hashtag. Thus, we want to exploit unlabeled data, i.e. non-hashtag tweets, to solve this problem. Now we have large amount of unlabeled data, but directly adding all non-hashtag tweets may not be helpful to train the model. To overcome this issue, we apply the weight-updating mechanisms to filter out the useless parts of non-hashtag tweets. These mechanisms also have to consider the temporal characteristics of hashtag due to the real-time nature of Twitter. The experimental results in this research show that adding non-hashtag tweets to extend original training data outperforms baseline methods which only exploit labeled data to train the model.},
keywords={learning (artificial intelligence);meta data;recommender systems;social networking (online);LDA based semisupervised learning;Twitter;event detection;hashtag recommendation;metadata tag;nonhashtag tweets;real-time social media;streaming short text;weight-updating mechanisms;Data models;Media;Supervised learning;Tagging;Training;Training data;Twitter;hashtag recommendation;semi-supervised learning;social media},
doi={10.1109/DSAA.2015.7344830},
month={Oct},}
@INPROCEEDINGS{7344888,
author={E. Fersini and F. A. Pozzi and E. Messina},
booktitle={2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
title={Detecting irony and sarcasm in microblogs: The role of expressive signals and ensemble classifiers},
year={2015},
pages={1-8},
abstract={The automatic detection of sarcasm and irony in user generated contents is one of the most challenging task of Natural Language Processing. In this paper we address this problem by introducing Bayesian Model Averaging (BMA), an ensemble approach to take into account several classifiers according to their reliabilities and their marginal probability predictions. The impact of the most used expressive signals (pragmatic particles and POS tags) have been evaluated in baseline models (traditional classifiers and majority voting) as well as in the proposed BMA approach. Experimental results highlight two main findings: (1) not all the features are equally able to characterize sarcasm and irony and (2) BMA not only outperforms traditional state of the art models, but is also able to ensure notable generalization capabilities both on ironic and sarcastic text.},
keywords={Bayes methods;natural language processing;pattern classification;social networking (online);text analysis;BMA;Bayesian model averaging;POS tags;ensemble classifiers;expressive signals;ironic text;irony automatic detection;majority voting;marginal probability predictions;microblogs;natural language processing;pragmatic particles;sarcasm automatic detection;sarcastic text;user generated contents;Bayes methods;Computational modeling;Electronic mail;Pragmatics;Predictive models;Reliability;Speech},
doi={10.1109/DSAA.2015.7344888},
month={Oct},}
@INPROCEEDINGS{7318685,
author={A. Ghosh and M. Danieli and G. Riccardi},
booktitle={2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
title={Annotation and prediction of stress and workload from physiological and inertial signals},
year={2015},
pages={1621-1624},
abstract={Continuous daily stress and high workload can have negative effects on individuals' physical and mental well-being. It has been shown that physiological signals may support the prediction of stress and workload. However, previous research is limited by the low diversity of signals concurring to such predictive tasks and controlled experimental design. In this paper we present 1) a pipeline for continuous and real-life acquisition of physiological and inertial signals 2) a mobile agent application for on-the-go event annotation and 3) an end-to-end signal processing and classification system for stress and workload from diverse signal streams. We study physiological signals such as Galvanic Skin Response (GSR), Skin Temperature (ST), Inter Beat Interval (IBI) and Blood Volume Pulse (BVP) collected using a non-invasive wearable device; and inertial signals collected from accelerometer and gyroscope sensors. We combine them with subjects' inputs (e.g. event tagging) acquired using the agent application, and their emotion regulation scores. In our experiments we explore signal combination and selection techniques for stress and workload prediction from subjects whose signals have been recorded continuously during their daily life. The end-to-end classification system is described for feature extraction, signal artifact removal, and classification. We show that a combination of physiological, inertial and user event signals provides accurate prediction of stress for real-life users and signals.},
keywords={accelerometers;biomedical measurement;blood;gyroscopes;skin;Blood Volume Pulse;Galvanic Skin Response;Inter Beat Interval;Skin Temperature;accelerometer sensors;gyroscope sensors;inertial signals;mental well being;noninvasive wearable device;physical well being;physiological signals;stress annotation;stress prediction;workload;Biomedical monitoring;Feature extraction;Physiology;Psychology;Sensors;Skin;Stress},
doi={10.1109/EMBC.2015.7318685},
ISSN={1094-687X},
month={Aug},}
@INPROCEEDINGS{7306946,
author={F. Yi and Z. Yu and H. Wang and B. Guo and X. Zhou},
booktitle={2014 IEEE 11th Intl Conf on Ubiquitous Intelligence and Computing and 2014 IEEE 11th Intl Conf on Autonomic and Trusted Computing and 2014 IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops},
title={An Opportunistic Music Sharing System Based on Mobility Prediction and Preference Learning},
year={2014},
pages={148-153},
abstract={With the widespread use of smart phones, opportunistic networks that leverage opportunistic contacting and data transmission among people have become a new data sharing medium. In this paper, we propose an intelligent music sharing system called "Music On Go", which is based on mobility prediction and preference extraction in opportunistic networks. In detail, we first present a human mobility prediction method based on geo-trajectory mining. A tag-based preference learning method is then proposed to extract user preference for supporting file sharing among peers. We implemented the system in commercial smart phones equipped with Bluetooth and GPS interfaces. Experimental results showed that the proposed system successfully enables opportunistic mobile file sharing and facilitates user interactions.},
keywords={data mining;learning (artificial intelligence);mobile computing;music;smart phones;user interfaces;Bluetooth interface;GPS interface;Music On Go;data sharing medium;data transmission;geotrajectory mining;human mobility prediction method;intelligent music sharing system;opportunistic contacting;opportunistic music sharing system;smart phone;tag-based preference learning method;Accuracy;Conferences;Global Positioning System;Peer-to-peer computing;Roads;Smart phones;Trajectory;Feature Extraction;Mobile file sharing;Mobility Prediction;Opportunistic network},
doi={10.1109/UIC-ATC-ScalCom.2014.72},
month={Dec},}
@INPROCEEDINGS{7276793,
author={Ü. Ilhan and G. Tezel and C. Özcan},
booktitle={2015 International Symposium on Innovations in Intelligent SysTems and Applications (INISTA)},
title={Tag SNP selection using similarity associations between SNPs},
year={2015},
pages={1-8},
abstract={Genetic changes that may be associated with complex diseases are tried to be determined by means of many genome-wide association studies. Single Nucleotide Polymorphisms (SNPs) are used primarily in these studies since they comprise a large part of these genetic changes. Statistical importance of the genome-wide association study is directly related to the number of individuals and SNPs. However, it is still very costly and time-consuming to genotype all SNPs inside the candidate area for many individuals in very large-scale association studies. For this reason, with a small error, it is necessary to select an appropriate subset of all SNPs that will represent the rest of SNPs. These selected SNPs are called tag SNPs or haplotype tag SNPs (tag SNPs or htSNPs). It is essential in tag SNP selection to determine minimum tag SNP set with very good prediction accuracy. In this study, while Clonal Selection Algorithm (CLONALG) was used as tag SNP selection method, a new method named CLONSim, in which similarity association between SNPs was used as the prediction method for the rest of SNPs was proposed. The proposed method was compared with BPSO (Binary Particle Swarm Optimization) and CLONTagger methods with parameter optimization using datasets of different sizes. Experiment results showed that the proposed method could identify tag SNPs significantly faster.},
keywords={bioinformatics;diseases;genetics;genomics;CLONALG;CLONSim method;clonal selection algorithm;complex diseases;genetic changes;genome-wide association;haplotype tag SNP;htSNP;minimum tag SNP set;parameter optimization;similarity association;similarity associations;single-nucleotide polymorphisms;tag SNP selection;Accuracy;Bioinformatics;Biological cells;Diseases;Genomics;Optimization;Prediction algorithms;clonal selection algorithm;similarity between SNPs;tag SNPs},
doi={10.1109/INISTA.2015.7276793},
month={Sept},}
@INPROCEEDINGS{7275523,
author={V. Oruganti and V. Gharat and E. Colin and A. Moretto},
booktitle={2014 International Conference on Indoor Positioning and Indoor Navigation (IPIN)},
title={Location performance law according to the dimensions of the corridor using trilateration},
year={2014},
pages={511-517},
abstract={Beacon positioning is a challenging issue in indoor positioning systems, as it considerably affects their performance. The positioning mean error may vary from 85 cm to 7 m depending on the beacons placement. This paper presents a semi-empirical law to predict location performances (accuracy and precision) in a corridor environment for given dimensions. This law can be applied to narrow indoor environments. This work is carried out in a corridor environment at two different frequency bands i.e. 433 MHz and 868 MHz with active UHF-RFID tags. Trilateration techniques are applied on Received Signal Strength Indicator (RSSI) values acquired from the tags. In this paper we study the impact of tag placement on the performance of location estimation in conjunction with a theoretical channel model. We choose the positions with best tag performances in the environment and compare the results for two frequency bands to define a law for location performance prediction depending on the dimensions of the corridor. This law helps to design a localization solution by providing two things: the density of the tags to be deployed and the positioning of the tags as a function of corridor dimensions for given frequency band and for the expected performances. We are able to achieve sub-meter accuracy (mean error) and precision (standard deviation) for both frequency bands.},
keywords={RSSI;indoor navigation;indoor radio;radio tracking;radiofrequency identification;UHF RFID tag;beacon positioning;channel model;corridor dimensions;frequency 433 MHz;frequency 868 MHz;indoor positioning systems;location estimation;location performance law;location performance prediction;received signal strength indicator;semiempirical law;trilateration;Accuracy;Estimation;Indoor navigation;Power measurement;Radiofrequency identification;Receiving antennas;Standards;Beacons positioning;Positioning accuracy;RSSI;UHF-RFID;trilateration},
doi={10.1109/IPIN.2014.7275523},
month={Oct},}
@INPROCEEDINGS{7252005,
author={H. Zhan and S. Li and A. C. Kot},
booktitle={2015 IEEE International Conference on Digital Signal Processing (DSP)},
title={Tagging the shoe images by semantic attributes},
year={2015},
pages={892-895},
abstract={With the rapid proliferation of Internet, it becomes a great challenge to annotate explosive number of objects manually. Especially for the fashion domain where a massive collection of new products come up everyday. Therefore, to save human labor, it is essential to develop an automatic tagging system for those fashion products in a variety of appearances. In this paper, we focus on addressing the issue of automatic shoe tagging where a novel system is proposed to predict the semantic attributes of the shoe images. Given a shoe image in an unknown viewpoint, our proposed system first classify it into one of the 6 pre-defined representative viewpoints, which are commonly displayed in online merchants. To localize the shoe parts on the identified viewpoint, a view-specific part localization model is proposed based on the prior knowledge of the shoe structures under different viewpoints. Finally, we extract several complementary low-level features from the localized shoe parts, which is fed into a SVM classifier for attribute prediction. The effectiveness of the proposed system is demonstrated on a newly-built pump shoe image dataset.},
keywords={Internet;identification technology;image classification;support vector machines;Internet;SVM classifier;automatic shoe tagging;automatic tagging system;fashion products;human labor;newly-built pump shoe image dataset;semantic attributes;shoe image tagging;view-specific part localization model;Accuracy;Conferences;Feature extraction;Footwear;Semantics;Support vector machines;Tagging;attribute prediction;shoe tagging;view classification;view-specific part localization},
doi={10.1109/ICDSP.2015.7252005},
ISSN={1546-1874},
month={July},}
@INPROCEEDINGS{7207240,
author={C. Ma and Y. Wang and H. Liu and H. Gui and W. Zhu and X. Shi and X. Li},
booktitle={2015 IEEE International Congress on Big Data},
title={An Approach to Social Relationship Ranking on Internet-Based Social Platforms by Tempo-spatial Data Mining Using Location Prediction Technique},
year={2015},
pages={327-334},
abstract={During the last decade, we have witnessed the prosperity of the Internet-based social platforms and mobile social applications such as Facebook, Twitter, etc. Meanwhile, due to the popularity of mobile terminals such as smart phones and variety of PADs, it is feasible to obtain relatively accurate tempo-spatial data from mobile terminal holders when they visit and upload geo-tagged messages or pictures to Internet based social platform. Therefore, it is observed that the volume of tempo-spatial social data posted on social platforms keeps increasing. This brings us more opportunities to mine the semantic information according to the analysis on the tempo spatial social information collected from Internet-based social platforms. In this paper, we present an approach to social relationship ranking by mining the tempo-spatial social data. To deal with the sparsity of raw tempo-spatial social data, the location prediction technique is employed. According to the comparison between the social relationship ranking method with location prediction and its version without location prediction, it shows that the former outperforms the latter substantially. Finally, we make several helpful observations about the social relationship ranking method when location prediction technique is adopted.},
keywords={Internet;data mining;mobile computing;smart phones;social networking (online);Facebook;Internet-based social platform;Twitter;data sparsity;geo-tagged message;geo-tagged picture;location prediction technique;mobile social application;mobile terminal;semantic information;smart phones;social relationship ranking method;tempo-spatial social data mining;tempo-spatial social information analysis;Accuracy;Context;Data collection;Markov processes;Mobile communication;Social network services;Trajectory;Internet-based social platform;location prediction;social relationship ranking;tempo-spatial data mining},
doi={10.1109/BigDataCongress.2015.56},
ISSN={2379-7703},
month={June},}
@ARTICLE{7165677,
author={M. Cheung and J. She and Z. Jie},
journal={IEEE Transactions on Multimedia},
title={Connection Discovery Using Big Data of User-Shared Images in Social Media},
year={2015},
volume={17},
number={9},
pages={1417-1428},
abstract={Billions of user-shared images are generated by individuals in many social networks today, and this particular form of user data is widely accessible to others due to the nature of online social sharing. When user social graphs are only accessible to exclusive parties, these user-shared images are proved to be an easier and effective alternative to discover user connections. This work investigated over 360 000 user shared images from two social networks, Skyrock and 163 Weibo, in which 3 million follower/ followee relationships are involved. It is observed that the shared images from users with a follower / followee relationship show relatively higher similarities . A multimedia big data system that utilizes this observed phenomenon is proposed as an alternative to user- generated tags and social graphs for follower/followee recommendation and gender identification. To the best of our knowledge, this is the first attempt in this field to prove and formulate such a phenomenon for mass user-shared images along with more practical prediction methods. These findings are useful for information or services recommendations in any social network with intensive image sharing, as well as for other interesting personalization applications, particularly when there is no access to those exclusive user social graphs.},
keywords={Big Data;multimedia systems;recommender systems;social networking (online);163 Weibo;Skyrock;follower-followee recommendation;gender identification;multimedia big data system;online social sharing;social media;social networks;user connection discovery;user social graphs;user-generated tags;user-shared images;Detectors;Europe;Feature extraction;Multimedia communication;Social network services;Tagging;Visualization;Big data;connection;discovery;recommendation;social network analysis;user-shared images},
doi={10.1109/TMM.2015.2460192},
ISSN={1520-9210},
month={Sept},}
@INPROCEEDINGS{7178906,
author={T. Mishra and Y. j. Kim and S. Bangalore},
booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Intonational phrase break prediction for text-to-speech synthesis using dependency relations},
year={2015},
pages={4919-4923},
abstract={Intonational phrase (IP) break prediction is an important aspect of front-end analysis in a text-to-speech system. Standard approaches for intonational phrase break prediction rely on the use of linguistic rules or more recently, lexicalized data-driven models. Linguistic rules are not robust while data-driven models based on lexical identity do not generalize across domains. To overcome these challenges, in this paper, we explore the use of syntactic features to predict intonational phrase breaks. On a test set of over 40 thousand words, while a lexically driven IP break prediction model yields an F-score of 0.82, a non-lexicalized model that uses part-of-speech tags and dependency relations achieves an F-score of 0.81 with added feature of being more portable across domains. In this work, we also examine the effect of contextual information on prediction performance. Our evaluation shows that using a three-token left context in a POS-tag based model results in only a 2% drop in recall compared to a model that uses both a left and right context, which suggests the viability of using such a model for incremental text-to-speech system.},
keywords={speech synthesis;IP break prediction;POS-tag based model;dependency relations;front-end analysis;incremental text-to-speech synthesis system;intonational phrase break prediction;lexicalized data-driven models;nonlexicalized model;part-of-speech tags;syntactic features;three-token left context;Computational modeling;Context;Context modeling;IP networks;Predictive models;Speech;Syntactics;IP prediction;Intonational phrase;phrase breaks;prosody;text-analysis},
doi={10.1109/ICASSP.2015.7178906},
ISSN={1520-6149},
month={April},}
@INPROCEEDINGS{7122529,
author={K. Akkaya and I. Guvenc and R. Aygun and N. Pala and A. Kadri},
booktitle={2015 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)},
title={IoT-based occupancy monitoring techniques for energy-efficient smart buildings},
year={2015},
pages={58-63},
abstract={With the proliferation of Internet of Things (IoT) devices such as smartphones, sensors, cameras, and RFIDs, it is possible to collect massive amount of data for localization and tracking of people within commercial buildings. Enabled by such occupancy monitoring capabilities, there are extensive opportunities for improving the energy consumption of buildings via smart HVAC control. In this respect, the major challenges we envision are 1) to achieve occupancy monitoring in a minimally intrusive way, e.g., using the existing infrastructure in the buildings and not requiring installation of any apps in the users' smart devices, and 2) to develop effective data fusion techniques for improving occupancy monitoring accuracy using a multitude of sources. This paper surveys the existing works on occupancy monitoring and multi-modal data fusion techniques for smart commercial buildings. The goal is to lay down a framework for future research to exploit the spatio-temporal data obtained from one or more of various IoT devices such as temperature sensors, surveillance cameras, and RFID tags that may be already in use in the buildings. A comparative analysis of existing approaches and future predictions for research challenges are also provided.},
keywords={HVAC;Internet of Things;building management systems;energy consumption;radiofrequency identification;sensor fusion;smart phones;Internet of Things;IoT devices;IoT-based occupancy monitoring techniques;RFID tags;cameras;commercial buildings;data fusion techniques;energy consumption;energy-efficient smart buildings;multimodal data fusion techniques;proliferation;sensors;smart HVAC control;smart commercial buildings;smartphones;spatio-temporal data;surveillance cameras;Accuracy;Buildings;Cameras;Data integration;IEEE 802.11 Standards;Monitoring;Sensors;Big data;HVAC;Markov chain;WLAN;WiFi;data fusion;data mining;energy efficiency;hidden Markov model (HMM);localization;occupancy monitoring;position estimation;positioning;wireless location estimation},
doi={10.1109/WCNCW.2015.7122529},
month={March},}
@INPROCEEDINGS{7117012,
author={X. Chen and Y. Cho and S. Y. Jang},
booktitle={2015 Systems and Information Engineering Design Symposium},
title={Crime prediction using Twitter sentiment and weather},
year={2015},
pages={63-68},
abstract={Social networking services have the hidden potential to reveal valuable insights when statistical analysis is applied to their unstructured data. As shown by previous research, GPS-tagged Twitter data enables the prediction of future crimes in a major city, Chicago, Illinois, of the United States. However, existing crime prediction models that incorporate data from Twitter have limitations in describing criminal incidents due to the absence of sentiment polarity and weather factors. The addition of sentiment analysis and weather predictors to such models would deliver significant insight about how crime. Our aim is to predict the time and location in which a specific type of crime will occur. Our approach is based on sentiment analysis by applying lexicon-based methods and understanding of categorized weather data, combined with kernel density estimation based on historical crime incidents and prediction via linear modeling. By testing our model's ability to predict future crime on each area of the city, we observed that the model surpassed the benchmark model, which predicts crime incidents using kernel density estimation.},
keywords={Global Positioning System;environmental factors;social networking (online);statistical analysis;Chicago;GPS-tagged Twitter data;Illinois;Twitter sentiment;United States;crime prediction models;kernel density estimation;lexicon-based method;linear modeling;sentiment analysis;social networking services;statistical analysis;unstructured data;weather factors;Data models;Logistics;Market research;Meteorology;Predictive models;Sentiment analysis;Twitter;Crime prediction;Kernel density estimation;Twitter sentiment analysis;Weather},
doi={10.1109/SIEDS.2015.7117012},
month={April},}
@ARTICLE{6994780,
author={Q. Zhu and M. L. Shyu},
journal={IEEE Transactions on Emerging Topics in Computing},
title={Sparse Linear Integration of Content and Context Modalities for Semantic Concept Retrieval},
year={2015},
volume={3},
number={2},
pages={152-160},
abstract={The semantic gap between low-level visual features and high-level semantics is a well-known challenge in content-based multimedia information retrieval. With the rapid popularization of social media, which allows users to assign tags to describe images and videos, attention is naturally drawn to take advantage of these metadata in order to bridge the semantic gap. This paper proposes a sparse linear integration (SLI) model that focuses on integrating visual content and its associated metadata, which are referred to as the content and the context modalities, respectively, for semantic concept retrieval. An optimization problem is formulated to approximate an instance using a sparse linear combination of other instances and minimize the difference between them. The prediction score of a concept for a test instance measures how well it can be reconstructed by the positive instances of that concept. Two benchmark image data sets and their associated tags are used to evaluate the SLI model. Experimental results show promising performance by comparing with the approaches based on a single modality and approaches based on popular fusion methods.},
keywords={content-based retrieval;information retrieval;meta data;multimedia computing;social networking (online);SLI model;content modalities;content-based multimedia information retrieval;context modalities;high-level semantics;low-level visual features;metadata;optimization problem;semantic concept retrieval;social media popularization;sparse linear integration model;Context;Equations;Feature extraction;Mathematical model;Semantics;Videos;Visualization;Semantic concept retrieval;multimodal integration;semantic concept retrieval;sparse linear methods},
doi={10.1109/TETC.2014.2384992},
ISSN={2168-6750},
month={June},}
@INPROCEEDINGS{7093074,
author={M. Lou and L. Wu and S. Shi and P. Lu},
booktitle={Fifth International Conference on Computing, Communications and Networking Technologies (ICCCNT)},
title={An energy-efficient two-level cache architecture for chip multiprocessors},
year={2014},
pages={1-5},
abstract={As microprocessors begin to leverage multi-core functionality, the power consumption incurred from tag comparison in cache hierarchy of Chip Multi-Processors (CMPs) becomes more prevalent. In this paper, a novel two-level cache architecture is explored to reduce the tag comparisons for mitigating power overhead. For one thing, a way-tagged L1 cache is adopted to access the L2 cache as a direct-mapping manner during the write hits. Moreover a combined multistep method is used to further reduce the L2 tag comparisons for both cache hit and miss predictions. With a simple predictor and the coherence status, a new prediction scheme for backward invalidation is proposed to compensate the limitation of the two applied solutions in CMPs. Furthermore, for the realization and optimization of the proposed structure, a banked Bloom Filter and a Linear Feedback Shift Register (LFSR) counter are exploited to replace the traditional predictors. Simulation results show that, the proposed technique can reduce the total cache power by an average 49.7% at the cost of the acceptable performance overhead.},
keywords={cache storage;data structures;energy conservation;microprocessor chips;multiprocessing systems;power consumption;shift registers;CMP;L2 cache;LFSR counter;backward invalidation;banked bloom filter;cache hierarchy;cache hit;chip multiprocessors;coherence status;direct-mapping manner;energy-efficient two-level cache architecture;linear feedback shift register counter;microprocessors;miss predictions;multicore functionality;multistep method;power consumption;power overhead mitigation;prediction scheme;predictor status;tag comparison;way-tagged L1 cache;write hits;Coherence;Delays;Energy efficiency;Logic gates;Power demand;Radiation detectors;System-on-chip;Bloom filter;cache;linear feedback shift register;multiprocessor;power},
doi={10.1109/ICCCNT.2014.7093074},
month={July},}
@INPROCEEDINGS{7092141,
author={R. Patil and B. Dasharath Dhamdhere and K. S. Dhonde and R. G. Chinchwade and S. B. Mehetre},
booktitle={International Conference for Convergence for Technology-2014},
title={A hybrid model to detect phishing-sites using clustering and Bayesian approach},
year={2014},
pages={1-5},
abstract={Phishing sites are the major attacks by which most of internet users are being fooled by the phisher. The replicas of the legitimate sites are created and users are directed to that web site by luring some offers to it. There are certain standards which are given by W3C (World Wide Web Consortium), based on these standards we are choosing some features which can easily describe the difference between legit site and phish site. We are proposing a model to determine the phishing sites to safeguard the web users from phisher. The features of URL along with the features of Web Page in HTML tags are considered to determine the attack. Here Clustering of Database is done through K-Means Clustering and Naive Bayes Classifier prediction technique is applied to determine the probability of the web site as Valid Phish or Invalid Phish. K-Means Clustering is applied on initial URL features and Validity is checked if still we are not able to determine the Validity of Web Site then Naive Bayes Classifier is applied onto URL as well as HTML tag features of Site and probability is evaluated based on training model.},
keywords={Bayes methods;Internet;Web sites;computer crime;database management systems;hypermedia markup languages;pattern clustering;unsolicited e-mail;HTML tag features;Internet users;URL features;W3C;Web page;Web site;Web users;World Wide Web Consortium;database;hybrid model;invalid phish;k-means clustering;legit site;legitimate sites;naive Bayes classifier prediction technique;phishing-sites detection;probability;training model;valid phish;Databases;Feature extraction;HTML;Training;Uniform resource locators;Web pages;Anti Phishing Technique;Bayesian Approach;Data Mining;Database Clustering;Hybrid Model;Phishing Attack},
doi={10.1109/I2CT.2014.7092141},
month={April},}
@INPROCEEDINGS{7087826,
author={L. Banda and K. K. Bharadwaj},
booktitle={Fourth International Conference on Advances in Recent Technologies in Communication and Computing (ARTCom2012)},
title={Improving scalability issues in collaborative filtering based on collaborative tagging using genre interestingness measure},
year={2012},
pages={240-243},
abstract={Recommender Systems are non-profit websites to predict user preferences. In Commercial websites predicting accurate data may result higher selling rates. A recommender system compares user profiles to some reference characteristics, and seeks to predict the rating or preference that a user would give to an item that they have not yet considered. These characteristics may be considered as content-based approach, collaborative filtering demographic filtering and hybrid recommender systems. Collaborative filtering (CF) is widely used in recommender systems. These methods are based on collecting and analyzing the information of a particular user behavior, activity, preferences and will predict the user's interest according to the similarity of other users. In this paper we address the problem of scalability associated with CF and propose a CF framework that combines collaborative tagging with genre interestingness measure for a movie RS. Our experiments on each movie dataset with recent timestamp demonstrate that the proposed CFT -GIM gives more accurate predictions of user's ratings as compared to both CF and CFT.},
keywords={Collaborative Filtering;Collaborative Tagging;Genre Interestingness Measure;Recommender Systems},
doi={10.1049/cp.2012.2537},
month={Oct},}
@ARTICLE{7060658,
author={X. Li and M. Larson and A. Hanjalic},
journal={IEEE Transactions on Multimedia},
title={Global-Scale Location Prediction for Social Images Using Geo-Visual Ranking},
year={2015},
volume={17},
number={5},
pages={674-686},
abstract={We propose an automatic method that addresses the challenge of predicting the geo-location of social images using only the visual content of those images. Our method is able to generate a geo-location prediction for an image globally . In this respect, it contrasts with other existing approaches, specifically with those that generate predictions restricted to specific cities, landmarks, or an otherwise pre-defined set of locations. The essence and the main novelty of our ranking-based method is that for a given query image a geo-location is recommended based on the evidence collected from images that are not only geographically close to this geo-location, but also have sufficient visual similarity to the query image within the considered image collection. Our method is evaluated experimentally on a public dataset of 8.8 million geo-tagged images from Flickr, released by the MediaEval 2013 evaluation benchmark. Experiments show that the proposed method delivers a substantial performance improvement compared to the existing related approaches, particularly for queries with high numbers of neighbors . In addition, a detailed analysis of the method's performance reveals the impact of different visual feature extraction and image matching strategies, as well as the densities and types of images found at different locations, on the prediction accuracy.},
keywords={feature extraction;image classification;image matching;image retrieval;Flickr;MediaEval 2013 evaluation benchmark;geo-tagged images;geo-visual ranking;image matching;query image;social images global-scale location prediction;visual feature extraction;Accuracy;Availability;Benchmark testing;Feature extraction;Image matching;Urban areas;Visualization;Geo-coordinate prediction;geo-location prediction;geo-visual ranking;image location prediction},
doi={10.1109/TMM.2015.2413351},
ISSN={1520-9210},
month={May},}
@INPROCEEDINGS{7051518,
author={L. Chen and R. Wang and S. Ma},
booktitle={2014 IEEE Visual Communications and Image Processing Conference},
title={Tagged multi-hypothesis motion compensation scheme for video coding},
year={2014},
pages={117-120},
abstract={Accuracy of prediction block (PB) plays a very important role in improving the coding performance. In this paper, we propose tagged multi-hypothesis motion compensation scheme (TMHMC) for inter frames to improve the accuracy of PB. TMHMC not only makes use of temporal correlation between frames but also the spatial correlation as motion vectors of adjacent blocks are used to derive the PB. For entropy coding process, only one motion vector and a tag indicating which adjacent block is used are coded in bit-stream. Adding TMHMC scheme as an additional mode in MPEG internet video coding (TVC) platform, the bitrate saving is up to 12% at the same objective quality compared with anchor. Average bitrate saving is close to 6% over all test sequences. In addition, we also implement the conventional multi-hypothesis motion compensation (MHMC) scheme. 3% bitrate is further saved on average by TMHMC compared with conventional MHMC.},
keywords={correlation methods;motion compensation;video coding;MPEG internet video coding platform;motion vector;prediction block;spatial correlation;tagged multihypothesis motion compensation;temporal correlation;Entropy coding;Joints;Motion compensation;Motion estimation;Vectors;Video coding;MPEG TVC;Multi-hypothesis;motion compensation;tag;video coding},
doi={10.1109/VCIP.2014.7051518},
month={Dec},}
@INPROCEEDINGS{7044855,
author={B. S. Kim and H. Kim and J. Lee and J. H. Lee},
booktitle={2014 Joint 7th International Conference on Soft Computing and Intelligent Systems (SCIS) and 15th International Symposium on Advanced Intelligent Systems (ISIS)},
title={Improving a recommender system by collective matrix factorization with tag information},
year={2014},
pages={980-984},
abstract={Collaborative filtering (CF) is the most widely used method of recommender systems. However, it is hard to give users reliable recommendation when there is little information about users. This is the sparsity problem of CF. In this paper, we propose a collective matrix factorization method using tag information to solve the sparsity problem. With tag information, we construct a user-tag matrix that represents users' preferences about tags. Using the user-tag matrix, we convert sparse user-item matrix into dense user-item matrix. In our method, the collective matrix factorization has the role of transferring information between the user-item matrix and user-tag matrix. We experimentally show that our method generates more precise prediction than general CF suffering from the sparsity problem.},
keywords={collaborative filtering;matrix decomposition;recommender systems;sparse matrices;collaborative filtering;collective matrix factorization method;recommender system;sparse user-item matrix;sparsity problem;tag information;user-tag matrix;Accuracy;Collaboration;Matrix converters;Matrix decomposition;Recommender systems;Sparse matrices;collaborative filtering;collective matrix factorization;recommender system;sparsity problem;tag information},
doi={10.1109/SCIS-ISIS.2014.7044855},
month={Dec},}
@INPROCEEDINGS{7031709,
author={N. B. Mallya and G. Patil and B. Raveendran},
booktitle={2015 28th International Conference on VLSI Design},
title={Way Halted Prediction Cache: An Energy Efficient Cache Architecture for Embedded Processors},
year={2015},
pages={65-70},
abstract={This paper proposes a novel cache architecture -- Way Halted Prediction -- to reduce energy consumption and effective access time of set associative caches. This is achieved with the help of halt tag array and prediction circuit. Experimental evaluation of various SPEC benchmark programs on CACTI 5.3 and CASIM simulators reveal that the proposed architecture offers 33%, 6% and 3% savings in dynamic energy consumption and 1.80%, 6.13% and -1.95% saving in effective access time over conventional, way predicting and way halting cache architectures respectively.},
keywords={cache storage;circuit simulation;content-addressable storage;embedded systems;energy consumption;microprocessor chips;CACTI 5.3 simulator;CASIM simulator;SPEC benchmark program;dynamic energy consumption;embedded processor;energy efficient cache architecture;halt tag array;halting cache architecture;prediction circuit;set associative cache;way halted prediction cache;Accuracy;Arrays;Benchmark testing;Decoding;Energy consumption;Energy efficiency;Program processors;cache architecture;energy efficient cache design;way halting;way predicting},
doi={10.1109/VLSID.2015.16},
ISSN={1063-9667},
month={Jan},}
@INPROCEEDINGS{7022674,
author={G. Cai and R. Lv and H. Wu and X. Hu},
booktitle={2014 IEEE International Conference on Data Mining Workshop},
title={An Improved Collaborative Method for Recommendation and Rating Prediction},
year={2014},
pages={781-788},
abstract={User-Item matrix (UI matrix) has been widely used in recommendation systems for data representation. However, as the amount of users and items increases, UI matrix becomes very sparse, which leads to unsatisfactory performance in traditional recommendation algorithms. To address this problem, in this paper, a rating prediction method with low sensitivity to sparse datasets is proposed. This method incorporates tag information and factor analysis approach that has been successfully applied in various areas, to discover the most similar top-N users based on the similarity of users' inner idiosyncrasies. Based on the most similar top-N users discovered, an improved collaborative filtering method is designed for rating prediction and recommendation. Extensive experiments have been done for comparing the proposed method with traditional collaborative filtering and the matrix factorization methods. The results demonstrate that our proposed method can achieve better accuracy, and it is less sensitive to sparseness of datasets.},
keywords={collaborative filtering;data structures;matrix algebra;recommender systems;UI matrix;collaborative method;data representation;factor analysis;rating prediction;recommendation system;tag information;user-item matrix;Collaboration;Data models;Fitting;Motion pictures;Prediction algorithms;Sparse matrices;Vectors;dynamic dataset;factor analysis;low sensitivity to sparseness;rating prediction;tag system},
doi={10.1109/ICDMW.2014.60},
ISSN={2375-9232},
month={Dec},}
@INPROCEEDINGS{7026273,
author={D. Falcone and C. Mascolo and C. Comito and D. Talia and J. Crowcroft},
booktitle={6th International Conference on Mobile Computing, Applications and Services},
title={What is this place? Inferring place categories through user patterns identification in geo-tagged tweets},
year={2014},
pages={10-19},
abstract={Online social networks such as Facebook and Twitter have started allowing users to tag their posts with geographical coordinates collected through the GPS interface of users smartphones. While this information is quite useful and already indicative of user behavior, it also lacks some semantics about the type of place the user is (e.g., restaurant, museum, school) which would allow a better understanding of users' patterns. While some location based online social network services (e.g., Foursquare) allow users to tag the places they visit, this is not an automated process but one which requires the user help. In this paper we exploit the dynamics of human activity to associate categories to GPS coordinates of social network posts. We have collected geo-tagged tweets of a large city through Twitter. A supervised learning framework takes the tweets spatial-temporal features and determines human dynamics which we use to infer the place category. Our results over the data show that the prediction framework is able to accurately identify if a place is of a certain category given its user activity patterns. The average accuracy is about 70%, reaching the highest accuracy for work (90%) and educational places (80%). Moreover the framework identifies the category of a place, with an accuracy up to 66%, finding out where people eat and drink, go for entertainment, or work/study.},
keywords={Global Positioning System;geography;mobile computing;social networking (online);Facebook;GPS interface;Twitter;geo-tagged tweets;geographical coordinates;human activity;human dynamics;location based online social network services;online social networks;place categories;post tagging;prediction framework;spatial-temporal features;supervised learning framework;user behavior;user patterns identification;users smartphones;Clustering algorithms;Educational institutions;Feature extraction;Global Positioning System;Semantics;Twitter},
doi={10.4108/icst.mobicase.2014.257683},
month={Nov},}
@INPROCEEDINGS{7023432,
author={J. Shang and T. Chen and H. Li and Z. Lu and Y. Yu},
booktitle={2014 IEEE International Conference on Data Mining},
title={A Parallel and Efficient Algorithm for Learning to Match},
year={2014},
pages={971-976},
abstract={Many tasks in data mining and related fields can be formalized as matching between objects in two heterogeneous domains, including collaborative filtering, link prediction, image tagging, and web search. Machine learning techniques, referred to as learning-to-match in this paper, have been successfully applied to the problems. Among them, a class of state-of-the-art methods, named feature-based matrix factorization, formalize the task as an extension to matrix factorization by incorporating auxiliary features into the model. Unfortunately, making those algorithms scale to real world problems is challenging, and simple parallelization strategies fail due to the complex cross talking patterns between sub-tasks. In this paper, we tackle this challenge with a novel parallel and efficient algorithm. Our algorithm, based on coordinate descent, can easily handle hundreds of millions of instances and features on a single machine. The key recipe of this algorithm is an iterative relaxation of the objective to facilitate parallel updates of parameters, with guaranteed convergence on minimizing the original objective function. Experimental results demonstrate that the proposed method is effective on a wide range of matching problems, with efficiency significantly improved upon the baselines while accuracy retained unchanged.},
keywords={convergence;iterative methods;learning (artificial intelligence);matrix decomposition;parallel algorithms;pattern matching;Web search;auxiliary feature;collaborative filtering;complex cross talking patterns;convergence;coordinate descent;data mining;efficient algorithm;feature-based matrix factorization;heterogeneous domain;image tagging;iterative relaxation;learning-to-match;link prediction;machine learning techniques;matching problems;parallel algorithm;parallelization strategy;state-of-the-art method;Algorithm design and analysis;Collaboration;Convergence;Parallel algorithms;Prediction algorithms;Time complexity;Training;collaborative filtering;learning to match;parallel matrix factorization},
doi={10.1109/ICDM.2014.71},
ISSN={1550-4786},
month={Dec},}
@INPROCEEDINGS{7014584,
author={P. Arunapuram and J. W. Bartel and P. Dewan},
booktitle={10th IEEE International Conference on Collaborative Computing: Networking, Applications and Worksharing},
title={Distribution, correlation and prediction of response times in Stack Overflow},
year={2014},
pages={378-387},
abstract={The sending of a message raises two important questions about its response: When will the first response arrive? When will the first acceptable response arrive? These questions can be partly or completely answered by identifying distributions of response times, correlating features with response times, and/or predicting the actual response times. We address distribution, correlation and prediction of response times in Stack Overflow. We analyzed response times of over two million question-answer threads. We found no strong correlation between response times and features studied in other messaging domains: (a) use of various kinds of pronouns and punctuations, and (b) the time of day, and day of week when messages were sent. We found that title lengths show a quadratic relationship with median response time and that mean response times vary according to the tags used in a post. We explored a large design space of prediction algorithms based on the distributions of response times. These approaches predicted ranges of time that were automatically determined using a clustering algorithm. The best results were given by an approach that combines, using an index-base weighted-average algorithm introduced here, the most frequent time-ranges in the distributions for the tags in the posts.},
keywords={electronic mail;electronic messaging;pattern clustering;Stack Overflow;clustering algorithm;index-base weighted-average algorithm;message sending;messaging domain;prediction algorithm;quadratic relationship;question-answer thread;response time correlation;response time distribution;response time prediction;Androids;Debugging;Facebook;HTML;Humanoid robots;Message systems;Visual databases;Stack Overflow;online forums;prediction;response time},
doi={10.4108/icst.collaboratecom.2014.257265},
month={Oct},}
@ARTICLE{6882134,
author={C. Shao and W. Lee and D. Z. Du},
journal={IEEE Antennas and Wireless Propagation Letters},
title={Time-Efficiency-Oriented Missing-Tag Identification Protocols for Large-Scale RFID Systems},
year={2014},
volume={13},
pages={1697-1700},
abstract={One fundamental and significant issue for large-scale radio frequency identification (RFID) systems is to promptly identify the missing events of passive tags. To this end, this letter proposes two novel protocols, Tag Retardation-based Compact Protocol (TRCP) and Probabilistic Prediction-based Protocol (P3), which address the missing-tag identification problem in a more time-efficient way than existing work. TRCP conducts tag retardation to alleviate tag collisions and achieve compact tag transmissions. Due to the fact that it is unnecessary to individually identify the tags that are likely to be missing simultaneously, we design P3, which leverages tag missing probability to avert needless tag retardation to further ameliorate TRCP. Simulation results validate the superiority of both TRCP and P3 to state-of-the-art studies in terms of time efficiency.},
keywords={protocols;radiofrequency identification;P3;TRCP;compact tag transmissions;large-scale RFID systems;large-scale radio frequency identification systems;passive tags;probabilistic prediction-based protocol;tag collisions;tag missing probability;tag retardation-based compact protocol;time-efficiency-oriented missing-tag identification protocols;Backscatter;Context;Protocols;Radiation detectors;Radiofrequency identification;Servers;Vectors;Missing-tag identification;radio frequency identification (RFID);time efficiency},
doi={10.1109/LAWP.2014.2351495},
ISSN={1536-1225},
month={},}
@INPROCEEDINGS{6982457,
author={R. Creţulescu and A. David and D. Morariu and L. Vinţan},
booktitle={2014 18th International Conference on System Theory, Control and Computing (ICSTCC)},
title={Part of speech tagging with Na #x00EF;ve Bayes methods},
year={2014},
pages={446-451},
abstract={In this paper we have focused on the problem of automatic prediction of parts of speech in sentences. We present an experimental framework which includes the analysis and the implementation of methods for part of speech (POS) labeling (tagging). We have tested three methods that predict the POS without current word's context and also three context awareness statistic methods. The main goal of our work was to evaluate the three statistical methods Forward, Backward and Complete Method in order to analyze their applicability in the problem of automatically prediction of the POS. These methods are derived from the classic Naïve Bayes classifier. In our research we have used the WordNet database and a set of benchmarks called the Brown University Standard Corpus of Present - Day American English. The results obtained by the non-context-awareness methods compared to the results obtained by statistical methods are better but not so reliable like the statistical methods.},
keywords={natural language processing;statistical analysis;Brown University Standard Corpus of Present;POS labeling;backward method;complete method;context awareness statistic methods;forward method;naive Bayes methods;part-of-speech tagging;parts-of-speech prediction;Accuracy;Bayes methods;Context;Measurement;Speech;Tagging;Training;NLP;Naïve Bayes;Part of Speech Prediction},
doi={10.1109/ICSTCC.2014.6982457},
month={Oct},}
@INPROCEEDINGS{6967131,
author={J. Zhao and J. Ma},
booktitle={Proceedings of 2013 3rd International Conference on Computer Science and Network Technology},
title={An improved slope one algorithm based on tag frequency},
year={2013},
pages={369-372},
abstract={Technology of Collaborative filtering algorithm recommends items to the target user with information of other users who have similar tastes with the target user. The basic Slope One collaborative filtering algorithm simply uses the linear regression model to predict the ratings of items. Based on the Slope One scheme, an improved algorithm considering the frequency of items' tags information is proposed in this paper. Firstly, the tag frequency of rated items is chosen to represent the vector of the target user's preference. After that, the similarity between rated items and unrated one is calculated and according to it, the unrated items' rating can be predicted. Experiments on MovieLens dataset show that the proposed approach gives better prediction accuracy.},
keywords={collaborative filtering;recommender systems;MovieLens dataset;item rating prediction;linear regression model;slope one collaborative filtering algorithm;tag frequency;user preference;Algorithm design and analysis;Collaboration;Filtering;Filtering algorithms;Motion pictures;Prediction algorithms;Vectors;Collaborative Filtering;Recommend System;Slope One;Tag Frequency},
doi={10.1109/ICCSNT.2013.6967131},
month={Oct},}
@INPROCEEDINGS{6936693,
author={Z. Zhang and M. Dong},
booktitle={The 9th International Symposium on Chinese Spoken Language Processing},
title={The power of special characters in prosodicword prediction for Chinese TTS},
year={2014},
pages={280-283},
abstract={Prosodic word (PW) prediction in Chinese Text-To-Speech (TTS) can be formulated as a classification problem that one predicts the tag of every character boundary in a sentence is the PW boundary or not. In this paper, a set of new features called special characters are introduced and put into classifiers to address the PW prediction problem. Some characters often appear at the beginning or at the end of a PW, which make them a strong clue of a PWboundary. Besides, quite a lot of PWs have only one character, which make such characters special. We select a set of special single characters, special starting characters, and special ending characters to help predict PW boundaries. Some special lexical words are often taken as PWs, and we collect a list of such words for PW boundary prediction. Decision tree, Supporting Vector Machine (SVM), MultiLayer Perceptron, and Random Forests are employed as the classifiers. Other features like part-of-speech (POS) of characters, word length, etc. are also used for PW prediction. In our experiments, we got 90.5% and 91.3% accuracies on two corpora containing 8, 000 and 1, 349 sentences respectively, which proved the efficiency of the method.},
keywords={decision trees;multilayer perceptrons;speech synthesis;support vector machines;Chinese TTS;Chinese text-to-speech;POS;PW boundary prediction;SVM;decision tree;lexical words;multilayer perceptron;part-of-speech;prosodic word prediction;random forests;special characters;special ending characters;special single characters;special starting characters;supporting vector machine;Accuracy;Probability;Radio frequency;Speech;Support vector machines;System performance;Training;prosodic word prediction;speech synthesis},
doi={10.1109/ISCSLP.2014.6936693},
month={Sept},}
@INPROCEEDINGS{6922292,
author={A. Divya Jebaseeli and M. Kiruba},
booktitle={2014 International Conference on Green Computing Communication and Electrical Engineering (ICGCCEE)},
title={Design of low power L2 cache architecture using partial way tag information},
year={2014},
pages={1-6},
abstract={Nowadays high-performance microprocessors make use of cache write-through policy for performance improvement and achieving good tolerance to soft errors in on-chip cache. However write through policy incurs large power utilization, while accessing the cache at low level (L2 cache) during write operation. In existing method, way_tagged cache was used under write-through policy, it's consumed more energy. A new cache architecture has a partial tag enhanced-bloom filter is used to improve the accuracy of cache miss prediction. By maintaining the wag tag of L2 cache in the L1 cache during read operation. The proposed technique enables L2 cache to work in direct mapping manner during write hit and reducing tag comparison of cache miss prediction, if cache miss is predicted there is no need to access the L2 cache. So that significant portion of energy will be reduced, without performance degradation. Simulation results are obtained both L1 and L2 cache configuration. The proposed technique achieves 63% energy saving in L2 cache on average with only 0.02% area overhead and no performance degradation, when compare with existing methods.},
keywords={cache storage;data structures;integrated circuit design;low-power electronics;L1 cache configuration;cache miss prediction;cache write-through policy;direct mapping;high-performance microprocessors;low power L2 cache architecture design;on-chip cache;partial tag enhanced-bloom filter;partial way tag information;performance improvement;power utilization;write hit;Arrays;Decoding;Degradation;Energy consumption;Microprocessors;Registers;System-on-chip;Bloom filter;Cache;low power;tag comparison;write-through policy},
doi={10.1109/ICGCCEE.2014.6922292},
month={March},}
@INPROCEEDINGS{6909804,
author={J. Xu and A. G. Schwing and R. Urtasun},
booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},
title={Tell Me What You See and I Will Show You Where It Is},
year={2014},
pages={3190-3197},
abstract={We tackle the problem of weakly labeled semantic segmentation, where the only source of annotation are image tags encoding which classes are present in the scene. This is an extremely difficult problem as no pixel-wise labelings are available, not even at training time. In this paper, we show that this problem can be formalized as an instance of learning in a latent structured prediction framework, where the graphical model encodes the presence and absence of a class as well as the assignments of semantic labels to superpixels. As a consequence, we are able to leverage standard algorithms with good theoretical properties. We demonstrate the effectiveness of our approach using the challenging SIFT-flow dataset and show average per-class accuracy improvements of 7% over the state-of-the-art.},
keywords={graph theory;image segmentation;learning (artificial intelligence);transforms;SIFT-flow dataset;graphical model;image tags;latent structured prediction framework;scale-invariant feature transforms;semantic segmentation;Accuracy;Graphical models;Image segmentation;Labeling;Semantics;Training;Vectors;Graphical Model;Semantic Segmentation;Structured Prediction;Weakly Supervised Learning},
doi={10.1109/CVPR.2014.408},
ISSN={1063-6919},
month={June},}
@ARTICLE{6573289,
author={P. Saari and T. Eerola},
journal={IEEE Transactions on Knowledge and Data Engineering},
title={Semantic Computing of Moods Based on Tags in Social Media of Music},
year={2014},
volume={26},
number={10},
pages={2548-2560},
abstract={Social tags inherent in online music services such as Last.fm provide a rich source of information on musical moods. The abundance of social tags makes this data highly beneficial for developing techniques to manage and retrieve mood information, and enables study of the relationships between music content and mood representations with data substantially larger than that available for conventional emotion research. However, no systematic assessment has been done on the accuracy of social tags and derived semantic models at capturing mood information in music. We propose a novel technique called Affective Circumplex Transformation (ACT) for representing the moods of music tracks in an interpretable and robust fashion based on semantic computing of social tags and research in emotion modeling. We validate the technique by predicting listener ratings of moods in music tracks, and compare the results to prediction with the Vector Space Model (VSM), Singular Value Decomposition (SVD), Nonnegative Matrix Factorization (NMF), and Probabilistic Latent Semantic Analysis (PLSA). The results show that ACT consistently outperforms the baseline techniques, and its performance is robust against a low number of track-level mood tags. The results give validity and analytical insights for harnessing millions of music tracks and associated mood data available through social tags in application development.},
keywords={information management;information retrieval;music;social networking (online);ACT;NMF;PLSA;SVD;VSM;affective circumplex transformation;conventional emotion research;emotion modeling;mood information management;mood information retrieval;mood representations;music content;musical moods;nonnegative matrix factorization;online music services;probabilistic latent semantic analysis;semantic computing;semantic models;singular value decomposition;social media;social tags;track-level mood tags;vector space model;Analytical models;Computational modeling;Mood;Music;Semantics;Vectors;Vocabulary;Affective Computing;Artificial Intelligence;Computing Methodology;Content Analysis and Indexing;Intelligent Web Services and Semantic Web;Modeling human emotion;Modeling structured;Multimedia databases;Ontology design;Semantic analysis;Sound and Music Computing;Web mining;genres;moods;music;music information retrieval;prediction;social tags;textual and multimedia data},
doi={10.1109/TKDE.2013.128},
ISSN={1041-4347},
month={Oct},}
@ARTICLE{6550021,
author={H. Y. Lo and S. D. Lin and H. M. Wang},
journal={IEEE Transactions on Knowledge and Data Engineering},
title={Generalized k-Labelsets Ensemble for Multi-Label and Cost-Sensitive Classification},
year={2014},
volume={26},
number={7},
pages={1679-1691},
abstract={Label powerset (LP) method is one category of multi-label learning algorithm. This paper presents a basis expansions model for multi-label classification, where a basis function is an LP classifier trained on a random k-labelset. The expansion coefficients are learned to minimize the global error between the prediction and the ground truth. We derive an analytic solution to learn the coefficients efficiently. We further extend this model to handle the cost-sensitive multi-label classification problem, and apply it in social tagging to handle the issue of the noisy training set by treating the tag counts as the misclassification costs. We have conducted experiments on several benchmark datasets and compared our method with other state-of-the-art multi-label learning methods. Experimental results on both multi-label classification and cost-sensitive social tagging demonstrate that our method has better performance than other methods.},
keywords={learning (artificial intelligence);minimisation;pattern classification;random processes;social networking (online);LP classifier;cost sensitive multilabel classification problem;expansion coefficients;generalized k-labelsets ensemble;global error minimization;label powerset method;misclassification cost;multilabel learning algorithm;noisy training set handling;random k-labelset;social tagging;tag counts;Laplace equations;Learning systems;Linear programming;Optimization;Prediction algorithms;Tagging;Training;Multi-label classification;cost-sensitive learning;ensemble method;hypergraph;labelset;multi-label classification;social tag;tag count},
doi={10.1109/TKDE.2013.112},
ISSN={1041-4347},
month={July},}
@INPROCEEDINGS{6836083,
author={V. Ordonez and V. Jagadeesh and W. Di and A. Bhardwaj and R. Piramuthu},
booktitle={IEEE Winter Conference on Applications of Computer Vision},
title={Furniture-geek: Understanding fine-grained furniture attributes from freely associated text and tags},
year={2014},
pages={317-324},
abstract={As the amount of user generated content on the internet grows, it becomes ever more important to come up with vision systems that learn directly from weakly annotated and noisy data. We leverage a large scale collection of user generated content comprising of images, tags and title/captions of furniture inventory from an e-commerce website to discover and categorize learnable visual attributes. Furniture categories have long been the quintessential example of why computer vision is hard, and we make one of the first attempts to understand them through a large scale weakly annotated dataset. We focus on a handful of furniture categories that are associated with a large number of fine-grained attributes. We propose a set of localized feature representations built on top of state-of-the-art computer vision representations originally designed for fine-grained object categorization. We report a thorough empirical characterization on the visual identifiability of various fine-grained attributes using these representations and show encouraging results on finding iconic images and on multi-attribute prediction.},
keywords={Internet;Web sites;computer vision;electronic commerce;furniture;object recognition;text analysis;Internet;Web site;computer vision;e-commerce;fine-grained furniture attributes;fine-grained object categorization;freely associated tags;freely associated text;furniture categories;furniture-geek;noisy data;user generated content;Abstracts;Calibration;HTML;Image color analysis;Predictive models},
doi={10.1109/WACV.2014.6836083},
ISSN={1550-5790},
month={March},}
@INPROCEEDINGS{6839273,
author={R. F. Joseph and A. A. Godbole},
booktitle={2014 International Conference on Circuits, Systems, Communication and Information Technology Applications (CSCITA)},
title={An intelligent traveling companion for visually impaired pedestrian},
year={2014},
pages={283-288},
abstract={A navigation system that will guide the blind and the visually impaired pedestrian with ease. The system will adapt to the user's behavior and will also provide the user with shortest path from the source to the user's chosen destination in the building. RFID technology is used to track the user's current location. The user carries his own PDA with the application installed in it and a RFID reader with him. RFID tags are deployed in the building. On detection of the RFID tag by the RFID reader as the reader comes in vicinity of the tag, the reader sends the tag information to the PDA using Bluetooth Technology. The PDA based user device provides the user navigation instructions in an audio form and the user can also select the preferences provides by giving input in form of speech. The system will be a blend of Optimal Routing and Users Preference. The PDA consist of the ACO algorithm that will help in the optimization of A* algorithm which will work as the prediction algorithm.},
keywords={Bluetooth;handicapped aids;notebook computers;radiofrequency identification;radionavigation;A* algorithm;ACO algorithm;Bluetooth technology;PDA based user device;RFID reader;RFID tag detection;RFID technology;audio form;intelligent traveling companion;navigation system;optimal routing;prediction algorithm;tag information;user behavior;user current location tracking;user navigation instructions;user preference;visually impaired pedestrian;Databases;Feature extraction;Navigation;Prediction algorithms;RFID tags;Rails;A* Algorithm;ACO;Adaptive;Evaporation;RFID;Weight Modifier},
doi={10.1109/CSCITA.2014.6839273},
month={April},}
@ARTICLE{6818595,
author={S. Walter and C. Quigley and M. M. Mueller},
journal={Journal of Cognitive Neuroscience},
title={Competitive Interactions of Attentional Resources in Early Visual Cortex during Sustained Visuospatial Attention within or between Visual Hemifields: Evidence for the Different-hemifield Advantage},
year={2014},
volume={26},
number={5},
pages={938-954},
abstract={Performing a task across the left and right visual hemifields results in better performance than in a within-hemifield version of the task, termed the different-hemifield advantage. Although recent studies used transient stimuli that were presented with long ISIs, here we used a continuous objective electrophysiological (EEG) measure of competitive interactions for attentional processing resources in early visual cortex, the steady-state visual evoked potential (SSVEP). We frequency-tagged locations in each visual quadrant and at central fixation by flickering light-emitting diodes (LEDs) at different frequencies to elicit distinguishable SSVEPs. Stimuli were presented for several seconds, and participants were cued to attend to two LEDs either in one (Within) or distributed across left and right visual hemifields (Across). In addition, we introduced two reference measures: one for suppressive interactions between the peripheral LEDs by using a task at fixation where attention was withdrawn from the periphery and another estimating the upper bound of SSVEP amplitude by cueing participants to attend to only one of the peripheral LEDs. We found significantly greater SSVEP amplitude modulations in Across compared with Within hemifield conditions. No differences were found between SSVEP amplitudes elicited by the peripheral LEDs when participants attended to the centrally located LEDs compared with when peripheral LEDs had to be ignored in Across and Within trials. Attending to only one LED elicited the same SSVEP amplitude as Across conditions. Although behavioral data displayed a more complex pattern, SSVEP amplitudes were well in line with the predictions of the different-hemifield advantage account during sustained visuospatial attention.},
doi={10.1162/jocn_a_00547},
ISSN={0898-929X},
month={May},}
@INPROCEEDINGS{6817921,
author={L. Faramondi and F. Inderst and F. Pascucci and R. Setola and U. Delprato},
booktitle={International Conference on Indoor Positioning and Indoor Navigation},
title={An enhanced indoor positioning system for first responders},
year={2013},
pages={1-8},
abstract={Localization and tracking support is useful in many contexts and becomes crucial in emergency response scenarios: being aware of team location is one of the most important knowledge for incident commander. In this work both localization and tracking for rescuers are addressed in the framework of REFIRE project. The designed positioning system is based on the well-known prediction-correction schema adopted in field robotics. Proprioceptive sensors, i.e., inertial sensors and magnetometer, mounted on the waist of the rescuers, are used to form a coarse estimation of the locations. Due to the drift of inertial sensors, the position estimate needs to be updated by exteroceptive sensors, i.e., RFID system composed by tags embedded in the emergency signs as exteroceptive sensors and a wearable tag-reader. In long-lasting mission RFID tags reset the drift by providing a positioning having room-level accuracy.},
keywords={Global Positioning System;magnetometers;radiofrequency identification;sensors;REFIRE project;RFID tags;emergency response scenarios;emergency signs;exteroceptive sensors;field robotics;first responders;incident commander;indoor positioning system enhancement;inertial sensors;localization support;magnetometer;prediction-correction schema;proprioceptive sensors;room-level accuracy;team location;tracking support;wearable tag-reader;Calibration;Gyroscopes;Magnetic sensors;Magnetometers;Navigation;Radiofrequency identification;Hybrid sensor fusion;RFID waypoint guidance;Situation aware tracking algorithms;Step length estimation;Systems integrating Inertial Measurement Units (IMU)},
doi={10.1109/IPIN.2013.6817921},
month={Oct},}
@INPROCEEDINGS{6802565,
author={H. M. Naeen and M. Jalali and A. M. Naeen},
booktitle={2014 Iranian Conference on Intelligent Systems (ICIS)},
title={A trust-aware collaborative filtering system based on weighted items for social tagging systems},
year={2014},
pages={1-5},
abstract={Collaborative Filtering systems consider users' social environment to predict what each user may like to visit in a social network i.e. they collect and analyze a large amount of information on users' behavior, activities or preferences and then predict or make suggestions to users. These systems use ranks or tags each user assign to different resources to make predictions. Lately, social tagging systems, in which users can insert new contents, tag, organize, share and search for contents, are becoming more popular. These social tagging systems have a lot of valuable information, but the data expansion in them is very fast and this has led to the need for recommender systems that will predict what each user may like or need make these suggestions to them. One of the problems in these systems is: “how much can we rely on the similar users, are they trustworthy?”. In this article we use trust metric, which we conclude from users' tagging behavior, beside similarities to give suggestions. Results show considering trust in a collaborative system can lead to better performance in generating suggestions.},
keywords={behavioural sciences;collaborative filtering;recommender systems;social networking (online);trusted computing;data expansion;recommender systems;social network;social tagging systems;trust metric;trust-aware collaborative filtering system;user activities;user behavior;user preferences;user social environment;user tagging behavior;weighted items;Collaboration;Measurement;Motion pictures;Recommender systems;Social network services;Tagging;Collaborative filtering systems;Recommender systems;Tag;Trust},
doi={10.1109/IranianCIS.2014.6802565},
month={Feb},}
@INPROCEEDINGS{6785788,
author={S. Naseri and A. Bahrehmand and C. Ding and C. H. Chi},
booktitle={2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)},
title={Enhancing tag-based collaborative filtering via integrated social networking information},
year={2013},
pages={761-765},
abstract={Recently, researchers have taken tremendous strides in attempting to synthesize conventional social judgments and automated filtering within recommender systems. In this study, we aim to enhance recommendation efficiency via integrating social networking information with traditional recommendation algorithms. To achieve this objective, we first propose a new user similarity metric that not only considers tagging activities of users, but also incorporates their social relationships, such as friendship and membership, in measuring the closeness of two users. Subsequently, we define a new item prediction method which makes use of both user-to-user similarity and item-to-item similarity. Experimental outcomes on Last.fm show some positive results that attest the efficiency of our proposed approach.},
keywords={collaborative filtering;recommender systems;social networking (online);Last.fm;automated filtering;friendship;integrated social networking information;item prediction method;item-to-item similarity;membership;recommendation efficiency;recommender systems;social judgments;social relationships;tag-based collaborative filtering enhancement;user similarity metric;user tagging activities;user-to-user similarity;Algorithm design and analysis;Collaboration;Measurement;Recommender systems;Social network services;Tagging;Collaborative Filtering;Friendship;Membership;Social Networking information;Social Tagging;User Similarity},
doi={10.1145/2492517.2492658},
month={Aug},}
@INPROCEEDINGS{6783864,
author={L. Y. Wei and M. Y. Yeh and G. Lin and Y. H. Chan and W. J. Lai},
booktitle={2013 Conference on Technologies and Applications of Artificial Intelligence},
title={Discovering Point-of-Interest Signatures Based on Group Features from Geo-social Networking Data},
year={2013},
pages={182-187},
abstract={In recent years, location-based social networking services (LBSNSs) have become popular, generating a huge volume of geo-social networking data, such as check-in records and geo-tagged photos. The geo-social networking data provide a new source for discovering the real-world user behaviors. The information is useful for different applications, such as location prediction and point-of-interest (POI) recommendation. For LBSNSs, the research in POI recommendation have widely studied the user preferences over POIs and social influences between users. However, POIs are usually favored by or suitable for different kinds of groups, such as a small group, a tight group, or a close group. In this paper, we propose an approach to discovering POI signatures from geo-social networking data. For each POI, we first discover whether it has been visited by any groups of people and the features of these groups from user trajectories. We then generate the signature for each POI based on the discovered group features. We conduct experiments on the real data of the check-in records from Bright kite, and show the various kinds of POI signatures we found.},
keywords={geographic information systems;social networking (online);Brightkite;LBSNS;POI recommendation;POI signatures;check-in records;close group;geo-social networking data;geo-tagged photos;group features;location prediction;location-based social networking services;point-of-interest recommendation;point-of-interest signature generation;real-world user behavior discovery;small group;social influences;tight group;user preferences;user trajectories;Artificial intelligence;Data mining;Electronic mail;Indexes;Size measurement;Social network services;Trajectory;Location-based social networks;geo-social networking data;point-of-interest recommendation;point-of-interest signatures},
doi={10.1109/TAAI.2013.45},
ISSN={2376-6816},
month={Dec},}
@ARTICLE{6759627,
author={I. Y. Park and D. Kim},
journal={Electronics Letters},
title={Artificial magnetic conductor loaded long-range passive RFID tag antenna mountable on metallic objects},
year={2014},
volume={50},
number={5},
pages={335-336},
abstract={A passive radio frequency identification (RFID) tag antenna providing a long recognition distance is proposed, which is mountable on various types of platforms including metallic and highly dielectric objects. To increase the reading distance, the antenna is installed in a recessed metallic cavity. To reduce further the height of the antenna, an artificial magnetic conductor is placed on the bottom face of the cavity. Consequently, the tag antenna not only can be miniaturised, but also can provide long reading distances on any type of platform objects. The measured maximum reading distance and the minimum sensitivity are 12.2 m and -17 dBm, under a reader transmitting 30 dBm with a 6 dBi antenna. Good agreement between the prediction and experimental results verifies that the approach is fairly effective and useful to substantially increase the reading distance.},
keywords={antennas;conductors (electric);magnetic materials;radiofrequency identification;antenna height;artificial magnetic conductor;artificial magnetic conductor loaded long-range passive RFID tag antenna;dielectric objects;maximum reading distance;metallic cavity;metallic objects;passive radio frequency identification tag antenna;reading distance},
doi={10.1049/el.2013.2671},
ISSN={0013-5194},
month={Feb},}
@INPROCEEDINGS{6779422,
author={R. Kumar and S. Vijayakumar and S. A. Ahamed},
booktitle={2014 IEEE International Advance Computing Conference (IACC)},
title={A pragmatic approach to predict hardware failures in storage systems using MPP database and big data technologies},
year={2014},
pages={779-788},
abstract={A storage system in a data center consists of various components such as Disk Array Enclosure (DAE), disks, processors, servers, hosts running different applications, and so on. Hard disk and server failures are not frequent but are often very costly. Such failures can have a very adverse effect on the business of an organization. The ability to accurately predict an impending disk or server failure can add an essential functionality for designing a reliable, fault tolerant and continuously available storage system. This paper explains a novel approach to predict hardware failures using spectrum-kernel Parallel Support Vector Machine (Parallel SVM) method by analyzing the system events logged in the system log files. These log files not only records the events processed by the system but it also holds the messages as the system state changes. A single message in the system log file is insufficient for any prediction and such prediction is bound to be less accurate. The approach introduced in the paper uses a sequence or pattern of messages from the system log file using a Sliding Window of messages with window size of 5 message sequence to predict the likelihood of a failure. These Sliding Windows of message sequences acts as inputs to the Parallel SVM. The Parallel SVM further tags the messages to a failure or non-failure system. Data Mining techniques are used in extracting useful information from the raw dataset. A solutioning model is developed using the structured dataset and Machine Learning algorithms. This environment when implemented using actual system logs from Linux-based storage system have shown to predict a hardware failure with accuracy of 90-92 percent.},
keywords={Big Data;Linux;computer centres;data mining;hard discs;learning (artificial intelligence);parallel processing;support vector machines;system recovery;Data Mining techniques;Linux-based storage system;continuously available storage system;failure system;fault tolerant storage system;hard disk failure;hardware failure prediction;information extracting;machine learning algorithms;message pattern;message sequence;nonfailure system;parallel SVM;raw dataset;server failure;sliding window size;spectrum-kernel parallel support vector machine method;structured dataset;system log files;Conferences;Decision support systems;Handheld computers;Big Data Analytics;Cloud Computing;Hard disk & Server failure prediction;MPP Database;Machine Learning;Parallel SVM Classification},
doi={10.1109/IAdCC.2014.6779422},
month={Feb},}
@INPROCEEDINGS{6760677,
author={C. Manes and F. Martinelli},
booktitle={52nd IEEE Conference on Decision and Control},
title={State estimation under quantized measurements: A Sigma-Point Bayesian approach},
year={2013},
pages={5024-5029},
abstract={Sensors providing only quantized or binary measurements are present in several automation contexts. A remarkable example is the Radio Frequency IDentification technology when only the detection of the tags is used as information for robot localization. In this paper we propose an algorithm which merges some concepts of the Unscented Kalman Filter (UKF) with some aspects of the Particle Filter (PF). The prediction step of the proposed method is like the prediction step of a standard UKF. On the contrary, the correction step of the UKF can not be trivially implemented due to the presence of binary measurements. For this reason a different correction step is proposed here where the sigma-points weights are modified according to their agreement with the measurements, like it is done for particles of a PF. The main advantage of the proposed algorithm with respect to a PF is that much less particles are needed. Moreover, the way to generate particles in the proposed approach is not random but deterministic. A simulative comparison of the proposed approach with respect to a PF and with respect to a Quantized Kalman Filter is reported in the paper.},
keywords={Kalman filters;particle filtering (numerical methods);quantisation (signal);state estimation;PF;UKF;binary measurements;correction step;particle filter;prediction step;quantized Kalman filter;quantized measurements;radiofrequency identification technology;robot localization;sensors;sigma-point Bayesian approach;sigma-points weights;state estimation;unscented Kalman filter;Approximation methods;Computational modeling;Noise;Noise measurement;Quantization (signal);Robots;Sensors},
doi={10.1109/CDC.2013.6760677},
ISSN={0191-2216},
month={Dec},}
@INPROCEEDINGS{6732508,
author={R. W. Zhao and G. Z. Li and J. M. Liu and X. Wang},
booktitle={2013 IEEE International Conference on Bioinformatics and Biomedicine},
title={Clinical multi-label free text classification by exploiting disease label relation},
year={2013},
pages={311-315},
abstract={Clinical data describing a patient's health status can be multi-labelled. For example, a clinical record describing patient suffering from cough and fever should be tagged with both two disease labels. These co-occurred labels often have interrelation which can be exploited to improve disease classifications. In this work, we treat the categorization of free clinical text as a multi-label learning problem. However, we discover that some commonly used multi-label learning methods might suffer from some severe side effects in exploiting complicated disease label relation, such as over-exploitation of label relation and error-propagation in label prediction. Based on these findings, we propose a novel multi-label learning algorithm called Ensemble of Sampled Classifier Chains (ESCC) to improve clinical text data classification. ESCC automatically learns to select relevant disease information that is helpful to improve classification performance when exploiting possible disease relation. In our conducted experiments, ESCC shows strong advantages over other state-of-the-art multi-label algorithms on medical text data with significant improvement in performance. The proposed algorithm is promising in mining knowledge from a wide range of multi-label medical text data.},
keywords={classification;diseases;learning (artificial intelligence);medical information systems;text analysis;ESCC;classification performance;clinical multilabel free text classification;clinical multilabelled data;clinical record;clinical text data classification;cooccurred labels;disease classifications;disease information;disease label relation;ensemble of sampled classifier chains;free clinical text categorization;label prediction error-propagation;label relation over-exploitation;multilabel learning algorithm;multilabel learning problem;multilabel medical text data;patient health status;Bioinformatics;Conferences;Diseases;Measurement;Medical diagnostic imaging;Prediction algorithms;Training;clinical text classification;disease relation learning;multi-label learning},
doi={10.1109/BIBM.2013.6732508},
month={Dec},}
@INPROCEEDINGS{6719875,
author={Phuong Le-Hong and Xuan-Hieu Phan and The-Trung Tran},
booktitle={The 2013 RIVF International Conference on Computing Communication Technologies - Research, Innovation, and Vision for Future (RIVF)},
title={On the effect of the label bias problem in part-of-speech tagging},
year={2013},
pages={103-108},
abstract={This paper investigates the effect of the label bias problem of maximum entropy Markov models for part-of-speech tagging, a typical sequence prediction task in natural language processing. This problem has been underexploited and underappreciated. The investigation reveals useful information about the entropy of local transition probability distributions of the tagging model which enables us to exploit and quantify the label bias effect of part-of-speech tagging. Experiments on a Vietnamese treebank and on a French treebank show a significant effect of the label bias problem in both of the languages.},
keywords={Markov processes;learning (artificial intelligence);maximum entropy methods;natural language processing;speech processing;statistical distributions;French treebank;Vietnamese treebank;label bias problem;local transition probability distribution entropy;maximum entropy Markov models;natural language processing;part-of-speech tagging;sequence prediction task;Accuracy;Context;Entropy;Hidden Markov models;Predictive models;Probability distribution;Tagging;CRF;French;MEMM;Vietnamese;label bias problem;machine learning;part-of-speech tagging;treebank},
doi={10.1109/RIVF.2013.6719875},
month={Nov},}
@INPROCEEDINGS{6707708,
author={J. Liu and P. Pasupat and Y. Wang and S. Cyphers and J. Glass},
booktitle={2013 IEEE Workshop on Automatic Speech Recognition and Understanding},
title={Query understanding enhanced by hierarchical parsing structures},
year={2013},
pages={72-77},
abstract={Query understanding has been well studied in the areas of information retrieval and spoken language understanding (SLU). There are generally three layers of query understanding: domain classification, user intent detection, and semantic tagging. Classifiers can be applied to domain and intent detection in real systems, and semantic tagging (or slot filling) is commonly defined as a sequence-labeling task - mapping a sequence of words to a sequence of labels. Various statistical features (e.g., n-grams) can be extracted from annotated queries for learning label prediction models; however, linguistic characteristics of queries, such as hierarchical structures and semantic relationships, are usually neglected in the feature extraction process. In this work, we propose an approach that leverages linguistic knowledge encoded in hierarchical parse trees for query understanding. Specifically, for natural language queries, we extract a set of syntactic structural features and semantic dependency features from query parse trees to enhance inference model learning. Experiments on real natural language queries show that augmenting sequence labeling models with linguistic knowledge can improve query understanding performance in various domains.},
keywords={computational linguistics;feature extraction;grammars;natural language processing;query processing;statistical analysis;SLU;domain classification;feature extraction;hierarchical parse trees;hierarchical parsing structure;inference model learning;information retrieval;label prediction model;linguistic characteristic;linguistic knowledge;n-grams;natural language queries;query parse trees;query understanding;semantic dependency feature;semantic tagging;sequence-labeling task;slot filling;spoken language understanding;statistical feature;syntactic structural feature;user intent detection;Feature extraction;Motion pictures;Natural languages;Pragmatics;Semantics;Syntactics;Tagging;linguistic parsing;query understanding;semantic tagging},
doi={10.1109/ASRU.2013.6707708},
month={Dec},}
@INPROCEEDINGS{6694518,
author={A. Narzullaev and H. S. Mohd},
booktitle={2013 IEEE International Conference on RFID-Technologies and Applications (RFID-TA)},
title={Wi-Fi signal strengths database construction for indoor positioning systems using Wi-Fi RFID},
year={2013},
pages={1-5},
abstract={Nowadays, fingerprinting based Wi-Fi positioning systems successfully provide location information to mobile users. Main idea behind fingerprinting is to build signal strength database of target area prior to location estimation. This process is called calibration. Indoor positioning system accuracy highly depends on calibration (sampling) intensity. This procedure requires huge amount of time and effort, and makes large-scale deployments of indoor positioning systems non-trivial. Newly constructed database may no longer be valid if there are any major changes in the target site. In this research we present a new approach of constructing fingerprint database. We propose a hybrid calibration procedure that combines signal sampling process with path-loss prediction algorithm. Instead of manual signal sampling, proposed method requires several Wi-Fi RFID tags to be installed in a target site. Advantage of such tag is that it can be read directly by commercial Wi-Fi access points from long distance. Several RFID tags mounted in target area will monitor the signal strength levels continuously and send scan data to the server. Whenever there are significant changes in signal levels detected, server will initiate database reconstruction procedure. Compared to existing calibration procedure our method requires only few signal samples from RFID tags to be collected and rest of the database is recovered using path-loss prediction algorithm.},
keywords={calibration;indoor communication;radiofrequency identification;signal sampling;wireless LAN;Wi-Fi RFID;Wi-Fi positioning systems;Wi-Fi signal strengths;calibration intensity;database construction;fingerprint database;hybrid calibration procedure;indoor positioning systems;large-scale deployments;path-loss prediction;signal sampling process;Databases;Monitoring;Radiofrequency identification;Resource management;Standards;Training;Transmitters},
doi={10.1109/RFID-TA.2013.6694518},
month={Sept},}
@INPROCEEDINGS{6690037,
author={D. Zhu and Y. Fukazawa and J. Ota},
booktitle={2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)},
title={Tri-layer-cluster Generation Model for Activity Prediction},
year={2013},
volume={1},
pages={359-366},
abstract={We propose a topic model capable of generating tri-layer clusters, each of which is composed of a topic layer, an activity layer and a word layer. The objective is to better predict activities involved in documents by considering general topics of the activities for clustering. The proposed model is a supervised topic model based on the Latent Dirichlet Allocation (LDA). As a follow-up study of word-pair generation LDA (wpLDA) model, the model introduces the topic-specific activity distribution as an external input, with an activity node inserted into the main generation thread. In addition, we refer to D. Ramage et al.'s one-to-one correspondence to directly learn word-activity tags. An experiment was conducted to prove the feasibility of this model. We chose ten top-listed activities from the wish clusters obtained by the previous wpLDA research, and used each as the key words to extract thirty tweets for training and five for testing, respectively, tagging the tweets with the corresponding activities. By applying the proposed model, we obtained the expected tri-layer clusters in the training phase. Then, in the testing phase, we utilized the activity-specific word distribution derived from the training results to learn the activities of the testing documents. The Stanford Classifier was put forward as the control group, and the activity prediction accuracy demonstrates that the proposed model exhibits the superiority in multi-activity prediction.},
keywords={document handling;pattern classification;pattern clustering;Stanford classifier;activity layer;activity prediction;latent Dirichlet allocation;supervised topic model;topic layer;topic-specific activity distribution;tri-layer-cluster generation model;word layer;word-pair generation LDA model;Accuracy;Computational modeling;Conferences;Electronic mail;Predictive models;Testing;Training;LDA model;activity prediction;tri-layer cluster;wpLDA},
doi={10.1109/WI-IAT.2013.51},
month={Nov},}
@INPROCEEDINGS{6639291,
author={A. Bhargava and A. Celikyilmaz and D. Hakkani-Tür and R. Sarikaya},
booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
title={Easy contextual intent prediction and slot detection},
year={2013},
pages={8337-8341},
abstract={Spoken language understanding (SLU) is one of the main tasks of a dialog system, aiming to identify semantic components in user utterances. In this paper, we investigate the incorporation of context into the SLU tasks of intent prediction and slot detection. Using a corpus that contains session-level information, including the start and end of a session and the sequence of utterances within it, we experiment with the incorporation of information from previous intra-session utterances into the SLU tasks on a given utterance. For slot detection, we find that including features indicating the slots appearing in the previous utterances gives no significant increase in performance. In contrast, for intent prediction we find that a similar approach that incorporates the intent of the previous utterance as a feature yields relative error rate reductions of 6.7% on transcribed data and 8.7% on automatically-recognized data. We also find similar gains when treating intent prediction of utterance sequences as a sequential tagging problem via SVM-HMMs.},
keywords={interactive systems;natural language processing;automatically-recognized data;contextual intent prediction;dialog system;sequential tagging problem;session-level information;slot detection;spoken language understanding;Abstracts;Pragmatics;contextual models;intent prediction;slot detection;spoken language understanding},
doi={10.1109/ICASSP.2013.6639291},
ISSN={1520-6149},
month={May},}
@INPROCEEDINGS{6639306,
author={H. Adel and N. T. Vu and F. Kraus and T. Schlippe and H. Li and T. Schultz},
booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
title={Recurrent neural network language modeling for code switching conversational speech},
year={2013},
pages={8411-8415},
abstract={Code-switching is a very common phenomenon in multilingual communities. In this paper, we investigate language modeling for conversational Mandarin-English code-switching (CS) speech recognition. First, we investigate the prediction of code switches based on textual features with focus on Part-of-Speech (POS) tags and trigger words. Second, we propose a structure of recurrent neural networks to predict code-switches. We extend the networks by adding POS information to the input layer and by factorizing the output layer into languages. The resulting models are applied to our task of code-switching language modeling. The final performance shows 10.8% relative improvement in perplexity on the SEAME development set which transforms into a 2% relative improvement in terms of Mixed Error Rate and a relative improvement of 16.9% in perplexity on the evaluation set which leads to a 2.7% relative improvement of MER.},
keywords={error statistics;recurrent neural nets;speech recognition;CS speech recognition;MER;POS tags;SEAME development set;conversational Mandarin-English code-switching speech recognition;evaluation set perplexity;mixed error rate;multilingual communities;part-of-speech tags;recurrent neural network language modeling;textual features;trigger words;Computational modeling;Error analysis;Recurrent neural networks;Speech;Speech coding;Speech recognition;Training;code-switching;recurrent neural network language model},
doi={10.1109/ICASSP.2013.6639306},
ISSN={1520-6149},
month={May},}
@INPROCEEDINGS{6616818,
author={Y. Ma and E. C. Kan},
booktitle={2013 IEEE International Wireless Symposium (IWS)},
title={Multi-path interference reduction in passive NLTL RFID tags},
year={2013},
pages={1-4},
abstract={We propose a multi-path interference reduction method of continuous wave (CW) passive RFID for indoor ranging applications by adopting nonlinear transmission line (NLTL) tags. Because the power and phase information are contained within the second harmonic (SH) rather than the fundamental frequency, interference and phase errors caused by direct reflections of interrogating signal can be greatly reduced. We present both theoretical predictions and simulations, followed by experimental results to verify the effectiveness of the proposed approach.},
keywords={indoor radio;interference suppression;radiofrequency identification;reflection;continuous wave passive RFID;indoor ranging applications;interrogating signal;multipath interference reduction method;nonlinear transmission line;passive NLTL RFID tags;phase errors;phase information;second harmonic;Distance measurement;Downlink;Interference;Passive RFID tags;Reflection;Uplink;Continuous wave;NLTL;harmonic generation;multi-path reflection;passive RFID;ranging},
doi={10.1109/IEEE-IWS.2013.6616818},
month={April},}
@INPROCEEDINGS{6607505,
author={Y. H. Yang},
booktitle={2013 IEEE International Conference on Multimedia and Expo (ICME)},
title={Towards real-time music auto-tagging using sparse features},
year={2013},
pages={1-6},
abstract={Unsupervised feature learning algorithms such as sparse coding and deep belief networks have been shown a viable alternative to hand-crafted feature design for music information retrieval. Nevertheless, such algorithms are usually computationally expensive. This paper investigates techniques to accelerate sparse feature extraction and music classification. To study the trade-off between computational efficiency and accuracy, we compare state-of-the-art, dense audio features with sparse features computed using 1) sparse coding with a random dictionary, 2) randomized clustering forest, and 3) an extension of randomized clustering forest to temporal signals. For classifier training and prediction, we compare support vector machines with linear or non-linear kernel functions. We conduct evaluation on music auto-tagging for 140 genre/style tags using a subset of 7,799 songs of the CAL10k data set. Our result leads to an 11-fold speed increase with 3.45% accuracy loss comparing to dense features. With the proposed sparse features, the feature extraction and auto-tagging operations can be finished in 1 second per song, with 0.1302 tagging accuracy in mean average precision.},
keywords={feature extraction;information retrieval;music;support vector machines;CAL10k data set;auto-tagging operations;classifier prediction;classifier training;computational efficiency;deep belief networks;dense audio features;hand-crafted feature design;mean average precision;music classification;music information retrieval;nonlinear kernel functions;random dictionary;randomized clustering forest;real-time music auto-tagging;sparse coding;sparse feature extraction;sparse features;support vector machines;temporal signals;unsupervised feature learning algorithms;Abstracts;Lead;Mel frequency cepstral coefficient;Unsupervised feature learning;music auto-tagging;randomized clustering forest;sparse coding},
doi={10.1109/ICME.2013.6607505},
ISSN={1945-7871},
month={July},}
@ARTICLE{6521356,
author={Y. Y. Chen and A. J. Cheng and W. H. Hsu},
journal={IEEE Transactions on Multimedia},
title={Travel Recommendation by Mining People Attributes and Travel Group Types From Community-Contributed Photos},
year={2013},
volume={15},
number={6},
pages={1283-1295},
abstract={Leveraging community-contributed data (e.g., blogs, GPS logs, and geo-tagged photos) for personalized recommendation is one of the active research problems since there are rich contexts and human activities in such explosively growing data. In this work, we focus on personalized travel recommendation and show promising applications by leveraging the freely available community-contributed photos. We propose to conduct personalized travel recommendation by further considering specific user profiles or attributes (e.g., gender, age, race) as well as travel group types (e.g., family, friends, couple). Instead of mining photo logs only, we exploit the automatically detected people attributes and travel group types in the photo contents. By information-theoretic measures, we demonstrate that such detected user profiles are informative and effective for travel recommendation-especially providing a promising aspect for personalization. We effectively mine the demographics of individual and group travelers for different locations (or landmarks) and their travel paths. A probabilistic Bayesian learning framework which further entails mobile recommendation on the spot is introduced as well. We experiment on more than 10 million photos collected from 19 major cities worldwide and conduct the extensive investigation of profiling activities in communities according to temporal and spatial information. Note that the photos in the paper attribute to various Flickr users under the Creative Commons License. The experiments confirm that people attributes of individuals and groups are promising and orthogonal to prior works using travel logs only and can further improve prior travel recommendation methods especially for difficult predictions by further leveraging user contexts via mobile devices.},
keywords={Bayes methods;data mining;learning (artificial intelligence);personal information systems;probability;recommender systems;social networking (online);Flickr;active research problems;automatically detected people attribute mining;community-contributed data;community-contributed photo content;creative commons license;information-theoretic measures;mobile devices;mobile recommendation method;personalized travel recommendation method;photo logs mining;probabilistic Bayesian learning framework;spatial information;temporal information;travel group type mining;Geo-tagged photos;people attributes;travel groups;travel recommendation},
doi={10.1109/TMM.2013.2265077},
ISSN={1520-9210},
month={Oct},}
@INPROCEEDINGS{6569128,
author={M. F. Chiang and W. Y. Zhu and W. C. Peng and P. S. Yu},
booktitle={2013 IEEE 14th International Conference on Mobile Data Management},
title={Distant-Time Location Prediction in Low-Sampling-Rate Trajectories},
year={2013},
volume={1},
pages={117-126},
abstract={With the growth of location-based services and social services, low-sampling-rate trajectories from check-in data or photos with geo-tag information becomes ubiquitous. In general, most detailed moving information in low-sampling-rate trajectories are lost. Prior works have elaborated on distant-time location prediction in high-sampling-rate trajectories. However, existing prediction models are pattern-based and thus not applicable due to the sparsity of data points in low-sampling-rate trajectories. For example, it becomes difficult to derive trajectory patterns, let alone utilizing trajectory patterns for distant-time location prediction. In this paper, given a query time, the current location and time, we aim to predict the location of an object at the query time. To address the sparsity in low-sampling-rate trajectories, we develop a Reachability-based prediction model on Time-constrained Mobility Graph (abbreviated as RTMG) to predict locations for distant-time queries. Specifically, we design an adaptive temporal exploration approach to extract effective supporting trajectories that are temporally close to the query time. These data points are then represented as a Time-constrained user mobility Graph (refers to as TG). In light of TG, we further derive the reachability probabilities among locations in TG. Thus, a location with maximum reachability from the current location among all possible locations in supporting trajectories is considered as the prediction result. To efficiently process queries, we proposed an index structure SOIT to organize location records for on-line query processing. We conduct extensive experiments on real low-sampling-rate datasets and demonstrate the effectiveness and efficiency of RTMG.},
keywords={data handling;data structures;indexing;mobile computing;probability;public administration;query processing;reachability analysis;social networking (online);RTMG;SOIT index structure;adaptive temporal exploration approach;check-in data;check-in photos;data points;distant-time location prediction;geotag information;high-sampling-rate trajectories;location-based services;low-sampling-rate trajectories;online query processing;query time;reachability probabilities;reachability-based prediction model;social services;time-constrained mobility graph;time-constrained user mobility graph;trajectory pattern derivation;trajectory pattern utilization;Adaptation models;Indexes;Predictive models;Probability;Query processing;Trajectory;location prediction;trajectory pattern mining and low-sampling-rate trajectories},
doi={10.1109/MDM.2013.22},
ISSN={1551-6245},
month={June},}
@INPROCEEDINGS{6562476,
author={D. R. Gallagher and D. C. Malocha},
booktitle={2012 IEEE International Ultrasonics Symposium},
title={Noise-like transducers for ultra wide band SAW correlators},
year={2012},
pages={1774-1777},
abstract={This paper presents the development of sampled Gaussian noise transducers for surface acoustic wave (SAW) correlation filters for use in ultra-wideband (UWB) communications and tagging. The orthogonal frequency coded (OFC) SAW correlator concept was previously demonstrated using a uniformly weighted OFC coded dispersive transducer in conjunction with a wideband apodized transducer. The interdigital SAW transducer can accurately represent the noise-signal by electrode apodization. For an ideal-Gaussian white noise signal, there are no correlation sidelobes and cross-correlation of other codes is extremely small. For a finite truncated white-noise Gaussian signal, that is also frequency band-limited, the auto-correlation sidelobes are produced, a function of the signal time bandwidth product. The implementation of noise-like generators and coding can be very useful in UWB systems. The UWB noise transducer used as a generator, can provide greater resistance to jamming and allows an UWB communication system to coexist with other systems. Code generation is performed in the transmitter using the noise weighted SAW filter and is correlated at the receiver using a matching filter device; eliminating the need for complex signal processing. This can lead to a very robust and simple short-range UWB communication system. The theoretical foundation for the signal analysis and transducer implementation will be presented. Coupling of mode (COM) theory will be used to show the important transducer design parameters for transducer evaluation. SAW correlators with fractional bandwidth of greater than 25% are fabricated on lithium niobate (LiNbO3) having a center frequency of 250 MHz. Discussion of the transducer design, analysis and measurements are presented. Results are shown for operation in a matched filter correlator for use in an UWB communication system and compared to predictions, showing good results.},
keywords={Gaussian noise;correlators;electric resistance;lithium compounds;orthogonal codes;radio transmitters;signal representation;surface acoustic wave filters;transducers;ultra wideband communication;white noise;COM theory;LiNbO3;OFC SAW correlator concept;SAW correlation filters;UWB noise transducer;UWB systems;autocorrelation sidelobes;code generation;complex signal processing;coupling of mode theory;electrode apodization;finite truncated white-noise Gaussian signal;fractional bandwidth;frequency 250 MHz;ideal-Gaussian white noise signal;interdigital SAW transducer;matching filter device;noise-like transducers;orthogonal frequency coded SAW correlator concept;sampled Gaussian noise transducers;short-range UWB communication system;signal analysis;signal time bandwidth product;surface acoustic wave correlation filters;transducer design parameters;transducer evaluation;transducer implementation;ultrawide band SAW correlators;ultrawideband communications;ultrawideband tagging;uniformly weighted OFC coded dispersive transducer;wideband apodized transducer;Bandwidth;Chirp;Correlation;Correlators;Noise;Surface acoustic waves;Transducers},
doi={10.1109/ULTSYM.2012.0445},
ISSN={1051-0117},
month={Oct},}
@INPROCEEDINGS{6544858,
author={Y. Fujiwara and M. Nakatsuji and H. Shiokawa and M. Onizuka},
booktitle={2013 IEEE 29th International Conference on Data Engineering (ICDE)},
title={Efficient search algorithm for SimRank},
year={2013},
pages={589-600},
abstract={Graphs are a fundamental data structure and have been employed to model objects as well as their relationships. The similarity of objects on the web (e.g., webpages, photos, music, micro-blogs, and social networking service users) is the key to identifying relevant objects in many recent applications. SimRank, proposed by Jeh and Widom, provides a good similarity score and has been successfully used in many applications such as web spam detection, collaborative tagging analysis, link prediction, and so on. SimRank computes similarities iteratively, and it needs O(N4T) time and O(N2) space for similarity computation where N and T are the number of nodes and iterations, respectively. Unfortunately, this iterative approach is computationally expensive. The goal of this work is to process top-k search and range search efficiently for a given node. Our solution, SimMat, is based on two ideas: (1) It computes the approximate similarity of a selected node pair efficiently in non-iterative style based on the Sylvester equation, and (2) It prunes unnecessary approximate similarity computations when searching for the high similarity nodes by exploiting estimations based on the Cauchy-Schwarz inequality. These two ideas reduce the time and space complexities of the proposed approach to O(Nn) where n is the target rank of the low-rank approximation (n ≪ N in practice). Our experiments show that our approach is much faster, by several orders of magnitude, than previous approaches in finding the high similarity nodes.},
keywords={approximation theory;computational complexity;graph theory;search problems;Cauchy-Schwarz inequality;SimMat;SimRank;Sylvester equation;Web spam detection;Webpage;collaborative tagging analysis;data structure;graph;link prediction;low-rank approximation;microblog;music;noniterative style;object similarity;photo;range search;search algorithm;similarity computation;similarity node;similarity score;social networking service user;space complexity;time complexity;top-k search;Approximation methods;Eigenvalues and eigenfunctions;Equations;Iterative methods;Mathematical model;Social network services;Vectors},
doi={10.1109/ICDE.2013.6544858},
ISSN={1063-6382},
month={April},}
@INPROCEEDINGS{6529013,
author={B. Akalya and B. Sumathi and G. Arock Nancy},
booktitle={2013 International Conference on Circuits, Power and Computing Technologies (ICCPCT)},
title={Personalized Image search through tag-based user profile on social websites},
year={2013},
pages={1174-1179},
abstract={With the increase of resource-sharing social Web-sites like Flicker, YouTube, del.icio.us, Personalized Search becomes more imperative and challenging, as users demand higher retrieval quality. A social sharing websites is a developed online website service which enables users to add, share, annotate, and tag images. A large -scale user generated metadata that describes and gives information about other data and not only facilitate users in sharing and organizing multimedia contents but provide useful information to improve Media Retrieval, Unlimited backup and Management. A Personalized Image search tracks a registered user's log history, and then adjusts the search results based upon the interests, preferences and information needs of users. Personalized Image search differs from general Image Search, which returns identical search results to all users for identical queries, regardless of varied user interests and information needs. In this paper we exploit the Social annotations and Novel Framework for considering the user query relevance and user specific-topic to learn personalized image search. The proposed framework contains two techniques: 1) Utility and Prediction model for social annotations. 2) We introduce a Hit Matrix technique for user query relevance and preference into the specific topic space. Performance evaluation shows that our proposed method outperforms the existing method and also shows that the developed model demonstrates the effectives of the Personalized Image Search},
keywords={image retrieval;social networking (online);Flicker;YouTube;del.icio.us;general image search;hit matrix technique;media retrieval;online Website service;personalized image search;resource-sharing social Websites;retrieval quality;tag-based user profile;user query relevance;Biological system modeling;Biomedical imaging;Vocabulary;Hit Matrix;Personalized Image search;Query Relevance;Social Annotation;User Profile;User Specific-Topic},
doi={10.1109/ICCPCT.2013.6529013},
month={March},}
@INPROCEEDINGS{6513531,
author={M. Boettcher and G. Gabrielli and B. M. Al-Hashimi and D. Kershaw},
booktitle={2013 Design, Automation Test in Europe Conference Exhibition (DATE)},
title={MALEC: A Multiple Access Low Energy Cache},
year={2013},
pages={368-373},
abstract={This paper addresses the dynamic energy consumption in L1 data cache interfaces of out-of-order superscalar processors. The proposed Multiple Access Low Energy Cache (MALEC) is based on the observation that consecutive memory references tend to access the same page. It exhibits a performance level similar to state of the art caches, but consumes approximately 48% less energy. This is achieved by deliberately restricting accesses to only 1 page per cycle, allowing the utilization of single-ported TLBs and cache banks, and simplified lookup structures of Store and Merge Buffers. To mitigate performance penalties it shares memory address translation results between multiple memory references, and shares data among loads to the same cache line. In addition, it uses a Page-Based Way Determination scheme that holds way information of recently accessed cache lines in small storage structures called way tables that are closely coupled to TLB lookups and are able to simultaneously service all accesses to a particular page. Moreover, it removes the need for redundant tag-array accesses, usually required to confirm way predictions. For the analyzed workloads, MALEC achieves average energy savings of 48% in the L1 data memory subsystem over a high performance cache interface that supports up to 2 loads and 1 store in parallel. Comparing MALEC and the high performance interface against a low power configuration limited to only 1 load or 1 store per cycle reveals 14% and 15% performance gain requiring 22% less and 48% more energy, respectively. Furthermore, Page-Based Way Determination exhibits coverage of 94%, which is a 16% improvement over the originally proposed line-based way determination.},
keywords={Computational efficiency;Out of order;Random access memory},
doi={10.7873/DATE.2013.085},
ISSN={1530-1591},
month={March},}
@ARTICLE{6494264,
author={A. Deoras and G. Tur and R. Sarikaya and D. Hakkani-Tür},
journal={IEEE Transactions on Audio, Speech, and Language Processing},
title={Joint Discriminative Decoding of Words and Semantic Tags for Spoken Language Understanding},
year={2013},
volume={21},
number={8},
pages={1612-1621},
abstract={Most Spoken Language Understanding (SLU) systems today employ a cascade approach, where the best hypothesis from Automatic Speech Recognizer (ASR) is fed into understanding modules such as slot sequence classifiers and intent detectors. The output of these modules is then further fed into downstream components such as interpreter and/or knowledge broker. These statistical models are usually trained individually to optimize the error rate of their respective output. In such approaches, errors from one module irreversibly propagates into other modules causing a serious degradation in the overall performance of the SLU system. Thus it is desirable to jointly optimize all the statistical models together. As a first step towards this, in this paper, we propose a joint decoding framework in which we predict the optimal word as well as slot sequence (semantic tag sequence) jointly given the input acoustic stream. Furthermore, the improved recognition output is then used for an utterance classification task, specifically, we focus on intent detection task. On a SLU task, we show 1.5% absolute reduction (7.6% relative reduction) in word error rate (WER) and 1.2% absolute improvement in F measure for slot prediction when compared to a very strong cascade baseline comprising of state-of-the-art large vocabulary ASR followed by conditional random field (CRF) based slot sequence tagger. Similarly, for intent detection, we show 1.2% absolute reduction (12% relative reduction) in classification error rate.},
keywords={decoding;natural language processing;random processes;signal classification;speech coding;speech recognition;statistical analysis;ASR;CRF;F measure;SLU systems;WER;automatic speech recognizer;classification error rate;conditional random field;error rate optimization;intent detectors;interpreter;joint discriminative semantic tag decoding;joint discriminative word decoding;knowledge broker;natural language;slot sequence classifiers;slot sequence tagger;spoken language understanding systems;statistical models;utterance classification task;word error rate;ASR;CRF;Joint Decoding;MaxEnt;SLU;lattice decoding;speech and dialog understanding;spoken language processing},
doi={10.1109/TASL.2013.2256894},
ISSN={1558-7916},
month={Aug},}
@INPROCEEDINGS{6460849,
author={R. Liu and Y. Wang and H. Yu and S. Naoi},
booktitle={Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)},
title={A renewed image annotation baseline by image embedding and tag correlation},
year={2012},
pages={3216-3219},
abstract={This paper presents a renewed image annotation baseline method under the nearest neighbor tag transfer framework. Two key problems are considered in this paper: (1) which images are determined as the neighbors; (2) how their keywords are transferred. Firstly, a soft neighbor selection scheme is designed by image embedding technique, with which we can provide more power to the crucial neighbors in decision making. Next, diffused tag propagation is introduced to allow one tag be propagated to other relevant tags. Besides this, the above two measures are formulated into an optimization framework to further improve the prediction performance. Experimental results on standard database show that the proposed approaches outperform the current state-of-the-art methods.},
keywords={correlation theory;decision making;image retrieval;optimisation;decision making;diffused tag propagation;image embedding technique;nearest neighbor tag transfer framework;optimization;renewed image annotation baseline method;soft neighbor selection scheme;tag correlation;Correlation;Image reconstruction;Measurement;Optimization;Semantics;Standards;Training},
ISSN={1051-4651},
month={Nov},}
@INPROCEEDINGS{6425640,
author={F. G. Davoodi and O. Fatemi},
booktitle={2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
title={Tag Based Recommender System for Social Bookmarking Sites},
year={2012},
pages={934-940},
abstract={It is often essential for people to consult with others and ask them about their past experience and thoughts when making choices. Exchanging ideas among people has become more meaningful since the extensive growth of information on the World Wide Web (WWW). People have access to tremendous amount of information, but choosing the most relevant information is of high effort. It was when recommender systems came into existence in 1992 in order to assist users in the process of finding the most appropriate information on WWW, and identify sets of items which are likely to be interesting for the users. Recommender systems have used different sources of data in order to identify users' interests. In addition, by growth of social resource sharing like social book marking sites, tagging activities can be considered as explicit knowledge for user and item modeling. Existing recommender systems lack use of external source of information for recommending the most appropriate item. They mainly use the information of their own website, while there is valuable information on the web which could improve the performance of the predictions. In this paper, we use Open Directory Project (ODP) data as external knowledge about web pages in addition to tagging activities of users in a social book marking site. We have designed a content based recommender system which can recommend the most relevant web pages for each user based on the user's profile and gathered information about web pages from ODP as implicit data. We empirically evaluate effect of ODP data on the predictions using Delicious dataset in order to analyze the performance of the proposed method. The results show that our recommender system outperforms when it uses ODP information as external source of data.},
keywords={content management;recommender systems;social networking (online);WWW;Web page;World Wide Web;content based recommender system;item modeling;open directory project;social bookmarking site;social resource sharing;tag based recommender system;Collaboration;Recommender systems;Search engines;Tagging;Web pages;World Wide Web;Content based Recommender;Open Directory Project;Recommender System;Social bookmarking;User modelling},
doi={10.1109/ASONAM.2012.166},
month={Aug},}
@INPROCEEDINGS{6413784,
author={P. Balamurugan and S. Shevade and T. R. Babu},
booktitle={2012 IEEE 12th International Conference on Data Mining},
title={Sequential Alternating Proximal Method for Scalable Sparse Structural SVMs},
year={2012},
pages={61-70},
abstract={Structural Support Vector Machines (SSVMs) have recently gained wide prominence in classifying structured and complex objects like parse-trees, image segments and Part-of-Speech (POS) tags. Typical learning algorithms used in training SSVMs result in model parameters which are vectors residing in a large-dimensional feature space. Such a high-dimensional model parameter vector contains many non-zero components which often lead to slow prediction and storage issues. Hence there is a need for sparse parameter vectors which contain a very small number of non-zero components. L1-regularizer and elastic net regularizer have been traditionally used to get sparse model parameters. Though L1-regularized structural SVMs have been studied in the past, the use of elastic net regularizer for structural SVMs has not been explored yet. In this work, we formulate the elastic net SSVM and propose a sequential alternating proximal algorithm to solve the dual formulation. We compare the proposed method with existing methods for L1-regularized Structural SVMs. Experiments on large-scale benchmark datasets show that the proposed dual elastic net SSVM trained using the sequential alternating proximal algorithm scales well and results in highly sparse model parameters while achieving a comparable generalization performance. Hence the proposed sequential alternating proximal algorithm is a competitive method to achieve sparse model parameters and a comparable generalization performance when elastic net regularized Structural SVMs are used on very large datasets.},
keywords={learning (artificial intelligence);pattern classification;support vector machines;L1-regularizer;complex object classification;dual elastic net SSVM;elastic net regularizer;high-dimensional model parameter vector;large-dimensional feature space;learning algorithms;nonzero components;scalable sparse structural SVM;sequential alternating proximal method;sparse model parameters;sparse parameter vectors;structural support vector machines;structured object classification;Computer science;Context;Electronic mail;Scalability;Support vector machine classification;Vectors;Alternating Proximal method;Structural SVMs},
doi={10.1109/ICDM.2012.81},
ISSN={1550-4786},
month={Dec},}
@INPROCEEDINGS{6390573,
author={L. Kui and J. Yang and Y. Cheng and B. He},
booktitle={Proceedings of the 31st Chinese Control Conference},
title={Prosody phrase break prediction in Vietnamese using decision tree},
year={2012},
pages={3733-3736},
abstract={The intelligibility of synthesized speech is satisfactory, but the naturalness is fair in Vietnamese speech synthesis system without prosody phrase breaks. In order to improve the naturalness of synthesized speech, prosody phrase (L3) breaks are automatically predicted by using C4.5 decision tree algorithm in this paper. Firstly, we collect Vietnamese text and construct corpus. Then we obtain training date and testing data after word segmentation, part of speech (POS) tags and manual label of L3 breaks for the sentences in the corpus. Word segmentation and part of speech (POS) tags are conducted by applying text analysis software. Secondly, we extract the relevant attribute from the training data, and then obtain decision tree by using C4.5 decision tree algorithm. According to the pruned decision tree, L3 breaks are predicted in prosody labeling stage. Finally, we conduct objective and subjective test to the prediction. The results of evaluation show that an F-Score of 59.96% and acceptable rate of 70.6% can be achieved for the L3 prediction in closed set, and there is an F-Score of 58.37% and acceptable rate of 68.9% in open set. This experiment for the further improvement of naturalness of synthesized Vietnamese speech lays a foundation.},
keywords={decision trees;speech intelligibility;speech synthesis;text analysis;C4.5 decision tree algorithm;F-Score;L3 breaks;POS;Vietnamese speech synthesis system;Vietnamese text;part of speech tags;prosody labeling stage;prosody phrase break prediction;pruned decision tree;synthesized speech intelligibility;text analysis software;word segmentation;Decision trees;Educational institutions;Electronic mail;Labeling;Prediction algorithms;Speech;Speech synthesis;C4.5;Vietnamese;decision tree;prosody phrase;speech synthesis},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{6384979,
author={C. Ming and B. Na},
booktitle={2012 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery},
title={An Efficient and Flexible Embedded Memory IP Compiler},
year={2012},
pages={268-273},
abstract={The efficiency and flexibility of current state-of-the-art memory compilers are often limited due to the heavy dependence on specific circuit structure, which leads to the high recurring design cost and long design cycle. To address these issues systematically, a set of novel design schemes have been proposed in this paper, including a general, scalable memory architecture that is suitable for various memories, an highly efficient layout tiling method based on overlap-distance, an automatic and easy-to-use template expansion scheme using an ASP-style tag language, and a general and accurate timing and power prediction technique based on a piecewise polynomial interpolation algorithm. To verify the effectiveness of these schemes proposed in this paper, a single-port SRAM compiler with the maximum capacity of 1Mb has been developed and taped out successfully in SMIC 65nm process.},
keywords={SRAM chips;embedded systems;interpolation;polynomials;circuit structure;efficient embedded memory IP compiler;flexible embedded memory IP compiler;polynomial interpolation algorithm;single-port SRAM compiler;Integrated circuit modeling;Interpolation;Mathematical model;Memory management;Random access memory;Tiles;Timing;SRAM;interpolation;memory compiler;modeling;tiling},
doi={10.1109/CyberC.2012.52},
month={Oct},}
@INPROCEEDINGS{6378636,
author={F. M. Sleiman and R. G. Dreslinski and T. F. Wenisch},
booktitle={2012 IEEE 30th International Conference on Computer Design (ICCD)},
title={Embedded way prediction for last-level caches},
year={2012},
pages={167-174},
abstract={This paper investigates Embedded Way Prediction for large last-level caches (LLCs): an architecture and circuit design to provide the latency of parallel tag-data access at substantial energy savings. Existing way prediction approaches for L1 caches are compromised by the high associativity and filtered temporal locality of LLCs. We demonstrate: (1) the need for wide partial tag comparison, which we implement with a dynamic CAM alongside the data sub-array wordline decode, and (2) the inhibit bit, an architectural innovation to provide accurate predictions when the partial tag comparison is inconclusive. We present circuit critical-path and architectural power/performance studies demonstrating speedups of up to 15.4% (6.6% average) for scientific and server applications, matching the performance of parallel tag-data access while reducing energy overhead by 40%.},
keywords={cache storage;embedded systems;L1 caches;LLC;architectural innovation;circuit critical-path;circuit design;data subarray wordline decode;dynamic CAM;embedded way prediction;energy overhead reduction;last-level caches;parallel tag-data access;partial tag comparison;temporal locality;wide partial tag comparison;Arrays;Computer aided manufacturing;Decoding;Delay;Random access memory;Servers;Tiles},
doi={10.1109/ICCD.2012.6378636},
ISSN={1063-6404},
month={Sept},}
@INPROCEEDINGS{6377120,
author={J. Ratsaby and V. Sirota},
booktitle={2012 IEEE 27th Convention of Electrical and Electronics Engineers in Israel},
title={FPGA-based data compressor based on prediction by partial matching},
year={2012},
pages={1-5},
abstract={We design and develop a data compression engine on a single FPGA chip that is used as part of a text-classification application. The implementation of the prediction by partial matching algorithm and arithmetic coding data compression is totally in hardware without any software code. Our design implements a dynamic data structure to store the symbol frequency counts up to maximal order of 2. The computation of the tag-interval that encodes the data sequence in arithmetic coding is done in a parallel architecture that achieves a high speedup factor. Even with a relatively slow 50 Mhz clock our hardware engine performs more than 70 times faster than a software-based implementation in C on a CPU running on a 3 Ghz clock.},
keywords={data compression;field programmable gate arrays;parallel architectures;FPGA-based data compressor;arithmetic coding data compression;data compression engine;data sequence;dynamic data structure;frequency 3 GHz;frequency 50 MHz;parallel architecture;partial matching algorithm;speedup factor;symbol frequency counts;tag-interval computation;text-classification application;Context;Data compression;Data structures;Encoding;Field programmable gate arrays;Hardware;Random access memory;Data compression;FPGA;parallel architecture},
doi={10.1109/EEEI.2012.6377120},
month={Nov},}
@INPROCEEDINGS{6362582,
author={E. L. Berz and F. P. Hessel and M. C. de Azambuja and J. C. Ody},
booktitle={2012 IEEE 23rd International Symposium on Personal, Indoor and Mobile Radio Communications - (PIMRC)},
title={Prediction of RFID systems coverage applied to smart cards scenario},
year={2012},
pages={1484-1490},
abstract={RFID systems usually need to be applied where the installation cost can be very high, and thus, running a simulation in such environments would bring many benefits such as saving time and money. In this case, the simulation could be considered as a prediction method that verifies whether the configuration for the desired scenario works correctly and meets the system's requirements. This work presents a research about statistical prediction models for RFID systems' coverage in a specific scenario. In order to predict the RFID system coverage, the tag read count was measured in an indoor environment. In the chosen scenario, RFID technology is applied to smart cards. This research presents a model using Multiple Linear Regression and another approach using Artificial Neural Networks on the prediction of the read count. Results showed improvements on the prediction of area coverage, bringing advantages to RFID projects, such as less time and resources required to RFID systems deployment.},
keywords={neural nets;radiofrequency identification;regression analysis;smart cards;telecommunication computing;RFID systems deployment;area coverage prediction;artificial neural networks;indoor environment;multiple linear regression;radiofrequency identification;smart cards scenario;statistical prediction models;tag read count;Artificial neural networks;Directive antennas;Linear regression;Materials;Mathematical model;Predictive models;Radiofrequency identification;Artificial Neural Networks;RFID Environment Simulation;RFID Prediction Model},
doi={10.1109/PIMRC.2012.6362582},
ISSN={2166-9570},
month={Sept},}
@INPROCEEDINGS{6345434,
author={K. Stefferud and J. Kleissl and J. Schoene},
booktitle={2012 IEEE Power and Energy Society General Meeting},
title={Solar forecasting and variability analyses using sky camera cloud detection amp; motion vectors},
year={2012},
pages={1-6},
abstract={Prediction of cloud location greatly increases the accuracy of solar generation forecasts when used in conjunction with regional meteorological data and historic data. Novel granular forecast techniques reduce intra-hour and minute-by-minute solar forecasting error by 50% compared to persistence models [3]. Our work creates cloud shadow maps on the ground to forecast power production ramps geospatially tagged and circuit topographically located to individual sites and aggregately to all sites on a distribution feeder. These forecasting data may be used to (1) reduce the detrimental impact on distribution systems due to voltage fluctuation caused by high PV penetration and (2) optimize utility operational and planning practices in the presence of high generation variability due to the presence of PV.},
keywords={clouds;geophysical image processing;image motion analysis;object detection;optimisation;photovoltaic power systems;power distribution lines;power generation planning;solar power;weather forecasting;circuit topographically located power production ramps;cloud location prediction;detrimental impact reduction;distribution feeder;forecasting data;geospatially tagged power production ramps;granular forecast techniques;high PV penetration;high generation variability;historic data;intra-hour solar forecasting error reduction;minute-by-minute solar forecasting error reduction;motion vectors;photovoltaic power generation;power production ramps forecasting;regional meteorological data;sky camera cloud detection;solar generation forecasting;solar variability analysis;utility operational practices optimization;utility planning practices optimization;voltage fluctuation;Clouds;Fluctuations;Forecasting;Planning;Reactive power;Voltage control;Voltage fluctuations;photovoltaic;power distribution lines;power generation;renewable energy;solar},
doi={10.1109/PESGM.2012.6345434},
ISSN={1932-5517},
month={July},}
@INPROCEEDINGS{6308914,
author={B. Song and S. r. Shuai and W. r. Hou and J. Yang and Y. l. Hou},
booktitle={2012 International Conference on Computer Science and Information Processing (CSIP)},
title={CDNA, genomic sequence cloning and overexpression of ribosomal protein S9 gene (RPS9) from Ailuropoda},
year={2012},
pages={553-556},
abstract={Ribosomal protein S9 is a component of the 40S ribosomal submit, encoded by the RPS9 gene in eucaryotic cell. It belongs to the S4P family of ribosomal proteins. To explore the structure characteristic of RPS9 gene of giant panda (Ailuropoda melanoleuca), primers were designed according to the known nucleotide sequence of RPS9 genes to clone the cDNA and genomic sequences of RPS9 gene of A. melanoleuca by RT-PCR and PCR strategy respectively, followed by sequencing and analyzing preliminarily. The results indicated that the cDNA fragment of RPS9 from giant panda was 637 bp in size, containing an open reading frame (ORF) of 585 bp, encoding 194 amino acids. The length of the genomic sequence was 6,193 bp, with four exons and three introns. The coding sequence shows a high degree of homology to those of Homo sapiens, Bos taurus, Canis lupus, Mus musculus and Rattus norvegicus by 92.65, 91.11, 92.48, 88.03, and 87.01%, respectively. The homology for the deduced amino acid sequences reached high up to 99.48%. Primary structure analysis revealed that the molecular weight of the putative RPS9 protein was 22.60 kDa, with a theoretical pI of 11.31. Based on topology prediction, there were four distinct types of functional sites in RPS9 protein of giant panda. The RPS9 gene was overexpressed in E. coli, and the N-terminally His-tagged protein was a 28 kDa polypeptide, in good agreement with the predicted molecular weight. The protein obtained could be purified for studying its function further.},
keywords={DNA;RNA;biochemistry;cellular biophysics;enzymes;genetics;genomics;microorganisms;molecular biophysics;molecular configurations;molecular weight;40S ribosomal submit encoding;Ailuropoda melanoleuca;Bos taurus;Canis lupus;E. coli;Homo sapiens;Mus musculus;N-terminally His-tagged protein;Rattus norvegicus;amino acid sequences;cDNA fragment;eucaryotic cell;exons;genomic sequence cloning;genomic sequence overexpression;giant panda;homology;introns;molecular weight;open reading frame;polypeptide;primary structure analysis;putative RPS9 protein;real-time polymerase chain reaction;ribosomal protein S9 gene;structural characteristics;Bioinformatics;DNA;Genomics;Cloning;Giant panda;RPS9;RT-PCR;Sequences analysis;overexpression},
doi={10.1109/CSIP.2012.6308914},
month={Aug},}
@INPROCEEDINGS{6308907,
author={Lan He and J. Yang and Xiang Ding and Yi-Ling Hou and W. R. Hou},
booktitle={2012 International Conference on Computer Science and Information Processing (CSIP)},
title={CDNA and genomic sequence clonging and sequence analysis of ribosomal protein S5 gene(rpS5) from giant panda and its overexpression},
year={2012},
pages={526-528},
abstract={RPS5 is a component of the 40S small ribosomal subunit encoded by rpS5 gene, which is specific to eukaryotes. The cDNA and the genomic sequence of rpS5 were cloned successfully from giant panda using RT-PCR technology and Touchdown-PCR, respectively. Both sequences were analyzed preliminarily and the cDNA of the rpS5 gene was overexpressed in E. coli BL21. The cDNA of rpS5 cloned from giant panda contain open reading frame of 615 bp encoding 204 amino acids. The nucleotide sequence of the coding sequence shows a high homology to some mammals as determined by Blast analyzing, and the same with the amino acid sequence. The genomic sequence is 4331 bp in length, with five exons and four introns. Primary structure analysis revealed that the molecular weight of the putative RPS5 protein is 22.87 KD with a theoretical pI 10.30. Topology prediction showed there are five different patterns of functional sites in the RPS5 protein of giant panda. The rpS5 can be really expressed in E. coli and its protein fused with the N-terminally GST -tagged protein gave rise to the accumulation of an expected 29.5 KD polypeptide. The expression product obtained could be used for purification and study of its function further.},
keywords={DNA;biology computing;genetics;genomics;microorganisms;molecular biophysics;molecular configurations;molecular weight;proteins;Blast analyzing;CDNA;E. coli BL21;RT-PCR technology;amino acid sequence;coding sequence;eukaryotes;gene overexpression;genomic sequence;giant panda;molecular weight;nucleotide sequence;primary structure analysis;purification;ribosomal protein;rpS5 gene;sequence analysis;touchdown-PCR;Amino acids;Bioinformatics;Genomics;Ailuropoda melanoleuca;Genomic cloning;Overexpression;RPS5},
doi={10.1109/CSIP.2012.6308907},
month={Aug},}
@INPROCEEDINGS{6308903,
author={Y. Q. Chen and Y. L. Hou and Wu Chun-Lian and Ding Xiang and W. R. Hou},
booktitle={2012 International Conference on Computer Science and Information Processing (CSIP)},
title={Cloning and sequence analysis of ribosomal protein L23 gene from Ailuropoda melanoleuca},
year={2012},
pages={510-513},
abstract={Ribosonal protein L23 is a component of the 60s large ribosomal subunit, and plays an important role in ribosome. To explore the structure characteristic of RPL23 gene of giant panda and investigate its homologies with other species reported, the cDNA and genomic sequence of RPL23 gene were cloned using RT-PCR and touchdown-PCR technology. The sequence data were analyzed by corresponding software. The results showed the length of cDNA fragment cloned was 457bp; containing an open reading frame of 423 bp. Deduced protein was composed of 144 amino acids with an estimated molecular weight of 14.86kD and pI of 11.19. The length of the genomic sequence was 5011 bp, containing five exons and four introns. The predicted protein has six different patterns of functional sites. The RPL23 gene can be readily expressed in E. coli. When it was fused with the N-terminally His-tagged protein, it gave rise to accumulation of an expected 20.5 kD polypeptide, in good agreement with the predicted molecular weight. Alignment analysis indicated that RPL23 was highly similarity with the reported species at the level of DNA and protein. Topology prediction showed that three different patterns were found in the RPL23 protein of giant panda. In this paper, the results provided scientific material for enriching and improving the mammals RPL23 gene database.},
keywords={DNA;bioinformatics;biological techniques;cellular biophysics;genetics;genomics;microorganisms;molecular biophysics;proteins;topology;Ailuropoda Melanoleuca;E. coli;N-terminally His-tagged protein;RT-PCR technology;alignment analysis;amino acids;cDNA fragment cloning;cDNA sequence;cloning analysis;genomic sequence;giant panda;homology;mammals RPL23 gene database;polypeptide;ribosomal protein L23 gene;sequence analysis;sequence data;software;structural properties;topology prediction;touchdown-PCR technology;Bioinformatics;Cloning;Design automation;Genomics;Materials;Proteins;Giant panda;Over-expression;RPL23;Sequence analysis;cDNA cloning},
doi={10.1109/CSIP.2012.6308903},
month={Aug},}
@INPROCEEDINGS{6308905,
author={Geng Wen-Feng and Wu Chun-Lian and W. R. Hou and Ding Xiang and Y. L. Hou},
booktitle={2012 International Conference on Computer Science and Information Processing (CSIP)},
title={cDNA, genomic sequence cloning, analyzing of ribosomal protein L36A (RPL36A) and its over-expression from giant panda},
year={2012},
pages={518-521},
abstract={The aim of this study is to explore the structural characteristics of the ribosomal protein L36A (RPL36A) gene from giant panda and to investigate its similarities and differences with other species reported. The cDNA and genomic sequence of RPL36A gene were cloned using RT-PCR and touchdown-PCR technology. The results showed that the length of cDNA cloned was 342 bp containing an ORF of 321bp encoded 106 amino acids with an estimated protein molecular weight 12.44kD and a theoretical pI of 11.29. The genomic DNA fragment was 2227 bp containing four exons and three introns. Topology prediction showed that there were one cAMP- and cGMP-dependent protein kinase phosphorylation site, three protein kinase C phosphorylation site, one tyrosine kinase phosphorylation site, one amidation site, one ribosomal protein L44e signature in the RPL36A protein of giant panda. The RPL36A gene could be readily expressed in E. coli. When it was fused with the N-terminally His-tagged protein, it gave rise to accumulation of an expected 17.5kD polypeptide, in good agreement with the predicted molecular weight. The expression product obtained can be purified for studies of its function. Alignment analysis indicated that the nucleotide sequence and the deduced amino acid sequence shared a high homology with other four mammals. In this paper, the cDNA of RPL36A was cloned successfully for the first time from giant panda. The results provided scientific material for enriching and improving the mammals RPL36A gene database.},
keywords={DNA;biochemistry;biology computing;enzymes;genetics;genomics;microorganisms;molecular biophysics;molecular configurations;molecular weight;321bp encoded amino acids;E. coli;N-terminally His-tagged protein;RPL36A gene database;amidation site;amino acid sequence;cAMP-dependent protein kinase phosphorylation site;cDNA;cGMP-dependent protein kinase phosphorylation site;exons;genomic DNA fragment;genomic sequence cloning;giant panda;homology;introns;mammals;nucleotide sequence;polypeptide;protein kinase C phosphorylation site;protein molecular weight;real-time polymerase chain reaction;ribosomal protein L36A gene overexpression;ribosomal protein L44e signature;structural characteristics;topology prediction;touchdown-polymerase chain reaction technology;tyrosine kinase phosphorylation site;Bioinformatics;Biotechnology;DNA;Encoding;Erbium;Genomics;Giant panda;Over-expression;RPL36A;Sequence analysis;cDNA cloning},
doi={10.1109/CSIP.2012.6308905},
month={Aug},}
@INPROCEEDINGS{6289063,
author={Y. Shi and P. Wiggers and C. M. Jonker},
booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Dynamic Bayesian socio-situational setting classification},
year={2012},
pages={5081-5084},
abstract={We propose a dynamic Bayesian classifier for the socio-situational setting of a conversation. Knowledge of the socio-situational setting can be used to search for content recorded in a particular setting or to select context-dependent models in speech recognition. The dynamic Bayesian classifier has the advantage - compared to static classifiers such a naive Bayes and support vector machines - that it can continuously update the classification during a conversation. We experimented with several models that use lexical and part-of-speech information. Our results show that the prediction accuracy of the dynamic Bayesian classifier using the first 25% of a conversation is almost 98% of the final prediction accuracy, which is calculated on the entire conversation. The best final prediction accuracy, 88.85%, is obtained by bigram dynamic Bayesian classification using words and part-of-speech tags.},
keywords={Bayes methods;speech recognition;context-dependent models;dynamic Bayesian socio-situational setting classification;part-of-speech information;part-of-speech tags;speech recognition;support vector machines;Accuracy;Bayesian methods;Educational institutions;Face;Mathematical model;Niobium;Speech;Dynamic Bayesian networks;conversation classification;socio-situational setting},
doi={10.1109/ICASSP.2012.6289063},
ISSN={1520-6149},
month={March},}
@INPROCEEDINGS{6287820,
author={R. Foucard and S. Essid and M. Lagrange and G. Richard},
booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={A regressive boosting approach to automatic audio tagging based on soft annotator fusion},
year={2012},
pages={73-76},
abstract={Automatic tagging of music has mostly been treated as a classification problem. In this framework, the association of a tag to a song is characterized in a “hard” fashion: the tag is either relevant or not. Yet, the relevance of a tag to a song is not always evident. Indeed, during the ground-truth annotation process, several annotators may express doubts, or disagree with each other. In this paper, we propose to fuse annotators' decisions in a way to keep information about this uncertainty. This fusion provides us continuous scores, that are used for training a regressive boosting algorithm. Our experiments show that regression with this soft ground truth leads to a more accurate learning, and better predictions, compared to traditionally used binary classification.},
keywords={audio signal processing;information retrieval;learning (artificial intelligence);music;regression analysis;signal classification;automatic audio tagging;binary classification;ground-truth annotation process;machine learning;music automatic tagging;music information retrieval;regressive boosting approach;soft annotator fusion;Boosting;Databases;Mel frequency cepstral coefficient;Prediction algorithms;Tagging;Training;Uncertainty;Autotagging;Boosting;Machine learning;Music information retrieval;Regression analysis},
doi={10.1109/ICASSP.2012.6287820},
ISSN={1520-6149},
month={March},}
@INPROCEEDINGS{6288798,
author={A. Parlikar and A. W. Black},
booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
title={Data-driven phrasing for speech synthesis in low-resource languages},
year={2012},
pages={4013-4016},
abstract={We present an approach to build phrase break prediction models when synthesizing text in low resource languages. This method allows building models without depending on the availability of part of speech taggers, or corpus with hand annotated breaks. We use the same speech data used for building a synthetic voice, to deduce acoustic phrase breaks. We perform unsupervised part of speech induction over a small text corpus in the language at hand. We use these tags and train a grammar based phrasing model. In this paper, we show results for the languages: English, Portuguese and Marathi, which suggest that we can quickly build very reasonable phrasing models for new languages using very little data.},
keywords={speech synthesis;acoustic phrase break deduction;data-driven phrasing;grammar based phrasing model;hand annotated breaks;low-resource languages;phrase break prediction models;speech data;speech induction;speech synthesis;speech taggers;synthetic voice;text corpus;text synthesis;Data models;Educational institutions;Grammar;Histograms;Numerical models;Predictive models;Speech;Low Resource Languages;Phrase Break Prediction;Speech Synthesis},
doi={10.1109/ICASSP.2012.6288798},
ISSN={1520-6149},
month={March},}
@ARTICLE{6200260,
author={B. Liao and X. Li and W. Zhu and Z. Cao},
journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics},
title={A Novel Method to Select Informative SNPs and Their Application in Genetic Association Studies},
year={2012},
volume={9},
number={5},
pages={1529-1534},
abstract={The association studies between complex diseases and single nucleotide polymorphisms (SNPs) or haplotypes have recently received great attention. However, these studies are limited by the cost of genotyping all SNPs. Therefore, it is essential to find a small subset of tag SNPs representing the rest of the SNPs. The presence of linkage disequilibrium between tag SNPs and the disease variant (genotyped or not), may allow fine mapping study. In this paper, we combine a nearest-means classifier (NMC) and ant colony algorithm to select tags. Results show that our method (ACO/NMC) can get a similar prediction accuracy with method BPSO/SVM and is better than BPSO/STAMPA for small data sets. For large data sets, although the prediction accuracy of our method is lower than BPSO/SVM, ACO/ NMC can reach a high accuracy (>;99 percent) in a relatively short time. when the number of tags increases, the time complexity of NMC is nearly linear growth. To find out that the ability of tags to locate disease locus, we simulate a case-control study and use two-locus haplotype analysis to quantitatively assess the power. The result showed that 20 percent of all SNPs selected by NMC have about 10 percent higher power than random tags, on average.},
keywords={biology computing;diseases;genetics;molecular biophysics;pattern classification;polymorphism;support vector machines;BPSO-STAMPA;BPSO-SVM;ant colony algorithm;case-control study;complex diseases;genetic association;genotyped disease variant;linkage disequilibrium;nearest-means classifier;single nucleotide polymorphisms;two-locus haplotype analysis;Accuracy;Bioinformatics;Diseases;Genomics;Prediction algorithms;Support vector machines;Haplotypes;informative SNP;single nucleotide polymorphism;tag selection.;Algorithms;Genetic Association Studies;Linkage Disequilibrium;Polymorphism, Single Nucleotide;Support Vector Machines},
doi={10.1109/TCBB.2012.70},
ISSN={1545-5963},
month={Sept},}
@INPROCEEDINGS{6234277,
author={J. Jin and Q. Chen},
booktitle={2012 9th International Conference on Fuzzy Systems and Knowledge Discovery},
title={A trust-based Top-K recommender system using social tagging network},
year={2012},
pages={1270-1274},
abstract={With the expansion of e-commerce, recommender systems are drawing more and more attentions. Collaborative Filtering(CF) is the most popular algorithm used for recommendation, but it performs not very well for sparse data and new users. The emergence of trust-based recommender system has solved the problem of CF in a better way. A system of this kind is commonly constructed based upon social network with trust relations. It contains not only user-item rating relations, but also friendships between users, and the friendships are very meaningful in recommendation. However, the trust values in the networks are all specified by users, which are subjective processes. In this paper, we propose a Top-K recommender system on social tagging network, and design a user-item rating matrix construction method on user browsed or searched information. We use tags, which can be regarded as users and items feature information, to compute the similarity between users or items. Moreover, we propose a Top-K recommender system construction method on the network with trust values computed from users' interest similarity. In our experiments we use the Last fm dataset, and we employ the RMSE and hit-radios benchmarks to evaluate the quality and performance of prediction on single item and Top-K recommendation. We compare our approach with two traditional CF algorithms. The experimental results show that our system has good performance, and it solves the defects of CF and existing Trust-based recommender systems.},
keywords={collaborative filtering;electronic commerce;matrix algebra;recommender systems;security of data;social networking (online);CF algorithms;Last fm dataset;RMSE;collaborative filtering;e-commerce;hit-radios benchmarks;items feature information;social tagging network;trust values;trust-based top-k recommender system construction method;user interest similarity;user-item rating matrix construction method;user-item rating relations;Java;Vectors},
doi={10.1109/FSKD.2012.6234277},
month={May},}
@INPROCEEDINGS{6228115,
author={L. Dickens and I. Molloy and J. Lobo and P. C. Cheng and A. Russo},
booktitle={2012 IEEE 28th International Conference on Data Engineering},
title={Learning Stochastic Models of Information Flow},
year={2012},
pages={570-581},
abstract={An understanding of information flow has many applications, including for maximizing marketing impact on social media, limiting malware propagation, and managing undesired disclosure of sensitive information. This paper presents scalable methods for both learning models of information flow in networks from data, based on the Independent Cascade Model, and predicting probabilities of unseen flow from these models. Our approach is based on a principled probabilistic construction and results compare favourably with existing methods in terms of accuracy of prediction and scalable evaluation, with the addition that we are able to evaluate a broader range of queries than previously shown, including probability of joint and/or conditional flow, as well as reflecting model uncertainty. Exact evaluation of flow probabilities is exponential in the number of edges and naive sampling can also be expensive, so we propose sampling in an efficient Markov-Chain Monte-Carlo fashion using the Metropolis-Hastings algorithm -- details described in the paper. We identify two types of data, those where the paths of past flows are known -- attributed data, and those where only the endpoints are known -- unattributed data. Both data types are addressed in this paper, including training methods, example real world data sets, and experimental evaluation. In particular, we investigate flow data from the Twitter microblogging service, exploring the flow of messages through retweets (tweet forwards) for the attributed case, and the propagation of hash tags (metadata tags) and urls for the unattributed case.},
keywords={Markov processes;Monte Carlo methods;data flow analysis;directed graphs;learning (artificial intelligence);meta data;probability;sampling methods;security of data;social networking (online);Markov-Chain Monte-Carlo methoc;Metropolis-Hastings algorithm;Twitter microblogging service;URL;conditional flow probability;data type identification;directed graph;hash tag propagation;independent cascade model;information flow;joint flow probability;malware propagation;marketing impact maximization;message flow;metadata tags;model uncertainty;naive sampling;principled probabilistic construction;retweet;sensitive information undesired disclosure management;social media;stochastic model learning;tweet forward;unattributed data;unseen flow probability;Accuracy;Data models;Equations;Joints;Predictive models;Twitter;Uncertainty},
doi={10.1109/ICDE.2012.103},
ISSN={1063-6382},
month={April},}
@ARTICLE{6061960,
author={M. M. Ahmed and M. A. Abdel-Aty},
journal={IEEE Transactions on Intelligent Transportation Systems},
title={The Viability of Using Automatic Vehicle Identification Data for Real-Time Crash Prediction},
year={2012},
volume={13},
number={2},
pages={459-468},
abstract={Real-time crash prediction research attempted the use of data from inductive loop detectors; however, no safety analysis has been carried out using traffic data from one of the most growing nonintrusive surveillance systems, i.e., the tag readers on toll roads known as automatic vehicle identification (AVI) systems. In this paper, for the first time, the identification of freeway locations with high crash potential has been examined using real-time speed data collected from AVI. Travel time and space mean speed data collected by AVI systems and crash data of a total of 78 mi on the expressway network in Orlando in 2008 were collected. Utilizing a random forest technique for significant variable selection and stratified matched case-control to account for the confounding effects of location, time, and season, the log odds of crash occurrence were calculated. The length of the AVI segment was found to be a crucial factor that affects the usefulness of the AVI traffic data. While the results showed that the likelihood of a crash is statistically related to speed data obtained from AVI segments within an average length of 1.5 mi and crashes can be classified with about 70% accuracy, all speed parameters obtained from AVI systems spaced at 3 mi or more apart were found to be statistically insignificant to identify crash-prone conditions. The findings of this study illustrate a promising real-time safety application for one of the most widely used and already present intelligent transportation systems, with many possible advances in the context of advanced traffic management.},
keywords={automated highways;road safety;surveillance;advanced traffic management;automatic vehicle identification data;automatic vehicle identification systems;expressway network;freeway locations;high crash potential;inductive loop detectors;intelligent transportation systems;nonintrusive surveillance systems;random forest technique;real-time crash prediction;real-time safety application;safety analysis;traffic data;Computer crashes;Detectors;Radio frequency;Real time systems;Traffic control;Vehicle crash testing;Vehicles;Automatic vehicle identification (AVI);freeway/expressway;intelligent transportation system (ITS);safety risk},
doi={10.1109/TITS.2011.2171052},
ISSN={1524-9050},
month={June},}
@INPROCEEDINGS{6196948,
author={S. Sriram and Xiaobu Yuan},
booktitle={2012 Proceedings of IEEE Southeastcon},
title={An enhanced approach for classifying emotions using customized decision tree algorithm},
year={2012},
pages={1-6},
abstract={This investigation reports the improved method for the text based emotion classification and prediction using a customized decision tree algorithm. Machine learning techniques such as Decision tree algorithm are widely used in research fields of bioinformatics, data mining, capturing knowledge in expert systems and so on. The emotions can be deducted from the online chat conversation and tagged. In this proposed work, the given dataset is classified using customized decision tree with respect to the two known classes of data. The main motivation behind this customized approach is to provide a simple, effective, less complex and memory optimized prediction model in deducing the classes of the given dataset. The effectiveness of the approach is then obtained by comparing it with the existing methodologies.},
keywords={decision trees;emotion recognition;text detection;bioinformatics;customized decision tree algorithm;data mining;expert systems;machine learning techniques;memory optimized prediction model;online chat conversation;text based emotion classification;text based emotion prediction;Accuracy;Classification algorithms;Decision trees;Machine learning;Prediction algorithms;Speech recognition;Training;Classification;Emotions;customized approach;decision tree;predictive model},
doi={10.1109/SECon.2012.6196948},
ISSN={1091-0050},
month={March},}
@INPROCEEDINGS{6184882,
author={L. Y. Chuang and W. L. Huang and C. H. Yang},
booktitle={2012 IEEE 26th International Conference on Advanced Information Networking and Applications},
title={Chaos Embedded Particle Swarm Optimization for Tag Single Nucleotide Polymorphism Selection},
year={2012},
pages={283-288},
abstract={Single Nucleotide Polymorphisms (SNPs) are the most common variants in the human genome. Disease analysis costs can be reduced by selecting meaningful SNPs, i.e., tagging the SNP selection. We propose a method, called chaos particle swarm optimization (CPSO), to select tag SNPs, and use linkage disequilibrium (LD) and the K-nearest neighbor (K-NN) method to respectively reduce and evaluate the tag SNPs. To measure the quality of the correction rate and the tag SNPs number, the Hap Map database was used to test CPSO's ability and to compare the proposed method with other methods. The results indicate that the proposed method is effectively to enhance the tag SNP prediction in terms of the result achieves a good accuracy when compared to methods from the literature.},
keywords={chaos;database management systems;diseases;genomics;learning (artificial intelligence);medical computing;particle swarm optimisation;pattern classification;Hap Map database;K-nearest neighbor method;SNP selection;chaos embedded particle swarm optimization;correction rate;disease analysis;human genome;linkage disequilibrium;tag single nucleotide polymorphism selection;Accuracy;Bioinformatics;Chaos;Couplings;Genomics;Particle swarm optimization;Support vector machines;Chaos;Linkage Disequilibrium;Particle Swarm Optimization;Single Nucleotide Polymorphism},
doi={10.1109/AINA.2012.123},
ISSN={1550-445X},
month={March},}
@ARTICLE{6171055,
author={H. Park and S. Yoo and S. Lee},
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
title={A Multistep Tag Comparison Method for a Low-Power L2 Cache},
year={2012},
volume={31},
number={4},
pages={559-572},
abstract={Tag comparison in a highly associative cache consumes a significant portion of the cache energy. Existing methods for tag comparison reduction are based on predicting either cache hits or cache misses. In this paper, we present novel ideas for both cache hit and miss predictions. We present a partial tag-enhanced Bloom filter to improve the accuracy of the cache miss prediction method and hot/cold checks that control data liveness to reduce the tag comparisons of the cache hit prediction method. We also combine both methods so that their order of application can be dynamically adjusted to adapt to changing cache access behavior, which further reduces tag comparisons. To overcome the common limitation of multistep tag comparison methods, we propose a method that reduces tag comparisons while meeting the given performance bound. Experimental results showed that the proposed method reduces the energy consumption of tag comparison by an average of 88.40%, which translates to an average reduction of 35.34% (40.19% with low-power data access) in the total energy consumption of the L2 cache and a further reduction of 8.86% (10.07% with low-power data access) when compared with existing methods.},
keywords={cache storage;digital filters;low-power electronics;cache hit;cache miss prediction method;highly associative cache;low-power L2 cache;multistep tag comparison method;tag-enhanced Bloom filter;Accuracy;Energy consumption;Power demand;Prediction methods;Radiation detectors;Runtime;Vectors;Bloom filter (BF);cache;power consumption;tag comparison;way prediction},
doi={10.1109/TCAD.2011.2177458},
ISSN={0278-0070},
month={April},}
@INPROCEEDINGS{6161972,
author={Hyeong-Joon Kwon and Kwang-Seok Hong},
booktitle={2012 IEEE International Conference on Consumer Electronics (ICCE)},
title={Personalized real-time location-tagged contents recommender system based on mobile social networks},
year={2012},
pages={558-559},
abstract={This paper proposes a real-time location-tagged contents recommender system which is based on mobile social network. The system locates a user via global positioning system, and then applies distance and preference filtering methods. We confirmed that the system is highly effective and applicable to convergence by a location data and content recommender through an implementation and preference prediction experiments.},
keywords={Global Positioning System;information filtering;mobile computing;real-time systems;recommender systems;social networking (online);distance filtering methods;global positioning system;location data convergence;mobile social networks;personalized real-time location-tagged contents recommender system;preference filtering methods;Mobile communication;Mobile computing;Real time systems;Recommender systems;Smart phones;Social network services},
doi={10.1109/ICCE.2012.6161972},
ISSN={2158-3994},
month={Jan},}
@INPROCEEDINGS{6151510,
author={M. M. Uddin and M. T. Hassan and A. Karim},
booktitle={2011 IEEE 14th International Multitopic Conference},
title={Personalized versus non-personalized tag recommendation: A suitability study on three social networks},
year={2011},
pages={56-61},
abstract={Tag recommendation systems are either personalized or non-personalized. Personalized tag recommendation utilizes a user's tagging behavior from her tagging history for predictions. Whereas non-personalized recommendation systems recommend what is popular and relevant to the user. In this study, we have analyzed the role of personal tagging history in recommending tags. The experiments are done on three folksonomy datasets: Delicious, Flickr and Bibsonomy. Important results for three popular tag recommendation algorithms: PITF, FolkRank and Adapted PageRank are reported in terms of prediction quality. It is found that users' history usage preferences change across all data sets; hence overall prediction quality of personalized recommendation system may suffer. We discover a generic life cycle of folksonomy users on the basis of their history usage. We propose this life cycle can be used to improve an overall prediction performance of a recommendation system across all folksonomies.},
keywords={recommender systems;social networking (online);user interfaces;Adapted PageRank algorithm;Bibsonomy dataset;Delicious dataset;Flickr dataset;FolkRank algorithm;PITF algorithm;history usage;nonpersonalized tag recommendation;personalized tag recommendation;social networks;tag recommendation system;usage preference;user tagging behavior;Adaptation models;Lead;Prediction algorithms;Folksonomy;Personalization;Tag Recommendation},
doi={10.1109/INMIC.2011.6151510},
month={Dec},}
@INPROCEEDINGS{6113114,
author={M. D. Conover and B. Goncalves and J. Ratkiewicz and A. Flammini and F. Menczer},
booktitle={2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third International Conference on Social Computing},
title={Predicting the Political Alignment of Twitter Users},
year={2011},
pages={192-199},
abstract={The widespread adoption of social media for political communication creates unprecedented opportunities to monitor the opinions of large numbers of politically active individuals in real time. However, without a way to distinguish between users of opposing political alignments, conflicting signals at the individual level may, in the aggregate, obscure partisan differences in opinion that are important to political strategy. In this article we describe several methods for predicting the political alignment of Twitter users based on the content and structure of their political communication in the run-up to the 2010 U.S. midterm elections. Using a data set of 1,000 manually-annotated individuals, we find that a support vector machine (SVM) trained on hash tag metadata outperforms an SVM trained on the full text of users' tweets, yielding predictions of political affiliations with 91% accuracy. Applying latent semantic analysis to the content of users' tweets we identify hidden structure in the data strongly associated with political affiliation, but do not find that topic detection improves prediction performance. All of these content-based methods are outperformed by a classifier based on the segregated community structure of political information diffusion networks (95% accuracy). We conclude with a practical application of this machinery to web-based political advertising, and outline several approaches to public opinion monitoring based on the techniques developed herein.},
keywords={Internet;politics;social networking (online);support vector machines;Twitter users;Web-based political advertising;content-based method;hash tag metadata;latent semantic analysis;opinions monitoring;political affiliation;political alignment prediction;political communication;political information diffusion network;political strategy;public opinion monitoring;social media;support vector machine training;yielding prediction;Accuracy;Data mining;Real time systems;Semantics;Support vector machines;Twitter;Vectors;data mining;machine leaning;networks;polarization;political science;social media;text mining;twitter},
doi={10.1109/PASSAT/SocialCom.2011.34},
month={Oct},}
@INPROCEEDINGS{6111034,
author={O. N. Osmanli and İ. H. Toroslu},
booktitle={2011 5th International Conference on Application of Information and Communication Technologies (AICT)},
title={Using tag similarity in SVD-based recommendation systems},
year={2011},
pages={1-4},
abstract={Data analysis has become a very important area for both companies and researchers as a consequence of the technological developments in recent years. Companies are trying to increase their profit by analyzing the existing data about their customers and making decisions for the future according to the results of these analyses. Parallel to the need of companies, researchers are investigating different methodologies to analyze data more accurately with high performance. In this paper, we adopted free-formatted text-based tags into traditional 2-Dimensional SVD approach. We analysed the effect of different tag similarity techniques to the 3-Dimensional SVD recommendation performance. Our experiments illustrated that, tags increase the performance to some extent. The more similar tags means, the more accurate predictions.},
keywords={data analysis;decision making;identification technology;pattern matching;recommender systems;singular value decomposition;text analysis;2-dimensional SVD approach;3-dimensional SVD recommendation performance;data analysis;decision making;free-formatted text-based tag;tag similarity technique;technological development;Java;Linear approximation;Matrix decomposition;Motion pictures;Ontologies;Recommender systems;Singular value decomposition;Recommendation Systems;Singular Value Decomposition;Tag Similarity},
doi={10.1109/ICAICT.2011.6111034},
month={Oct},}
@INPROCEEDINGS{6106495,
author={Yang Zhao and Yong Zhang and Chunxiao Xing and Yang Ding and Shuang Xia and S. Roepnack and Shihong Huang and Yigang Sun and Xianzhong Zhu},
booktitle={2011 6th International Conference on Pervasive Computing and Applications},
title={IBeST: An algorithmic framework for extending item-based collaborative filtering with social tags},
year={2011},
pages={153-159},
abstract={Collaborative filtering technology is one major method used in recommendation systems. Most existing collaborative filtering algorithms merely use rating data as their prediction input. Social tags have become widely used in web applications which not only reflect the user's personality but also item's properties and semantic meanings. We design an algorithmic framework by extending item-based collaborative filtering with social tags which we call IBeST. IBeST contains the whole lifecycle of the item similarity measurement based on social tags and improves item-based algorithmic results in four phases: dataset preprocessing, metadata injection, algorithm selection and optimization, and similarity weight selection. The calculated similarity is then used in item-based algorithm. MovieLens 10M ratings 100k tags dataset is used in our experiment. IBeST generates improved recommendation ratings than baseline item-based algorithms, and provides a feasible and loosely coupled solution to use social tags in item-based recommendation system.},
keywords={collaborative filtering;meta data;optimisation;recommender systems;semantic Web;social networking (online);IBeST;MovieLens rating;Web application;algorithm selection;algorithmic framework;dataset preprocessing;item based collaborative filtering technology;item based recommendation system;item similarity measurement;metadata injection;optimization;prediction input;rating data;semantic meanings;similarity weight selection;social tags;tag dataset;user personality;Filtering algorithms;Optimization;Prediction algorithms;Algorithmic Framework;Collaborative Filtering;Item-Based Algorithm;Recommender Systems;Social Tags},
doi={10.1109/ICPCA.2011.6106495},
month={Oct},}
@ARTICLE{6068263,
author={A. Vena and E. Perret and S. Tedjini},
journal={IEEE Transactions on Microwave Theory and Techniques},
title={Chipless RFID Tag Using Hybrid Coding Technique},
year={2011},
volume={59},
number={12},
pages={3356-3364},
abstract={Increasing the coding capacity of chipless RFID tags is a key factor while considering the development of miniaturized tags. A novel hybrid coding technique by combining phase deviation and frequency position encoding is proposed here. A coding capacity of 22.9 bits is obtained simply with five resonators within a reduced dimension of 2 cm × 4 cm. The proposed tag is based on 5 `C' like metallic strip resonators having resonance frequency within the band of 2.5 GHz to 7.5 GHz. The tag is potentially low-cost since only one conductive layer is needed for the fabrication. Different tag configurations are designed and validated with measurement results in bi-static configuration. A good agreement between measurement and simulation validates the theoretical predictions.},
keywords={radiofrequency identification;strip line resonators;chipless RFID tag;coding capacity;conductive layer;frequency 2.5 GHz to 7.5 GHz;frequency position encoding;hybrid coding technique;metallic strip resonator;phase deviation;Bandwidth;Constellation diagram;Encoding;RFID tags;Radiofrequency identification;Resonant frequency;“C” resonator;RFID;chipless RFID;frequency encoding;hybrid encoding;phase encoding},
doi={10.1109/TMTT.2011.2171001},
ISSN={0018-9480},
month={Dec},}
@INPROCEEDINGS{6068608,
author={I. Uysal and J. P. Emond and G. Bennett},
booktitle={2011 IEEE International Conference on RFID-Technologies and Applications},
title={Tag testing methodology for RFID enabled temperature tracking and shelf life estimation},
year={2011},
pages={8-15},
abstract={Recent advances in sensory devices using radio frequency identification (RFID) led to applications such as monitoring the temperature during the transportation of heat sensitive products where recorded data can be used to detect refrigeration equipment failure along the supply chain or estimate remaining shelf life of the product. For the project discussed in this paper, a handheld based portable RFID system is used to track the storage and transportation temperatures of perishable products using battery assisted passive temperature tags. The information from the tags is used in shelf life prediction models to estimate the remaining shelf life based on the recorded temperature data to provide a dynamic expiration date. Instead of the full application development effort, this paper focuses on the unique project requirements and challenges which led to the introduction of three novel concepts related to RFID enabled temperature tracking systems. First, due to absence of a common standard for testing RFID temperature tags, we develop a requirement driven, comprehensive testing protocol combining statistical tools and common industry standards with the help of a uniquely designed test setup to realistically simulate and evaluate the real life performances of different temperature tags. Next, a novel context based accuracy metric is derived for objective and application (such as shelf life prediction) specific comparison of different technologies. Finally, a pallet temperature estimation algorithm is developed to overcome some of the physical difficulties encountered in reading ultra-high frequency tags near the presence of metals and liquids.},
keywords={protocols;radiofrequency identification;temperature measurement;RFID enabled temperature tracking;RFID temperature tags;handheld based portable RFID system;heat sensitive products;radio frequency identification;shelf life estimation;statistical tools;tag testing methodology;temperature estimation algorithm;testing protocol;Accuracy;Radiofrequency identification;Schedules;Temperature distribution;Temperature sensors;Testing;Vibrations},
doi={10.1109/RFID-TA.2011.6068608},
month={Sept},}
@INPROCEEDINGS{6068623,
author={K. D'hoe and T. Hamelinckx and J. P. Goemaere and N. Stevens and L. De Strycker and B. Nauwelaers},
booktitle={2011 IEEE International Conference on RFID-Technologies and Applications},
title={Design and reliability evaluation of passive HF RFID systems in metal environments},
year={2011},
pages={103-108},
abstract={In spite of the popularity of passive Radio Frequency Identification (RFID) systems, reliability is an important topic to achieve the adoption of this technology in certain areas of applications. Maintaining this reliability is especially challenging in applications where metals are ubiquitous. This article describes how a passive HF RFID system is optimized for implementation within a closed metal case. The ideal orientation of a transponder within a metal environment is determined. Various simulations were executed in order to predict the areas where the magnetic field exceeded the activation field of the tags. The findings, resulting from these simulations, are verified by hardware measurements which show high prediction accuracy for the practical test setup. In this paper we optimized the reliability of RFID systems by adjusting the radius of a circular loop antenna to the metal construction. In future work, the simulation and measurement tools presented here will be used to evaluate and, eventually automatically generate, optimal antennas with other (non-circular) shapes for different environments.},
keywords={loop antennas;radiofrequency identification;telecommunication network reliability;circular loop antenna;metal environments;passive HF RFID systems;passive radio frequency identification systems;reliability evaluation;Antenna measurements;Antennas;Metals;Q factor;Radiofrequency identification;Reliability;Transponders},
doi={10.1109/RFID-TA.2011.6068623},
month={Sept},}
@INPROCEEDINGS{6061505,
author={A. C. Fang and H. Bunt and J. Cao and X. Liu},
booktitle={2011 IEEE Fifth International Conference on Semantic Computing},
title={Relating the Semantics of Dialogue Acts to Linguistic Properties: A Machine Learning Perspective through Lexical Cues},
year={2011},
pages={490-497},
abstract={This paper describes a corpus-based investigation of dialogue acts. In particular, it attempts to answer questions about the empirical distribution of dialogue acts and to what extent dialogue acts can be automatically predicted from their lexical features. The Switchboard Dialogue Act Corpus is adopted and the SWBD-DAMSL tags used for automatic prediction. We show that 60-70% of the dialogue acts can be predicted from lexical features alone depending on different levels of granularity. We also present a mapping from SWBD-DAMSL tags to the tags of the new ISO standard for dialogue act annotation, as part of an ongoing investigation into the relationship between the structure and granularity of the tag set and classification accuracy. The paper concludes with discussions and suggestions for future work.},
keywords={ISO standards;computational linguistics;interactive systems;learning (artificial intelligence);pattern classification;ISO standard;SWBD-DAMSL tags;automatic prediction;classification accuracy;corpus-based investigation;dialogue act annotation;dialogue acts;granularity;lexical cues;lexical features;linguistic property;machine learning perspective;semantics;switchboard dialogue act corpus;tag set;Accuracy;Educational institutions;ISO;ISO standards;Pragmatics;Semantics;Switches;ISO dialogue annotation standard;SWBD-DAMSL;Switchboard corpus;automatic classification;dialogue act},
doi={10.1109/ICSC.2011.32},
month={Sept},}
@INPROCEEDINGS{6041330,
author={H. Sadeghi and H. Sarbazi-Azad and H. R. Zarandi},
booktitle={2009 17th IFIP International Conference on Very Large Scale Integration (VLSI-SoC)},
title={Power-aware branch target prediction using a new BTB architecture},
year={2009},
pages={53-58},
abstract={This paper presents two effective methods to reduce power consumption of branch target buffer (BTB): 1) the first method is based on storing distance to next branch address in tag array instead of storing whole branch address, 2) the second method is to use a new field in data array of BTB namely Next Branch Distance (NBD) which holds distance of next branch address from current branch address. When a new hit is performed in BTB, based on NBD field, there would be no access through NBD number of instructions, so BTB can be shutdown not to consume power. The new architecture does not impose extra delay and reduction in prediction accuracy. Both methods were implemented and simulated using SimpleScalar and Wattch performance and power tools. The simulation experiment results show that the first method decreases power about 3% and the second method decreases power consumption of BTB up to 7.3%. Moreover, combining these two methods would reduce power consumption of BTB up to 8.3% without affecting performance of the processor.},
keywords={computer architecture;performance evaluation;power aware computing;BTB architecture;SimpleScalar;Wattch;branch address;branch target buffer;data array;next branch distance;power aware branch target prediction;power consumption reduction;tag array;Adders;Art;Banking;Benchmark testing;Delay;Energy consumption;Power demand;branch prediction;branch target buffer;performance analysis;power analysis;power consumption},
doi={10.1109/VLSISOC.2009.6041330},
ISSN={2324-8432},
month={Oct},}
