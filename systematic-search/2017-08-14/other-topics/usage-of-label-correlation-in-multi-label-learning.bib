% Encoding: UTF-8

@InProceedings{kang_etal_2006,
  author    = {Kang, Feng and Jin, Rong and Sukthankar, Rahul},
  title     = {Correlated Label Propagation with Application to Multi-label Learning},
  booktitle = {Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2},
  year      = {2006},
  series    = {CVPR '06},
  pages     = {1719--1726},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  acmid     = {1153652},
  doi       = {10.1109/CVPR.2006.90},
  isbn      = {0-7695-2597-0},
  numpages  = {8},
  url       = {http://dx.doi.org/10.1109/CVPR.2006.90},
}

@InBook{guo_schuurmans_2012,
  pages     = {355--370},
  title     = {Semi-supervised Multi-label Classification},
  publisher = {Springer Berlin Heidelberg},
  year      = {2012},
  author    = {Guo, Yuhong and Schuurmans, Dale},
  editor    = {Flach, Peter A. and De Bie, Tijl and Cristianini, Nello},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-33486-3},
  abstract  = {Labeled data is often sparse in common learning scenarios, either because it is too time consuming or too expensive to obtain, while unlabeled data is almost always plentiful. This asymmetry is exacerbated in multi-label learning, where the labeling process is more complex than in the single label case. Although it is important to consider semi-supervised methods for multi-label learning, as it is in other learning scenarios, surprisingly, few proposals have been investigated for this particular problem. In this paper, we present a new semi-supervised multi-label learning method that combines large-margin multi-label classification with unsupervised subspace learning. We propose an algorithm that learns a subspace representation of the labeled and unlabeled inputs, while simultaneously training a supervised large-margin multi-label classifier on the labeled portion. Although joint training of these two interacting components might appear intractable, we exploit recent developments in induced matrix norm optimization to show that these two problems can be solved jointly, globally and efficiently. In particular, we develop an efficient training procedure based on subgradient search and a simple coordinate descent strategy. An experimental evaluation demonstrates that semi-supervised subspace learning can improve the performance of corresponding supervised multi-label learning methods.},
  booktitle = {Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2012, Bristol, UK, September 24-28, 2012. Proceedings, Part II},
  doi       = {10.1007/978-3-642-33486-3_23},
  url       = {https://doi.org/10.1007/978-3-642-33486-3_23},
}

@Article{chen_etal_2008,
  author = {Gang Chen and Yangqiu Song and Fei Wang and Changshui Zhang},
  title  = {Semi-supervised Multi-label Learning by Solving a Sylvester Equation},
  year   = {2008},
  url    = {https://pdfs.semanticscholar.org/955d/807225cc9cd2646efa9f23df77f17f4abfab.pdf},
}

@InBook{godbole_sarawagi_2004,
  pages     = {22--30},
  title     = {Discriminative Methods for Multi-labeled Classification},
  publisher = {Springer Berlin Heidelberg},
  year      = {2004},
  author    = {Godbole, Shantanu and Sarawagi, Sunita},
  editor    = {Dai, Honghua and Srikant, Ramakrishnan and Zhang, Chengqi},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-24775-3},
  abstract  = {In this paper we present methods of enhancing existing discriminative classifiers for multi-labeled predictions. Discriminative methods like support vector machines perform very well for uni-labeled text classification tasks. Multi-labeled classification is a harder task subject to relatively less attention. In the multi-labeled setting, classes are often related to each other or part of a is-a hierarchy. We present a new technique for combining text features and features indicating relationships between classes, which can be used with any discriminative algorithm. We also present two enhancements to the margin of SVMs for building better models in the presence of overlapping classes. We present results of experiments on real world text benchmark datasets. Our new methods beat accuracy of existing methods with statistically significant improvements.},
  booktitle = {Advances in Knowledge Discovery and Data Mining: 8th Pacific-Asia Conference, PAKDD 2004, Sydney, Australia, May 26-28, 2004. Proceedings},
  doi       = {10.1007/978-3-540-24775-3_5},
  url       = {https://doi.org/10.1007/978-3-540-24775-3_5},
}

@Comment{jabref-meta: databaseType:bibtex;}
