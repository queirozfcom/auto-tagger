{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import nltk\n",
    "import sklearn\n",
    "import random\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA, RandomizedPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reuters 21-578 modApte version\n",
    "> a collection of 10,788 documents from the Reuters financial newswire service, partitioned into a training set with 7769 documents and a test set with 3019 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/felipe/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/felipe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters')\n",
    "nltk.download('punkt') # needed for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipFilePathPointer(u'/home/felipe/nltk_data/corpora/reuters.zip', u'reuters/')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = nltk.corpus.reuters\n",
    "dataset.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataset.readme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10788"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training/4679'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileids = dataset.fileids()\n",
    "sample_fileid = [ fileids[i] for i in sorted(random.sample(xrange(len(fileids)), 1)) ][0]\n",
    "sample_fileid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipFilePathPointer(u'/home/felipe/nltk_data/corpora/reuters.zip', u'reuters/training/4679')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.abspath(sample_fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.words(sample_fileid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'CHINA', u'TRYING', u'TO', u'INCREASE', u'COTTON', ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.words(sample_fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"CHINA TRYING TO INCREASE COTTON OUTPUT, PAPER SAYS\\n  China's 1987 cotton output must rise\\n  above the 1986 level of 3.54 mln tonnes or supply will fall\\n  short of increasing demand, the China Daily said.\\n      Demand in 1986 rose 10.9 pct over 1985.\\n      Output in 1986 fell from 4.15 mln tonnes in 1985 and a\\n  record 6.2 mln in 1984, official figures show. The China Daily\\n  attributed the decline to several factors, including less\\n  favorable weather conditions and new state measures to restrict\\n  cotton production after the 1984 build-up of stocks.\\n      According to Customs figures, cotton exports rose to\\n  558,089 tonnes in calendar 1986 from 347,026 in 1985.\\n      To increase output quickly, the state will raise by 10 pct\\n  the price it pays for cotton produced above and beyond quota\\n  levels, the newspaper said. Its official purchasing agencies\\n  will buy cotton produced in excess of that originally\\n  contracted for, it added.\\n      The China Daily said all cotton growing areas in south\\n  China should be maintained, and growing in the north should be\\n  concentrated in Hebei, Shandong, Henan and Xinjiang.\\n      It called for comprehensive planning to coordinate\\n  production of cotton with that of grain, edible oil and other\\n  crops, but gave no more details.\\n  \\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.raw(sample_fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'CHINA', u'TRYING', u'TO', u'INCREASE', u'COTTON', ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.words(sample_fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'CHINA', u'TRYING', u'TO', u'INCREASE', u'COTTON', u'OUTPUT', u',', u'PAPER', u'SAYS', u'China', u\"'\", u's', u'1987', u'cotton', u'output', u'must', u'rise', u'above', u'the', u'1986', u'level', u'of', u'3', u'.', u'54', u'mln', u'tonnes', u'or', u'supply', u'will', u'fall', u'short', u'of', u'increasing', u'demand', u',', u'the', u'China', u'Daily', u'said', u'.'], [u'Demand', u'in', u'1986', u'rose', u'10', u'.', u'9', u'pct', u'over', u'1985', u'.'], ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sents(sample_fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'CHINA', u'TRYING', u'TO', u'INCREASE', u'COTTON', u'OUTPUT', u',', u'PAPER', u'SAYS', u'China', u\"'\", u's', u'1987', u'cotton', u'output', u'must', u'rise', u'above', u'the', u'1986', u'level', u'of', u'3', u'.', u'54', u'mln', u'tonnes', u'or', u'supply', u'will', u'fall', u'short', u'of', u'increasing', u'demand', u',', u'the', u'China', u'Daily', u'said', u'.'], [u'Demand', u'in', u'1986', u'rose', u'10', u'.', u'9', u'pct', u'over', u'1985', u'.'], [u'Output', u'in', u'1986', u'fell', u'from', u'4', u'.', u'15', u'mln', u'tonnes', u'in', u'1985', u'and', u'a', u'record', u'6', u'.', u'2', u'mln', u'in', u'1984', u',', u'official', u'figures', u'show', u'.'], [u'The', u'China', u'Daily', u'attributed', u'the', u'decline', u'to', u'several', u'factors', u',', u'including', u'less', u'favorable', u'weather', u'conditions', u'and', u'new', u'state', u'measures', u'to', u'restrict', u'cotton', u'production', u'after', u'the', u'1984', u'build', u'-', u'up', u'of', u'stocks', u'.'], [u'According', u'to', u'Customs', u'figures', u',', u'cotton', u'exports', u'rose', u'to', u'558', u',', u'089', u'tonnes', u'in', u'calendar', u'1986', u'from', u'347', u',', u'026', u'in', u'1985', u'.'], [u'To', u'increase', u'output', u'quickly', u',', u'the', u'state', u'will', u'raise', u'by', u'10', u'pct', u'the', u'price', u'it', u'pays', u'for', u'cotton', u'produced', u'above', u'and', u'beyond', u'quota', u'levels', u',', u'the', u'newspaper', u'said', u'.'], [u'Its', u'official', u'purchasing', u'agencies', u'will', u'buy', u'cotton', u'produced', u'in', u'excess', u'of', u'that', u'originally', u'contracted', u'for', u',', u'it', u'added', u'.'], [u'The', u'China', u'Daily', u'said', u'all', u'cotton', u'growing', u'areas', u'in', u'south', u'China', u'should', u'be', u'maintained', u',', u'and', u'growing', u'in', u'the', u'north', u'should', u'be', u'concentrated', u'in', u'Hebei', u',', u'Shandong', u',', u'Henan', u'and', u'Xinjiang', u'.'], [u'It', u'called', u'for', u'comprehensive', u'planning', u'to', u'coordinate', u'production', u'of', u'cotton', u'with', u'that', u'of', u'grain', u',', u'edible', u'oil', u'and', u'other', u'crops', u',', u'but', u'gave', u'no', u'more', u'details', u'.']]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.paras(sample_fileid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "corpus_train = []\n",
    "corpus_test = []\n",
    "for fileid in dataset.fileids():\n",
    "    document = dataset.raw(fileid)\n",
    "    if re.match('training/',fileid):\n",
    "        corpus_train.append(document)\n",
    "    else:\n",
    "        corpus_test.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7769, 3019)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_train),len(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessor(string):\n",
    "    repl = re.sub('&lt;','',string)\n",
    "    return repl.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "                min_df=10, # tweaking this parameter reduces the length of the feature vector\n",
    "                strip_accents='ascii',\n",
    "                preprocessor=preprocessor,\n",
    "                stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7769, 6462), (3019, 6462), (10788, 6462))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to use both corpuses for fitting because otherwise there may be words that only occur in the\n",
    "# training set or in the test set\n",
    "full_corpus = corpus_train + corpus_test\n",
    "vectorizer.fit(full_corpus)\n",
    "\n",
    "X_train_counts = vectorizer.transform(corpus_train)\n",
    "X_test_counts = vectorizer.transform(corpus_test)\n",
    "X_full_counts = vectorizer.transform(full_corpus)\n",
    "\n",
    "X_train_counts.shape,X_test_counts.shape, X_full_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#uncomment these to see how the vectorizer is analyzing, tokenizing and preprocessing documents\n",
    "\n",
    "#vectorizer.build_analyzer()(dataset.raw(fileid))\n",
    "#vectorizer.build_tokenizer()(\"ADVANCED INSTITUTIONAL &lt;AIMS> CUTS WORKFORCE\\n  Advanced Institutional \")\n",
    "#vectorizer.build_preprocessor()(\"ADVANCED INSTITUTIONAL &lt;AIMS> CUTS WORKFORCE\\n  Advanced Institutional \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0].toarray().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts[0].toarray().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7769, 6462), (3019, 6462), (10788, 6462))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "# again, we need to fit the transformer to all documents (train and test)\n",
    "transformer.fit(X_full_counts)\n",
    "\n",
    "X_train_tfidf = transformer.transform(X_train_counts)\n",
    "X_test_tfidf = transformer.transform(X_test_counts)\n",
    "X_full_tfidf = transformer.transform(X_full_counts)\n",
    "\n",
    "X_train_tfidf.shape, X_test_tfidf.shape, X_full_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.       ,  0.       ,  0.       , ...,  0.0466051,  0.       ,  0.       ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf[0].toarray().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf[0].toarray().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7769, 90), (3019, 90))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = []\n",
    "Y_test = []\n",
    "\n",
    "for (idx,fileid) in enumerate(dataset.fileids()):    \n",
    "    categories = '*'.join(dataset.categories(fileid))\n",
    "\n",
    "    if re.match('training/',fileid):\n",
    "        Y_train.append(categories)\n",
    "    else:\n",
    "        Y_test.append(categories)\n",
    "\n",
    "series_train = pd.Series(Y_train)\n",
    "Y_train_df = series_train.str.get_dummies(sep='*')\n",
    "\n",
    "series_test = pd.Series(Y_test)\n",
    "Y_test_df = series_test.str.get_dummies(sep='*')\n",
    "\n",
    "Y_train = Y_train_df.values\n",
    "Y_test = Y_test_df.values\n",
    "\n",
    "Y_train.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7769, 50)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "\n",
    "meta_clf = OneVsRestClassifier(clf)\n",
    "\n",
    "pca = RandomizedPCA(n_components=50)\n",
    "pca.fit(X_train_tfidf.toarray())\n",
    "\n",
    "X_train_reduced = pca.transform(X_train_tfidf.toarray())\n",
    "X_test_reduced = pca.transform(X_test_tfidf.toarray())\n",
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_clf.fit(X_train_reduced,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = meta_clf.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72664015904572576"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_test,Y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
