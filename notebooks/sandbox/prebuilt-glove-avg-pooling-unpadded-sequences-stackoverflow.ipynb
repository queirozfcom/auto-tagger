{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classify stackoverflow posts by considering each document a simple mean of its individual word embeddings, then using individual tag probabilities to assign tags to samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, GlobalAvgPool1D\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "# my stuff in the helpers/ directory\n",
    "from helpers import files_helper, texts_helper, metrics_helper, tags_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED=np.random.randint(1,1000)\n",
    "SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts, labels = files_helper.read_stackoverflow_sample_small()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EMBEDDING_DIM=100\n",
    "LABELS_MIN_DOC_COUNT = int(10)\n",
    "BATCH_SIZE=1\n",
    "NUM_EPOCHS=10\n",
    "TOKENIZER_FILTERS='\\'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "TAG_PROB_THRESHOLD=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS,\n",
    "                     filters=TOKENIZER_FILTERS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "inverse_word_index = texts_helper.build_inverse_word_index(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apply',\n",
       " 'onclick',\n",
       " 'event',\n",
       " 'to',\n",
       " 'an',\n",
       " 'option',\n",
       " 'i',\n",
       " 'am',\n",
       " 'using',\n",
       " 'zend',\n",
       " 'form',\n",
       " 'to',\n",
       " 'create',\n",
       " 'a',\n",
       " 'form',\n",
       " 'i',\n",
       " 'am',\n",
       " 'also',\n",
       " 'using',\n",
       " 'mootools',\n",
       " 'for',\n",
       " 'javascript',\n",
       " 'this',\n",
       " 'gt',\n",
       " 'radio',\n",
       " 'alone',\n",
       " 'array',\n",
       " 'label',\n",
       " 'gt',\n",
       " 'are',\n",
       " 'you',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'taking',\n",
       " 'part',\n",
       " 'with',\n",
       " 'anyone',\n",
       " 'else',\n",
       " 'required',\n",
       " 'gt',\n",
       " 'true',\n",
       " 'onclick',\n",
       " 'gt',\n",
       " 'gt',\n",
       " 'array',\n",
       " 'yes',\n",
       " 'gt',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'gt',\n",
       " 'no',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'the',\n",
       " 'onclick',\n",
       " 'event',\n",
       " 'works',\n",
       " 'if',\n",
       " 'any',\n",
       " 'option',\n",
       " 'is',\n",
       " 'selected',\n",
       " 'how',\n",
       " 'do',\n",
       " 'i',\n",
       " 'get',\n",
       " 'it',\n",
       " 'to',\n",
       " 'work',\n",
       " 'for',\n",
       " 'just',\n",
       " 'yes',\n",
       " 'being',\n",
       " 'selected']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inverse_word_index[idx] for idx in sequences[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "truncated_labels = tags_helper.truncate_labels(labels,LABELS_MIN_DOC_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb = preprocessing.MultiLabelBinarizer()\n",
    "binary_labels = lb.fit_transform(truncated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tag position => fraction of docs having that tag\n",
    "tag_probabilities_index = tags_helper.get_probabilities_index(binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word => embedding\n",
    "embeddings_index = files_helper.read_glove(d=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1,EMBEDDING_DIM))\n",
    "\n",
    "for word,i in word_index.items():\n",
    "    \n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    \n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178778, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25600, 6400, (32000, 1209))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unpadded sequences. no call to pad_sequences\n",
    "data = sequences\n",
    "num_rows = len(data)\n",
    "\n",
    "indices = np.arange(num_rows)\n",
    "\n",
    "data = [ np.array(data[i]) for i in indices]\n",
    "\n",
    "indices = np.arange(num_rows)\n",
    "\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "labels_1 = binary_labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * num_rows)\n",
    "\n",
    "X_train = data[:-num_validation_samples]\n",
    "Y_train = labels_1[:-num_validation_samples]\n",
    "X_val = data[-num_validation_samples:]\n",
    "Y_val = labels_1[-num_validation_samples:]\n",
    "\n",
    "len(X_train),len(X_val),labels_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76, 209, 103, 92, 560, 143, 171, 148, 1048, 98]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG: lengths of the first 10 documents\n",
    "seq_lengths_train = [len(seq) for seq in data]\n",
    "seq_lengths_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25600/25600 [01:08<00:00, 372.24it/s]\n",
      "100%|██████████| 6400/6400 [00:06<00:00, 812.64it/s] \n",
      "  0%|          | 25/25600 [00:00<01:44, 243.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch 0: train_loss: 0.013153879903256893, val_loss: 0.012133252806961536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25600/25600 [01:12<00:00, 355.35it/s]\n",
      "100%|██████████| 6400/6400 [00:05<00:00, 1212.36it/s]\n",
      "  0%|          | 33/25600 [00:00<01:18, 325.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch 1: train_loss: 0.012076538987457752, val_loss: 0.01215445064008236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25600/25600 [01:11<00:00, 356.75it/s]\n",
      "100%|██████████| 6400/6400 [00:05<00:00, 1276.98it/s]\n",
      "  0%|          | 38/25600 [00:00<01:08, 372.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch 2: train_loss: 0.011958181858062744, val_loss: 0.012971908785402775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25600/25600 [01:12<00:00, 354.48it/s]\n",
      "100%|██████████| 6400/6400 [00:05<00:00, 1197.64it/s]\n",
      "  0%|          | 34/25600 [00:00<01:16, 333.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after epoch 3: train_loss: 0.01166074350476265, val_loss: 0.011564414948225021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 5624/25600 [00:16<00:57, 346.64it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/felipe/tf-venv3/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    939\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    940\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/felipe/tf-venv3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/tf-venv3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2103\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/tf-venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/tf-venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/tf-venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/felipe/tf-venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/felipe/tf-venv3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_labels = labels_1.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index)+1,\n",
    "                           EMBEDDING_DIM,\n",
    "                           weights=[embedding_matrix],\n",
    "                           trainable = False))\n",
    "model.add(GlobalAvgPool1D())\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam')\n",
    "\n",
    "for epoch_num in range(10):\n",
    "\n",
    "    # training in single-example batches\n",
    "    idxs = np.array(list(range(len(X_train))))\n",
    "    np.random.shuffle(idxs)\n",
    "       \n",
    "    train_losses = []\n",
    "    val_losses = []    \n",
    "        \n",
    "    for i in tqdm(idxs):\n",
    "\n",
    "        train_x = X_train[i].reshape(1,-1)\n",
    "        train_y = Y_train[i].reshape(1,-1)\n",
    "        \n",
    "        model.train_on_batch(train_x,train_y)\n",
    "        train_losses.append(model.test_on_batch(train_x,train_y))\n",
    "        \n",
    "    # average of validation scores over whole validation set   \n",
    "    idxs = np.array(list(range(len(X_val))))\n",
    "    np.random.shuffle(idxs)\n",
    "\n",
    "        \n",
    "    for i in tqdm(idxs):   \n",
    "        val_x = X_val[i].reshape(1,-1)\n",
    "        val_y = Y_val[i].reshape(1,-1)\n",
    "        \n",
    "        \n",
    "        val_losses.append(model.test_on_batch(val_x,val_y))\n",
    "    \n",
    "    train_loss = np.mean(np.array(train_losses))\n",
    "    val_loss = np.mean(np.array(val_losses))\n",
    "    \n",
    "    tqdm.write(\"after epoch {0}: train_loss: {1}, val_loss: {2}\".format(\n",
    "        epoch_num,\n",
    "        train_loss,\n",
    "        val_loss))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(predicted_probabilities, predicted_indices):\n",
    "    \"\"\"\n",
    "    predicted_probabilities (output of n sigmoid output units)\n",
    "    predicted_indices (according to some strategy, e.g. static threshold, etc)\n",
    "    \"\"\"\n",
    "    \n",
    "    # indices that are turned on (equal 1)\n",
    "    active_indices = predicted_indices.ravel().nonzero()[0]\n",
    "        \n",
    "    scores_for_active_indices = predicted_probabilities[active_indices]\n",
    "    \n",
    "    scores_for_active_indices_as_matrix = scores_for_active_indices.reshape(1,-1)\n",
    "    \n",
    "    return scores_for_active_indices_as_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('jar', 'java', 'netbeans')\n",
      "[('javascript', 0.09530472), ('java', 0.091640197), ('php', 0.087819368), ('c#', 0.079533748), ('android', 0.077264994), ('jquery', 0.063962288), ('python', 0.062537163), ('html', 0.051446669)]\n",
      "\n",
      "\n",
      "('dataframe', 'r')\n",
      "[('javascript', 0.093118869), ('java', 0.09103056), ('php', 0.085039146), ('c#', 0.078287423), ('android', 0.075730354), ('jquery', 0.063308433), ('python', 0.06063414)]\n",
      "\n",
      "\n",
      "('animation', 'ios', 'iphone', 'swift3')\n",
      "[('javascript', 0.090115122), ('java', 0.087930478), ('php', 0.081183553), ('c#', 0.074570678), ('android', 0.073187307), ('jquery', 0.060236402), ('python', 0.058433939)]\n",
      "\n",
      "\n",
      "()\n",
      "[('javascript', 0.091660246), ('java', 0.089986801), ('php', 0.082986042), ('c#', 0.076710582), ('android', 0.074333116), ('jquery', 0.062237859), ('python', 0.058679678)]\n",
      "\n",
      "\n",
      "('go',)\n",
      "[('javascript', 0.092242248), ('java', 0.09046711), ('php', 0.085395887), ('c#', 0.078096718), ('android', 0.075273827), ('jquery', 0.062632553), ('python', 0.059128549)]\n",
      "\n",
      "\n",
      "('c#', 'visual-studio-2013', 'visual-studio-2015')\n",
      "[('javascript', 0.089133613), ('java', 0.087264843), ('php', 0.077862523), ('c#', 0.073158108), ('android', 0.071122453), ('jquery', 0.060332425), ('python', 0.057667654)]\n",
      "\n",
      "\n",
      "('facebook', 'facebook-graph-api', 'ruby')\n",
      "[('javascript', 0.091658674), ('java', 0.089401543), ('php', 0.083415754), ('c#', 0.076343693), ('android', 0.074712552), ('jquery', 0.061533839), ('python', 0.05967968)]\n",
      "\n",
      "\n",
      "('click', 'events', 'image', 'java')\n",
      "[('javascript', 0.093439639), ('java', 0.093066059), ('php', 0.086675808), ('c#', 0.078957208), ('android', 0.076954179), ('jquery', 0.064522654), ('python', 0.060480222), ('html', 0.051079743)]\n",
      "\n",
      "\n",
      "('connection', 'github', 'svn')\n",
      "[('javascript', 0.089957625), ('java', 0.088289753), ('php', 0.083742328), ('c#', 0.077000074), ('android', 0.073466659), ('jquery', 0.060704682), ('python', 0.056626182)]\n",
      "\n",
      "\n",
      "('iis-7', 'visual-studio-2010')\n",
      "[('javascript', 0.092862353), ('java', 0.091141842), ('php', 0.084176339), ('c#', 0.077593885), ('android', 0.074714728), ('jquery', 0.063742526), ('python', 0.059758585)]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      " 22%|██▏       | 5624/25600 [00:30<01:46, 187.29it/s]"
     ]
    }
   ],
   "source": [
    "# sample result for a couple of test cases\n",
    "num_test_cases = 10\n",
    "\n",
    "for i in np.random.randint(low=0, high=len(Y_val), size=num_test_cases):\n",
    "\n",
    "    actual_label_indices = Y_val[i].reshape(1,-1)\n",
    "    actual_labels = lb.inverse_transform(actual_label_indices)\n",
    "    actual_labels_tpl = actual_labels[0]\n",
    "    \n",
    "    predicted_tag_probabilities = model.predict(X_val[i].reshape(1,-1)).ravel()\n",
    "              \n",
    "    predicted_label_indices = tags_helper.get_predicted_indices_by_threshold(\n",
    "        predicted_tag_probabilities,\n",
    "        TAG_PROB_THRESHOLD)\n",
    "       \n",
    "#     predicted_label_indices = get_predicted_indices_by_tag_doc_fraction(\n",
    "#         tag_probabilities_index,\n",
    "#         predicted_tag_probabilities)\n",
    "        \n",
    "#     print(predicted_label_indices.nonzero()[0])\n",
    "    \n",
    "    predicted_label_scores_mat = get_scores(predicted_tag_probabilities,\n",
    "                                       predicted_label_indices)\n",
    "    \n",
    "    predicted_label_scores_arr = predicted_label_scores_mat.ravel()\n",
    "    \n",
    "    predicted_labels = lb.inverse_transform(predicted_label_indices)\n",
    "\n",
    "    predicted_labels_tpl = predicted_labels[0]\n",
    "    \n",
    "#     print(predicted_label_scores.ravel())\n",
    "    \n",
    "    tags_and_scores = sorted(list(zip(predicted_labels_tpl,predicted_label_scores_arr)), key=lambda tpl: tpl[1], reverse=True)\n",
    "  \n",
    "\n",
    "    print(actual_labels_tpl)\n",
    "    print(tags_and_scores)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Global TF Kernel (Python 3)",
   "language": "python",
   "name": "global-tf-python-3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
